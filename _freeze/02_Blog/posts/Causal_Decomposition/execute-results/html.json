{
  "hash": "8698537d34337f9c8ea92ca079d64245",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Causal Decomposition Analysis\"\ndate: 2024-02-22\ncategories: [Causal Inference]\n---\n\n\n## 前準備\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(cfdecomp)\nlibrary(gapclosing)\nlibrary(causal.decomp)\n\n\nd <- \n  sMIDUS |> \n  transmute(Y = health |> as.numeric(),  # outcome\n            T = edu |> as.numeric(),   # treatment (continuous)\n            T2 = edu |> case_match(4:6 ~ 0,   # treatment (binary)\n                                   7:9 ~ 1,\n                                   .default = NA) |> factor(),\n            X = racesex |> factor(levels = c(\"1\", \"4\", \"2\", \"3\")),  # note!\n            L1 = lowchildSES |> as.numeric(),\n            L2 = abuse |> as.numeric(),\n            C1 = age |> as.numeric(),\n            C2 = stroke |> as.numeric(),\n            C3 = T2DM |> as.numeric(),\n            C4 = heart |> as.numeric()) |> \n  mutate(across(L1:C4, \\(.x){.x - mean(.x, na.rm = TRUE)})) |> \n  tibble()\n```\n:::\n\n\n# continuuous mediator\n\n## `cfdecomp`\n\n- @Sudharsanan2021 の方法。mediatorの値をシミュレーションで複数生成するのが特徴\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# cfd.mean\nfit_cfdecomp <-\n  cfdecomp::cfd.mean(\n    formula.y = 'Y ~ X + T + X:T + L1 + L2 + C1 + C2 + C3 + C4',\n    formula.m = 'T ~ X + C1 + C2 + C3 + C4',\n    mediator = 'T',\n    group = 'X',\n    data = d |> data.frame(),\n    family.y = 'gaussian',\n    family.m = 'gaussian',\n    bs.size = 50,\n    mc.size = 10,\n    alpha = 0.05\n  )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_cfdecomp\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$out_nc_m\n          1        4        2        3\n1  7.731789 5.805505 7.066859 6.349031\n2  7.707226 5.843033 7.070471 6.485656\n3  7.698774 5.821902 7.062534 6.375884\n4  7.691470 5.865455 7.099146 6.303865\n5  7.688225 5.836683 7.054470 6.312770\n6  7.723805 5.803500 7.068066 6.444975\n7  7.698415 5.870867 7.062609 6.386744\n8  7.699978 5.933884 7.057151 6.402836\n9  7.710907 5.845157 7.059609 6.461985\n10 7.708696 5.950518 7.081765 6.478036\n11 7.686202 5.955810 7.077234 6.504364\n12 7.669373 5.879307 7.048990 6.403341\n13 7.710189 5.911726 7.074698 6.387250\n14 7.688763 5.840438 7.105175 6.406841\n15 7.708662 5.863814 7.074277 6.360935\n16 7.702557 5.886883 7.082974 6.381459\n17 7.720214 5.875628 7.092283 6.553809\n18 7.734196 5.847053 7.088655 6.312337\n19 7.726682 5.844651 7.113512 6.447178\n20 7.662551 5.897172 7.094152 6.408982\n21 7.687241 5.806254 7.097668 6.356683\n22 7.706224 5.821863 7.054051 6.433060\n23 7.741596 5.801439 7.062559 6.392707\n24 7.674205 5.894450 7.081670 6.385270\n25 7.709742 5.799705 7.114933 6.466543\n26 7.716565 5.906480 7.070636 6.382427\n27 7.742944 5.859867 7.061948 6.401316\n28 7.717200 5.890989 7.097299 6.409356\n29 7.723915 5.868337 7.071758 6.372131\n30 7.726668 5.881568 7.100313 6.372692\n31 7.731705 5.919737 7.105135 6.373668\n32 7.712671 5.839134 7.088908 6.460836\n33 7.682584 5.857658 7.062899 6.533219\n34 7.691469 5.835281 7.090124 6.398250\n35 7.743882 5.871340 7.064668 6.419700\n36 7.713512 5.902022 7.118880 6.411312\n37 7.693975 5.942511 7.065955 6.404655\n38 7.697669 5.849695 7.099616 6.396220\n39 7.691657 5.886817 7.068964 6.244611\n40 7.681820 5.871839 7.087398 6.434817\n41 7.718626 5.877690 7.066733 6.400651\n42 7.709633 5.861919 7.046760 6.351833\n43 7.736185 5.912152 7.092974 6.424599\n44 7.705218 5.879939 7.054936 6.350873\n45 7.683444 5.900607 7.072793 6.430105\n46 7.719582 5.888390 7.092494 6.473278\n47 7.681407 5.883261 7.095664 6.423728\n48 7.696037 5.844135 7.091612 6.329174\n49 7.702683 5.891098 7.101262 6.381780\n50 7.720314 5.916573 7.092069 6.310055\n\n$out_cf_m\n          1        4        2        3\n1  7.719913 7.746320 7.728786 7.699058\n2  7.678215 7.694068 7.693180 7.665525\n3  7.699434 7.725147 7.722325 7.696981\n4  7.676104 7.727642 7.696774 7.647236\n5  7.692116 7.709129 7.696729 7.674762\n6  7.731730 7.727295 7.750164 7.699577\n7  7.704540 7.714182 7.719238 7.698657\n8  7.709604 7.716467 7.729127 7.701963\n9  7.714103 7.718377 7.729895 7.684083\n10 7.707093 7.698710 7.712935 7.672843\n11 7.680038 7.702717 7.700398 7.668603\n12 7.677552 7.677258 7.678370 7.662850\n13 7.701106 7.722790 7.730619 7.741173\n14 7.692373 7.693829 7.705447 7.669664\n15 7.711272 7.714818 7.705975 7.707794\n16 7.726449 7.746166 7.711053 7.709945\n17 7.722831 7.707959 7.733351 7.733453\n18 7.731768 7.723379 7.739136 7.668382\n19 7.745723 7.733054 7.751725 7.755856\n20 7.671000 7.679469 7.655867 7.626149\n21 7.702213 7.734704 7.725656 7.680785\n22 7.707144 7.742190 7.727008 7.716613\n23 7.729849 7.738835 7.742313 7.685720\n24 7.685653 7.711574 7.699772 7.670258\n25 7.710139 7.747027 7.736181 7.697113\n26 7.709258 7.705371 7.718198 7.673312\n27 7.753493 7.755348 7.758776 7.757045\n28 7.739015 7.718246 7.720594 7.715022\n29 7.716218 7.724317 7.713021 7.700595\n30 7.711303 7.727521 7.713654 7.696233\n31 7.760813 7.742986 7.748841 7.746770\n32 7.716122 7.710385 7.722291 7.696317\n33 7.693466 7.662975 7.679297 7.709346\n34 7.683647 7.689322 7.686074 7.703252\n35 7.744599 7.741218 7.750546 7.724121\n36 7.697419 7.685222 7.724294 7.692201\n37 7.700813 7.740795 7.713151 7.696126\n38 7.676711 7.680532 7.706335 7.671492\n39 7.690267 7.654816 7.691495 7.633795\n40 7.676736 7.694828 7.691697 7.692020\n41 7.712844 7.741225 7.715984 7.724711\n42 7.718374 7.729696 7.734668 7.725327\n43 7.736461 7.745641 7.754585 7.720189\n44 7.694301 7.703422 7.717384 7.646946\n45 7.692242 7.692127 7.684788 7.666741\n46 7.735225 7.711455 7.735495 7.745750\n47 7.681518 7.720674 7.699393 7.694490\n48 7.694283 7.686017 7.721461 7.692578\n49 7.711065 7.713413 7.716224 7.728340\n50 7.722788 7.733545 7.729447 7.682326\n\n$out_nc_quantile_m\n             1        4        2        3\n2.5%  7.670460 5.801903 7.050129 6.305258\n50%   7.707944 5.871590 7.079452 6.400983\n97.5% 7.742641 5.948717 7.114614 6.526726\n\n$out_cf_quantile_m\n             1        4        2        3\n2.5%  7.676241 7.666189 7.678578 7.636754\n50%   7.708201 7.717356 7.718718 7.696275\n97.5% 7.751745 7.746868 7.753942 7.753812\n\n$out_nc_y\n          1        4        2        3\n1  7.654354 6.726877 7.279371 7.006732\n2  7.604374 6.703217 7.315085 7.097881\n3  7.605167 6.640730 7.292927 7.048538\n4  7.609123 6.686366 7.323191 6.849639\n5  7.577872 6.763536 7.318662 6.942950\n6  7.587875 6.683869 7.348530 6.897409\n7  7.596512 6.736657 7.297214 7.017636\n8  7.597459 6.706974 7.365672 7.009930\n9  7.584375 6.740994 7.313201 7.063046\n10 7.602285 6.749087 7.328256 7.125055\n11 7.571613 6.701864 7.287344 7.027034\n12 7.642267 6.679553 7.348553 6.990542\n13 7.579927 6.759528 7.302936 7.048694\n14 7.561756 6.662268 7.324979 7.032725\n15 7.609795 6.692728 7.303105 6.986432\n16 7.606684 6.733055 7.290687 7.005327\n17 7.596875 6.687174 7.301648 7.018505\n18 7.615286 6.712333 7.293161 6.975195\n19 7.611216 6.714235 7.318400 7.103140\n20 7.610244 6.719374 7.305010 7.000470\n21 7.620159 6.733937 7.357554 6.972791\n22 7.596723 6.712167 7.345405 7.021319\n23 7.617759 6.661849 7.308262 6.971760\n24 7.579323 6.658994 7.307253 6.996847\n25 7.574397 6.681958 7.335591 6.944247\n26 7.612435 6.745267 7.350639 7.024679\n27 7.579164 6.709612 7.295948 6.949603\n28 7.584462 6.700136 7.287569 6.990432\n29 7.624832 6.701683 7.340434 6.948277\n30 7.629350 6.749253 7.352669 6.997115\n31 7.615771 6.689698 7.304085 7.004110\n32 7.624198 6.680530 7.324006 6.888503\n33 7.591139 6.631380 7.336246 7.108249\n34 7.596286 6.698941 7.318825 7.032162\n35 7.587954 6.669535 7.333915 6.948089\n36 7.639479 6.733325 7.347933 7.023281\n37 7.606131 6.800760 7.304337 6.976923\n38 7.555995 6.682133 7.313927 6.983365\n39 7.612931 6.717997 7.305366 6.775258\n40 7.539498 6.773797 7.326341 7.022486\n41 7.633821 6.692777 7.300170 7.072764\n42 7.613440 6.671418 7.343165 7.002534\n43 7.589947 6.730775 7.335019 6.982015\n44 7.580244 6.673911 7.318004 7.007913\n45 7.612123 6.772801 7.326254 6.918901\n46 7.598858 6.675470 7.327589 7.099497\n47 7.571266 6.728050 7.312118 6.924836\n48 7.633511 6.633413 7.316639 6.917330\n49 7.565143 6.713109 7.333032 6.933765\n50 7.597296 6.769629 7.359050 6.870460\n\n$out_cf_y\n          1        4        2        3\n1  7.651580 7.280327 7.433407 7.148336\n2  7.598316 7.364480 7.462969 7.513760\n3  7.605259 7.300873 7.445011 7.280079\n4  7.605265 7.220335 7.447280 7.444796\n5  7.578768 7.313775 7.455726 7.287270\n6  7.589536 7.333158 7.529055 7.181668\n7  7.597940 7.159310 7.431304 7.407380\n8  7.600139 7.238519 7.520944 7.347962\n9  7.585226 7.238013 7.467420 7.206755\n10 7.601882 7.204490 7.467875 7.349244\n11 7.570062 7.310320 7.417403 7.246240\n12 7.644254 7.295837 7.497083 7.402857\n13 7.578033 7.218928 7.431563 7.332764\n14 7.562771 7.188282 7.458223 7.190563\n15 7.610323 7.046494 7.421189 7.233469\n16 7.612510 7.308954 7.415157 7.429157\n17 7.597392 7.254821 7.428926 7.263213\n18 7.614863 7.212235 7.469477 7.093990\n19 7.615121 7.226062 7.488663 7.230689\n20 7.612024 7.290666 7.406780 7.188714\n21 7.623698 7.311562 7.510014 7.236440\n22 7.596961 7.348498 7.463619 7.334002\n23 7.615365 7.455319 7.460632 7.417265\n24 7.581550 7.019159 7.436448 7.225535\n25 7.574483 7.212054 7.452269 7.177630\n26 7.610472 7.277957 7.454000 7.302071\n27 7.581687 7.217582 7.480976 7.242596\n28 7.590178 7.222412 7.431234 7.331709\n29 7.622939 7.366921 7.480330 7.235731\n30 7.625461 7.364106 7.487113 7.355902\n31 7.622096 7.199349 7.465602 7.253736\n32 7.624942 7.355884 7.447775 7.055203\n33 7.593184 7.246195 7.456345 7.206748\n34 7.594305 7.205120 7.450068 7.272635\n35 7.588149 7.245190 7.505413 7.014219\n36 7.635373 7.277123 7.451057 7.323479\n37 7.607531 7.413763 7.449557 7.470978\n38 7.552591 7.290708 7.443413 7.045987\n39 7.612603 7.141743 7.455111 7.169168\n40 7.538307 7.369341 7.465470 7.473931\n41 7.632490 7.184794 7.471516 7.342080\n42 7.615353 7.229403 7.450599 7.394764\n43 7.590004 7.279568 7.486427 7.158535\n44 7.577797 7.246399 7.476507 7.094514\n45 7.614111 7.256873 7.473994 7.177816\n46 7.602539 7.264906 7.485320 7.459046\n47 7.571299 7.190251 7.444465 6.994557\n48 7.633077 7.249494 7.479441 7.142252\n49 7.567511 7.096721 7.486926 7.228220\n50 7.597905 7.411709 7.460691 7.268741\n\n$out_nc_quantile_y\n             1        4        2        3\n2.5%  7.557292 6.635059 7.287395 6.854324\n50%   7.600571 6.705095 7.318531 6.998793\n97.5% 7.641640 6.773573 7.358713 7.107100\n\n$out_cf_quantile_y\n             1        4        2        3\n2.5%  7.554882 7.057795 7.415662 7.021367\n50%   7.601011 7.252157 7.459427 7.249988\n97.5% 7.642256 7.413301 7.518484 7.473267\n\n$mediation\n        4         2         3 \n0.6182036 0.5076457 0.4483935 \n\n$mediation_quantile\n              4         2         3\n2.5%  0.4045932 0.3607608 0.1081933\n97.5% 0.7773249 0.6739174 0.8130188\n\n$mc_conv_info_m\n          [,1]     [,2]     [,3]     [,4]\n [1,] 7.725375 5.833575 7.061328 6.407614\n [2,] 7.739864 5.846927 7.057499 6.373652\n [3,] 7.739435 5.830384 7.069188 6.383956\n [4,] 7.739284 5.834167 7.072495 6.378767\n [5,] 7.735722 5.823713 7.063801 6.367829\n [6,] 7.735676 5.814660 7.064555 6.359981\n [7,] 7.741011 5.813870 7.069577 6.356077\n [8,] 7.734823 5.807032 7.067207 6.357027\n [9,] 7.735733 5.808808 7.066303 6.350663\n[10,] 7.731789 5.805505 7.066859 6.349031\n\n$mc_conv_info_y\n          [,1]     [,2]     [,3]     [,4]\n [1,] 7.652856 6.734882 7.278084 7.012877\n [2,] 7.656240 6.738689 7.277193 7.009315\n [3,] 7.656140 6.733972 7.279913 7.010396\n [4,] 7.656105 6.735050 7.280683 7.009852\n [5,] 7.655273 6.732069 7.278660 7.008704\n [6,] 7.655262 6.729488 7.278835 7.007881\n [7,] 7.656508 6.729262 7.280004 7.007472\n [8,] 7.655063 6.727312 7.279453 7.007571\n [9,] 7.655275 6.727819 7.279242 7.006904\n[10,] 7.654354 6.726877 7.279371 7.006732\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp$out_nc_y[,2] - fit_cfdecomp$out_nc_y[,1])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.8922794\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp$out_cf_y[,2] - fit_cfdecomp$out_nc_y[,1])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.3410542\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp$out_nc_y[,2] - fit_cfdecomp$out_cf_y[,2])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.5512252\n```\n\n\n:::\n\n```{.r .cell-code}\nfit_cfdecomp$mediation\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        4         2         3 \n0.6182036 0.5076457 0.4483935 \n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp$out_nc_y[,3] - fit_cfdecomp$out_nc_y[,1])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.2796684\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp$out_cf_y[,3] - fit_cfdecomp$out_nc_y[,1])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.1390182\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp$out_nc_y[,3] - fit_cfdecomp$out_cf_y[,3])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.1406502\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp$out_nc_y[,4] - fit_cfdecomp$out_nc_y[,1])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.609046\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp$out_cf_y[,4] - fit_cfdecomp$out_nc_y[,1])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.336486\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp$out_nc_y[,4] - fit_cfdecomp$out_cf_y[,4])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.2725601\n```\n\n\n:::\n:::\n\n\n## `causal.decomp`\n\n- @Park2023a の方法。\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# smi \nfit.y <- lm(Y ~ X + T + X:T + L1 + L2 + C1 + C2 + C3 + C4, data = d)\nfit.m <- lm(T ~ X + C1 + C2 + C3 + C4, data = d)\n\nfit_smi <- smi(fit.y = fit.y,\n    fit.m = fit.m,\n    treat = \"X\", \n    sims = 100, \n    conf.level = .95,\n    conditional = TRUE,\n    covariates = 1,\n    # baseline covariatesを調整できる\n    #covariates = c(\"C1\", \"C2\", \"C3\", \"C4\"),\n    seed = 227,\n    )\n\nfit_smi\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nResults:\n\n                               estimate 95% CI Lower 95% CI Upper\nInitial Disparity   (1 vs 4) -0.8993401   -0.9925190  -0.79813505\nDisparity Remaining (1 vs 4) -0.3384430   -0.4880863  -0.14795873\nDisparity Reduction (1 vs 4) -0.5608971   -0.7346168  -0.42650061\nInitial Disparity   (1 vs 2) -0.2749659   -0.3378874  -0.19366549\nDisparity Remaining (1 vs 2) -0.1213246   -0.2203441  -0.05458727\nDisparity Reduction (1 vs 2) -0.1536412   -0.1896213  -0.10521328\nInitial Disparity   (1 vs 3) -0.6137425   -0.7326095  -0.47793913\nDisparity Remaining (1 vs 3) -0.3500123   -0.5151994  -0.08733348\nDisparity Reduction (1 vs 3) -0.2637302   -0.4880614  -0.11574038\n```\n\n\n:::\n:::\n\n\n- sensitivity analysis[@Park2023]\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsensRes <- sensitivity(boot.res = fit_smi, fit.m = fit.m, fit.y = fit.y, \n                       mediator = \"T\",\n                       covariates = c(\"C1\", \"C2\", \"C3\", \"C4\"), \n                       treat = \"X\",\n                       sel.lev.treat = \"4\", \n                       max.rsq = 0.3)\nplot(sensRes)\n```\n\n::: {.cell-output-display}\n![](Causal_Decomposition_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\n# binary mediator\n\n## `cfdecomp`\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# cfd.mean\nset.seed(123456)\nfit_cfdecomp_b <-\n  cfd.mean(\n    formula.y = 'Y ~ X + T2 + X:T2 + L1 + L2 + C1 + C2 + C3 + C4',\n    formula.m = 'T2 ~ X + C1 + C2 + C3 + C4',\n    mediator = 'T2',\n    group = 'X',\n    data = d |> mutate(T2 = as.numeric(T2) - 1) |> data.frame(),\n    family.y = 'gaussian',\n    family.m = 'binomial',\n    bs.size = 50,\n    mc.size = 10,\n    alpha = 0.05\n  )\nmean(fit_cfdecomp_b$out_nc_y[,\"4\"] - fit_cfdecomp_b$out_nc_y[,\"1\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.8981701\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp_b$out_cf_y[,\"4\"] - fit_cfdecomp_b$out_nc_y[,\"1\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.5546351\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp_b$out_nc_y[,\"4\"] - fit_cfdecomp_b$out_cf_y[,\"4\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.343535\n```\n\n\n:::\n\n```{.r .cell-code}\nfit_cfdecomp_b$mediation\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        4         2         3 \n0.3828971 0.1298177 0.2061071 \n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp_b$out_nc_y[,\"2\"] - fit_cfdecomp_b$out_nc_y[,\"1\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.2774845\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp_b$out_cf_y[,\"2\"] - fit_cfdecomp_b$out_nc_y[,\"1\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.2419289\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp_b$out_nc_y[,\"2\"] - fit_cfdecomp_b$out_cf_y[,\"2\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.03555558\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp_b$out_nc_y[,\"3\"] - fit_cfdecomp_b$out_nc_y[,\"1\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.5849521\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp_b$out_cf_y[,\"3\"] - fit_cfdecomp_b$out_nc_y[,\"1\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.4655888\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp_b$out_nc_y[,\"3\"] - fit_cfdecomp_b$out_cf_y[,\"3\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.1193632\n```\n\n\n:::\n:::\n\n\n## `causal.decomp`\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# smi\nfit.y <- lm(Y ~ X + T2 + X:T2 + L1 + L2 + C1 + C2 + C3 + C4, data = d)\nfit.m <- glm(T2 ~ X + C1 + C2 + C3 + C4, data = d, family = binomial(link = \"logit\"))\n\nfit_smi_b <- smi(fit.y = fit.y,\n               fit.m = fit.m,\n               treat = \"X\", \n               sims = 100, \n               conf.level = .95,\n               conditional = TRUE,\n               # covariates = 1,\n               covariates = c(\"C1\", \"C2\", \"C3\", \"C4\"),\n               seed = 123456)\nfit_smi_b\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nResults:\n\n                                estimate 95% CI Lower 95% CI Upper\nInitial Disparity   (1 vs 4) -0.95667843  -1.02938841  -0.88175003\nDisparity Remaining (1 vs 4) -0.61262729  -0.77966809  -0.46844380\nDisparity Reduction (1 vs 4) -0.34405113  -0.49650368  -0.21581205\nInitial Disparity   (1 vs 2) -0.31394841  -0.38058533  -0.26000373\nDisparity Remaining (1 vs 2) -0.27995004  -0.34624791  -0.22226331\nDisparity Reduction (1 vs 2) -0.03399837  -0.05003528  -0.02022012\nInitial Disparity   (1 vs 3) -0.59968604  -0.69525994  -0.49987857\nDisparity Remaining (1 vs 3) -0.48148718  -0.61387973  -0.32105036\nDisparity Reduction (1 vs 3) -0.11819886  -0.24676548  -0.03361808\n```\n\n\n:::\n\n```{.r .cell-code}\nsensRes <- sensitivity(boot.res = fit_smi_b, \n                       fit.m = fit.m, \n                       fit.y = fit.y, \n                       mediator = \"T2\",\n                       covariates = c(\"C1\", \"C2\", \"C3\", \"C4\"), \n                       treat = \"X\",\n                       sel.lev.treat = \"4\", \n                       max.rsq = 0.3)\nplot(sensRes)\n```\n\n::: {.cell-output-display}\n![](Causal_Decomposition_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n## `gapclosing`\n\n- @Lundberg2022a\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# gapclosing - regression\n# stochastic intervention\n# treatmentの割り当て確率の予測値を算出\nfit_glm <- glm(T2 ~ X + C1 + C2 + C3, data = d, family = binomial(link = \"logit\"))\n\n# 全員のtreatmentが1だった時の予測値\nassing_prob <- predict(fit_glm, newdata = d |> mutate(X = \"1\"), type = \"response\")\n\n# 予測値をもとにrandom draw\ndraw <- rbinom(n = nrow(d), size = 1, prob = assing_prob)\n\nfit_gapclosing <- \n  gapclosing(\n    data = d |> mutate(T2 = as.numeric(T2) - 1),\n    outcome_formula = Y ~ T2 * X + C1 + C2 + C3 + C4 + L1 + L2,\n    treatment_name = \"T2\",\n    category_name = \"X\",\n    counterfactual_assignments = draw # random draw\n  )\n\nfit_gapclosing\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nFactual mean outcomes:\n# A tibble: 4 × 2\n  X     estimate\n  <fct>    <dbl>\n1 1         7.60\n2 4         6.70\n3 2         7.32\n4 3         6.98\n\nCounterfactual mean outcomes (post-intervention means):\n# A tibble: 4 × 2\n  X     estimate\n  <fct>    <dbl>\n1 1         7.60\n2 4         7.03\n3 2         7.36\n4 3         7.11\n\nFactual disparities:\n# A tibble: 12 × 2\n   X     estimate\n   <chr>    <dbl>\n 1 1 - 4    0.899\n 2 1 - 2    0.275\n 3 1 - 3    0.614\n 4 4 - 1   -0.899\n 5 4 - 2   -0.624\n 6 4 - 3   -0.286\n 7 2 - 1   -0.275\n 8 2 - 4    0.624\n 9 2 - 3    0.339\n10 3 - 1   -0.614\n11 3 - 4    0.286\n12 3 - 2   -0.339\n\nCounterfactual disparities (gap-closing estimands):\n# A tibble: 12 × 2\n   X     estimate\n   <chr>    <dbl>\n 1 1 - 4   0.566 \n 2 1 - 2   0.241 \n 3 1 - 3   0.483 \n 4 4 - 1  -0.566 \n 5 4 - 2  -0.325 \n 6 4 - 3  -0.0830\n 7 2 - 1  -0.241 \n 8 2 - 4   0.325 \n 9 2 - 3   0.242 \n10 3 - 1  -0.483 \n11 3 - 4   0.0830\n12 3 - 2  -0.242 \n\nAdditive gap closed: Counterfactual - Factual\n# A tibble: 12 × 2\n   X     estimate\n   <chr>    <dbl>\n 1 1 - 4   0.334 \n 2 1 - 2   0.0339\n 3 1 - 3   0.131 \n 4 4 - 1  -0.334 \n 5 4 - 2  -0.300 \n 6 4 - 3  -0.203 \n 7 2 - 1  -0.0339\n 8 2 - 4   0.300 \n 9 2 - 3   0.0972\n10 3 - 1  -0.131 \n11 3 - 4   0.203 \n12 3 - 2  -0.0972\n\nProportional gap closed: (Counterfactual - Factual) / Factual\n# A tibble: 12 × 2\n   X     estimate\n   <chr>    <dbl>\n 1 1 - 4    0.371\n 2 1 - 2    0.123\n 3 1 - 3    0.214\n 4 4 - 1    0.371\n 5 4 - 2    0.480\n 6 4 - 3    0.710\n 7 2 - 1    0.123\n 8 2 - 4    0.480\n 9 2 - 3    0.287\n10 3 - 1    0.214\n11 3 - 4    0.710\n12 3 - 2    0.287\n```\n\n\n:::\n\n```{.r .cell-code}\ndisparityplot(fit_gapclosing, category_A = \"1\", category_B = \"4\")\n```\n\n::: {.cell-output-display}\n![](Causal_Decomposition_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n\n```{.r .cell-code}\ndisparityplot(fit_gapclosing, category_A = \"1\", category_B = \"2\")\n```\n\n::: {.cell-output-display}\n![](Causal_Decomposition_files/figure-html/unnamed-chunk-8-2.png){width=672}\n:::\n\n```{.r .cell-code}\ndisparityplot(fit_gapclosing, category_A = \"1\", category_B = \"3\")\n```\n\n::: {.cell-output-display}\n![](Causal_Decomposition_files/figure-html/unnamed-chunk-8-3.png){width=672}\n:::\n:::\n\n\n- 機械学習をつかったdoubly robustな方法も使える\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# gapclosing - ranger, doubly robust\nfit_gapclosing_ranger <- \n  gapclosing(\n  data = d |> mutate(T2 = as.numeric(T2) - 1),\n  outcome_formula = Y ~ T2 + X + C1 + C2 + C3 + C4 + L1 + L2,\n  treatment_formula = T2 ~ X + C1 + C2 + C3 + C4 + L1 + L2, \n  treatment_name = \"T2\",\n  treatment_algorithm = \"ranger\",\n  outcome_algorithm = \"ranger\",\n  category_name = \"X\",\n  counterfactual_assignments = rbinom(n = nrow(d), size = 1, prob = assing_prob) \n)\n\nfit_gapclosing\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nFactual mean outcomes:\n# A tibble: 4 × 2\n  X     estimate\n  <fct>    <dbl>\n1 1         7.60\n2 4         6.70\n3 2         7.32\n4 3         6.98\n\nCounterfactual mean outcomes (post-intervention means):\n# A tibble: 4 × 2\n  X     estimate\n  <fct>    <dbl>\n1 1         7.60\n2 4         7.03\n3 2         7.36\n4 3         7.11\n\nFactual disparities:\n# A tibble: 12 × 2\n   X     estimate\n   <chr>    <dbl>\n 1 1 - 4    0.899\n 2 1 - 2    0.275\n 3 1 - 3    0.614\n 4 4 - 1   -0.899\n 5 4 - 2   -0.624\n 6 4 - 3   -0.286\n 7 2 - 1   -0.275\n 8 2 - 4    0.624\n 9 2 - 3    0.339\n10 3 - 1   -0.614\n11 3 - 4    0.286\n12 3 - 2   -0.339\n\nCounterfactual disparities (gap-closing estimands):\n# A tibble: 12 × 2\n   X     estimate\n   <chr>    <dbl>\n 1 1 - 4   0.566 \n 2 1 - 2   0.241 \n 3 1 - 3   0.483 \n 4 4 - 1  -0.566 \n 5 4 - 2  -0.325 \n 6 4 - 3  -0.0830\n 7 2 - 1  -0.241 \n 8 2 - 4   0.325 \n 9 2 - 3   0.242 \n10 3 - 1  -0.483 \n11 3 - 4   0.0830\n12 3 - 2  -0.242 \n\nAdditive gap closed: Counterfactual - Factual\n# A tibble: 12 × 2\n   X     estimate\n   <chr>    <dbl>\n 1 1 - 4   0.334 \n 2 1 - 2   0.0339\n 3 1 - 3   0.131 \n 4 4 - 1  -0.334 \n 5 4 - 2  -0.300 \n 6 4 - 3  -0.203 \n 7 2 - 1  -0.0339\n 8 2 - 4   0.300 \n 9 2 - 3   0.0972\n10 3 - 1  -0.131 \n11 3 - 4   0.203 \n12 3 - 2  -0.0972\n\nProportional gap closed: (Counterfactual - Factual) / Factual\n# A tibble: 12 × 2\n   X     estimate\n   <chr>    <dbl>\n 1 1 - 4    0.371\n 2 1 - 2    0.123\n 3 1 - 3    0.214\n 4 4 - 1    0.371\n 5 4 - 2    0.480\n 6 4 - 3    0.710\n 7 2 - 1    0.123\n 8 2 - 4    0.480\n 9 2 - 3    0.287\n10 3 - 1    0.214\n11 3 - 4    0.710\n12 3 - 2    0.287\n```\n\n\n:::\n\n```{.r .cell-code}\ndisparityplot(fit_gapclosing_ranger, category_A = \"1\", category_B = \"4\")\n```\n\n::: {.cell-output-display}\n![](Causal_Decomposition_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n\n```{.r .cell-code}\ndisparityplot(fit_gapclosing_ranger, category_A = \"1\", category_B = \"2\")\n```\n\n::: {.cell-output-display}\n![](Causal_Decomposition_files/figure-html/unnamed-chunk-9-2.png){width=672}\n:::\n\n```{.r .cell-code}\ndisparityplot(fit_gapclosing_ranger, category_A = \"1\", category_B = \"3\")\n```\n\n::: {.cell-output-display}\n![](Causal_Decomposition_files/figure-html/unnamed-chunk-9-3.png){width=672}\n:::\n:::\n",
    "supporting": [
      "Causal_Decomposition_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}