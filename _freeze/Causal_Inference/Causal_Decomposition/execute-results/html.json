{
  "hash": "7aa9c56aae3f7ef3fb0c0658751bea7a",
  "result": {
    "markdown": "---\ntitle: \"Causal Decomposition Analysis\"\n---\n\n\n## 前準備\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(cfdecomp)\nlibrary(gapclosing)\nlibrary(causal.decomp)\n\n\nd <- \n  sMIDUS |> \n  transmute(Y = health |> as.numeric(),  # outcome\n            T = edu |> as.numeric(),   # treatment (continuous)\n            T2 = edu |> case_match(4:6 ~ 0,   # treatment (binary)\n                                   7:9 ~ 1,\n                                   .default = NA) |> factor(),\n            X = racesex |> factor(levels = c(\"1\", \"4\", \"2\", \"3\")),  # note!\n            L1 = lowchildSES |> as.numeric(),\n            L2 = abuse |> as.numeric(),\n            C1 = age |> as.numeric(),\n            C2 = stroke |> as.numeric(),\n            C3 = T2DM |> as.numeric(),\n            C4 = heart |> as.numeric()) |> \n  mutate(across(L1:C4, \\(.x){.x - mean(.x, na.rm = TRUE)})) |> \n  tibble()\n```\n:::\n\n\n# continuuous mediator\n\n## `cfdecomp`\n\n- @Sudharsanan2021 の方法。mediatorの値をシミュレーションで複数生成するのが特徴\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# cfd.mean\nfit_cfdecomp <-\n  cfdecomp::cfd.mean(\n    formula.y = 'Y ~ X + T + X:T + L1 + L2 + C1 + C2 + C3 + C4',\n    formula.m = 'T ~ X + C1 + C2 + C3 + C4',\n    mediator = 'T',\n    group = 'X',\n    data = d |> data.frame(),\n    family.y = 'gaussian',\n    family.m = 'gaussian',\n    bs.size = 50,\n    mc.size = 10,\n    alpha = 0.05\n  )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_cfdecomp\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$out_nc_m\n          1        4        2        3\n1  7.704393 5.878511 7.100601 6.334574\n2  7.684907 5.893482 7.078147 6.504993\n3  7.667103 5.792513 7.064230 6.331297\n4  7.691473 5.832407 7.094649 6.448269\n5  7.702502 5.867025 7.084150 6.302879\n6  7.707649 5.881564 7.073169 6.348328\n7  7.698524 5.863295 7.094253 6.304080\n8  7.665428 5.934105 7.077088 6.393080\n9  7.687736 5.849997 7.069869 6.413267\n10 7.691149 5.867068 7.097231 6.395584\n11 7.717062 5.875149 7.083784 6.311631\n12 7.714051 5.841621 7.081830 6.427463\n13 7.720328 5.865250 7.084813 6.451981\n14 7.716165 5.781157 7.065282 6.483936\n15 7.701326 5.931750 7.110469 6.480753\n16 7.713160 5.909803 7.113075 6.471447\n17 7.717832 5.793296 7.100073 6.395649\n18 7.721109 5.873599 7.059873 6.346348\n19 7.706348 5.847319 7.067505 6.412451\n20 7.711646 5.830050 7.082999 6.401420\n21 7.692526 5.825116 7.072620 6.470432\n22 7.720256 5.818086 7.109367 6.362887\n23 7.687258 5.858049 7.071935 6.427542\n24 7.779983 5.917717 7.064179 6.440181\n25 7.687712 5.880672 7.070538 6.392827\n26 7.681760 5.874938 7.072690 6.387883\n27 7.723142 5.922137 7.074596 6.458075\n28 7.745995 5.868351 7.109323 6.394674\n29 7.675111 5.874267 7.080646 6.400481\n30 7.704231 5.869453 7.084789 6.438085\n31 7.703909 5.828574 7.069695 6.400884\n32 7.723633 5.923871 7.101306 6.442652\n33 7.704270 5.940003 7.073209 6.348928\n34 7.690021 5.863546 7.141164 6.350132\n35 7.713714 5.935156 7.068561 6.379914\n36 7.701639 5.803481 7.090905 6.380944\n37 7.663258 5.898129 7.065360 6.451323\n38 7.700254 5.880185 7.038593 6.495530\n39 7.740043 5.857458 7.052444 6.229921\n40 7.675637 5.903854 7.053284 6.370314\n41 7.720521 5.804465 7.127913 6.454960\n42 7.722971 5.832164 7.059062 6.404134\n43 7.718257 5.865445 7.110773 6.377804\n44 7.710481 5.916549 7.056362 6.351512\n45 7.693268 5.862944 7.063951 6.447388\n46 7.678086 5.846925 7.073370 6.380035\n47 7.723755 5.911177 7.075948 6.456036\n48 7.677894 5.949973 7.048513 6.405711\n49 7.718471 5.880965 7.061658 6.505462\n50 7.676996 5.882907 7.099679 6.596813\n\n$out_cf_m\n          1        4        2        3\n1  7.695237 7.698664 7.714275 7.698376\n2  7.692037 7.735170 7.708061 7.714884\n3  7.662060 7.669484 7.678900 7.629026\n4  7.692625 7.730004 7.692944 7.727442\n5  7.703100 7.676401 7.707583 7.680340\n6  7.692301 7.704222 7.711041 7.705918\n7  7.694546 7.747794 7.717056 7.698930\n8  7.662324 7.658380 7.681429 7.643902\n9  7.672684 7.694050 7.695842 7.699512\n10 7.666396 7.665698 7.676986 7.634029\n11 7.731539 7.728737 7.725253 7.689596\n12 7.718414 7.677185 7.721105 7.718532\n13 7.727804 7.725323 7.732888 7.713343\n14 7.700645 7.691775 7.700034 7.693086\n15 7.693895 7.700015 7.690966 7.660751\n16 7.705284 7.730238 7.701869 7.703176\n17 7.715922 7.735389 7.729652 7.730373\n18 7.729834 7.708581 7.740596 7.716448\n19 7.727479 7.681980 7.725371 7.715341\n20 7.718810 7.699963 7.723112 7.709143\n21 7.690483 7.710145 7.714376 7.704448\n22 7.710002 7.708093 7.729129 7.701050\n23 7.676221 7.676947 7.689312 7.657328\n24 7.786247 7.790737 7.794220 7.774169\n25 7.686563 7.700556 7.700895 7.692829\n26 7.685353 7.692371 7.698384 7.675953\n27 7.725504 7.745133 7.735270 7.716700\n28 7.747605 7.728458 7.759898 7.731043\n29 7.679783 7.643081 7.686112 7.665649\n30 7.704130 7.699832 7.720783 7.721398\n31 7.701701 7.710872 7.713634 7.678175\n32 7.735713 7.726618 7.730834 7.721670\n33 7.696643 7.697963 7.702217 7.712556\n34 7.704079 7.707784 7.701126 7.679178\n35 7.716738 7.713484 7.721166 7.720744\n36 7.702610 7.693181 7.710453 7.682322\n37 7.686079 7.703241 7.703538 7.694242\n38 7.695140 7.706969 7.701521 7.704428\n39 7.726793 7.741675 7.727676 7.697694\n40 7.670291 7.660500 7.683376 7.666899\n41 7.713675 7.707159 7.724040 7.713228\n42 7.723779 7.761976 7.739969 7.705372\n43 7.712476 7.713428 7.715712 7.685084\n44 7.704671 7.722937 7.717555 7.698043\n45 7.684617 7.724854 7.705855 7.684188\n46 7.700869 7.696082 7.695639 7.658616\n47 7.735210 7.731111 7.732692 7.722269\n48 7.690006 7.728187 7.703978 7.687452\n49 7.710897 7.730958 7.717505 7.715660\n50 7.684738 7.694305 7.692742 7.681102\n\n$out_nc_quantile_m\n             1        4        2        3\n2.5%  7.665805 5.792689 7.049397 6.303149\n50%   7.704251 5.868902 7.075272 6.401152\n97.5% 7.744656 5.938913 7.124575 6.505357\n\n$out_cf_quantile_m\n             1        4        2        3\n2.5%  7.663240 7.658857 7.679469 7.636250\n50%   7.702156 7.707471 7.712338 7.699221\n97.5% 7.744930 7.758785 7.755555 7.730893\n\n$out_nc_y\n          1        4        2        3\n1  7.609364 6.718684 7.341827 7.002085\n2  7.628486 6.719177 7.294239 7.052794\n3  7.595029 6.716448 7.336332 6.978392\n4  7.636489 6.711188 7.305312 6.893564\n5  7.579541 6.660990 7.316580 6.975759\n6  7.580596 6.700170 7.288052 6.998277\n7  7.595183 6.711373 7.332799 7.012144\n8  7.551420 6.644580 7.306586 7.013259\n9  7.582326 6.707404 7.296872 6.987075\n10 7.589799 6.677915 7.328206 6.971000\n11 7.614199 6.720911 7.339720 6.868702\n12 7.586114 6.689092 7.351506 7.026881\n13 7.622678 6.682343 7.325961 6.977455\n14 7.603960 6.650643 7.338078 7.110627\n15 7.579252 6.724402 7.317658 6.975170\n16 7.611930 6.774817 7.335448 6.945007\n17 7.585327 6.647768 7.341476 6.935480\n18 7.576620 6.666223 7.322488 6.842111\n19 7.575377 6.692609 7.320514 7.008304\n20 7.642213 6.704353 7.360568 6.919576\n21 7.578390 6.697662 7.305599 7.009812\n22 7.623193 6.667674 7.323701 6.975625\n23 7.603659 6.720316 7.327473 6.977863\n24 7.624144 6.785678 7.330341 6.934198\n25 7.591184 6.740607 7.296366 7.087310\n26 7.580709 6.697542 7.305766 6.971515\n27 7.596846 6.736814 7.309232 6.977437\n28 7.626346 6.705490 7.365605 6.953224\n29 7.588795 6.682027 7.350720 7.021670\n30 7.598572 6.671137 7.332563 7.050782\n31 7.663353 6.674185 7.316531 6.956455\n32 7.638913 6.654991 7.315467 6.943161\n33 7.583040 6.744792 7.315880 7.050680\n34 7.587131 6.745807 7.315240 7.040534\n35 7.629869 6.777861 7.320697 6.987942\n36 7.633211 6.690888 7.296936 7.042209\n37 7.586876 6.690698 7.304879 7.001249\n38 7.605630 6.641577 7.312473 7.054762\n39 7.578209 6.702098 7.346856 6.861277\n40 7.615791 6.693407 7.275010 6.904633\n41 7.619558 6.629054 7.335635 6.968320\n42 7.597071 6.722200 7.301024 6.909407\n43 7.653331 6.665569 7.320626 6.992004\n44 7.608243 6.725489 7.387248 7.060275\n45 7.563750 6.676142 7.308825 6.848430\n46 7.614122 6.674357 7.303363 6.924984\n47 7.596193 6.694495 7.306756 6.901427\n48 7.606979 6.738551 7.326250 7.075850\n49 7.593624 6.698417 7.340698 7.080536\n50 7.543299 6.771432 7.302208 6.976786\n\n$out_cf_y\n          1        4        2        3\n1  7.607414 7.241627 7.491580 7.233985\n2  7.629989 7.175883 7.438672 7.212483\n3  7.593847 7.247442 7.492807 7.189440\n4  7.636815 7.247154 7.413713 7.170191\n5  7.579692 7.455758 7.484690 7.201809\n6  7.576799 7.155861 7.400021 7.370657\n7  7.594346 7.214699 7.435885 7.201016\n8  7.550623 7.151088 7.492054 7.540559\n9  7.578009 7.233869 7.443912 7.093525\n10 7.584653 7.362574 7.447179 7.274074\n11 7.617740 7.272451 7.504440 7.298578\n12 7.587291 7.339500 7.496442 7.085919\n13 7.624523 7.385366 7.442322 7.356935\n14 7.599690 7.218713 7.469391 7.235977\n15 7.577244 7.383210 7.436937 7.392177\n16 7.609999 7.393361 7.470339 7.195733\n17 7.584932 7.420018 7.491768 7.261574\n18 7.578244 7.254377 7.458756 7.223458\n19 7.580229 7.269746 7.464720 7.195017\n20 7.643505 7.154219 7.509154 7.172263\n21 7.577978 7.352014 7.478805 7.269683\n22 7.620846 7.433312 7.479854 7.302266\n23 7.600740 7.173616 7.491643 7.306826\n24 7.625785 7.277016 7.473609 7.127676\n25 7.591045 7.274529 7.444616 7.291411\n26 7.581488 7.264959 7.465865 7.008815\n27 7.597288 7.414300 7.441858 7.187059\n28 7.626680 7.300014 7.496952 7.040814\n29 7.589927 7.158867 7.460670 7.154384\n30 7.598552 7.174590 7.487488 7.261998\n31 7.662883 7.166347 7.477567 7.374014\n32 7.641907 7.242302 7.487043 7.168227\n33 7.581495 7.313520 7.479004 7.389798\n34 7.590214 7.370308 7.474344 7.297419\n35 7.630770 7.325501 7.430298 7.332733\n36 7.633509 7.268941 7.415104 7.397309\n37 7.592106 7.105822 7.426028 7.199093\n38 7.604581 7.172293 7.460978 7.311739\n39 7.575793 7.168612 7.484473 7.132777\n40 7.614368 7.213674 7.416985 7.150848\n41 7.617792 7.227409 7.463862 7.133855\n42 7.597207 7.443558 7.387119 7.053380\n43 7.651733 7.302834 7.477593 7.174305\n44 7.606760 7.238119 7.544200 7.360466\n45 7.561765 7.197407 7.476156 7.196137\n46 7.621505 7.178989 7.430615 7.389787\n47 7.599247 7.233115 7.424585 7.335626\n48 7.610071 7.200206 7.495498 7.266563\n49 7.592124 7.159419 7.512929 7.217993\n50 7.545320 7.359588 7.435835 7.243914\n\n$out_nc_quantile_y\n             1        4        2        3\n2.5%  7.554194 6.642253 7.289444 6.851321\n50%   7.596958 6.698040 7.320570 6.977659\n97.5% 7.650829 6.777176 7.364472 7.085786\n\n$out_cf_quantile_y\n             1        4        2        3\n2.5%  7.553130 7.151793 7.403101 7.043642\n50%   7.597920 7.247298 7.469865 7.228721\n97.5% 7.649881 7.441253 7.512079 7.396155\n\n$mediation\n        4         2         3 \n0.6283431 0.5154469 0.4166421 \n\n$mediation_quantile\n              4         2         3\n2.5%  0.4836956 0.3327377 0.1110938\n97.5% 0.8243395 0.7036244 0.6867509\n\n$mc_conv_info_m\n          [,1]     [,2]     [,3]     [,4]\n [1,] 7.689496 5.829198 7.091873 6.309873\n [2,] 7.703785 5.850273 7.113070 6.306611\n [3,] 7.701987 5.858959 7.098913 6.314230\n [4,] 7.705048 5.868545 7.101568 6.324108\n [5,] 7.706593 5.870395 7.098734 6.339593\n [6,] 7.703159 5.875024 7.099050 6.323742\n [7,] 7.703515 5.879523 7.098054 6.317544\n [8,] 7.702621 5.878158 7.101698 6.315582\n [9,] 7.706594 5.879419 7.100027 6.332194\n[10,] 7.704393 5.878511 7.100601 6.334574\n\n$mc_conv_info_y\n          [,1]     [,2]     [,3]     [,4]\n [1,] 7.606192 6.704516 7.339697 6.997885\n [2,] 7.609234 6.710571 7.344870 6.997330\n [3,] 7.608851 6.713067 7.341415 6.998625\n [4,] 7.609503 6.715821 7.342063 7.000305\n [5,] 7.609832 6.716352 7.341372 7.002938\n [6,] 7.609101 6.717682 7.341449 7.000243\n [7,] 7.609177 6.718975 7.341206 6.999189\n [8,] 7.608986 6.718583 7.342095 6.998855\n [9,] 7.609832 6.718945 7.341687 7.001680\n[10,] 7.609364 6.718684 7.341827 7.002085\n```\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp$out_nc_y[,2] - fit_cfdecomp$out_nc_y[,1])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.9007578\n```\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp$out_cf_y[,2] - fit_cfdecomp$out_nc_y[,1])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.3357567\n```\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp$out_nc_y[,2] - fit_cfdecomp$out_cf_y[,2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.5650011\n```\n:::\n\n```{.r .cell-code}\nfit_cfdecomp$mediation\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        4         2         3 \n0.6283431 0.5154469 0.4166421 \n```\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp$out_nc_y[,3] - fit_cfdecomp$out_nc_y[,1])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.2795149\n```\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp$out_cf_y[,3] - fit_cfdecomp$out_nc_y[,1])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.1373915\n```\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp$out_nc_y[,3] - fit_cfdecomp$out_cf_y[,3])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.1421234\n```\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp$out_nc_y[,4] - fit_cfdecomp$out_nc_y[,1])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.6208383\n```\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp$out_cf_y[,4] - fit_cfdecomp$out_nc_y[,1])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.361873\n```\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp$out_nc_y[,4] - fit_cfdecomp$out_cf_y[,4])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.2589653\n```\n:::\n:::\n\n\n## `causal.decomp`\n\n- @Park2023a の方法。\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# smi \nfit.y <- lm(Y ~ X + T + X:T + L1 + L2 + C1 + C2 + C3 + C4, data = d)\nfit.m <- lm(T ~ X + C1 + C2 + C3 + C4, data = d)\n\nfit_smi <- smi(fit.y = fit.y,\n    fit.m = fit.m,\n    treat = \"X\", \n    sims = 100, \n    conf.level = .95,\n    conditional = TRUE,\n    covariates = 1,\n    # baseline covariatesを調整できる\n    #covariates = c(\"C1\", \"C2\", \"C3\", \"C4\"),\n    seed = 227,\n    )\n\nfit_smi\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nResults:\n\n                               estimate 95% CI Lower 95% CI Upper\nInitial Disparity   (1 vs 4) -0.8993401   -0.9925190  -0.79813505\nDisparity Remaining (1 vs 4) -0.3384430   -0.4880863  -0.14795873\nDisparity Reduction (1 vs 4) -0.5608971   -0.7346168  -0.42650061\nInitial Disparity   (1 vs 2) -0.2749659   -0.3378874  -0.19366549\nDisparity Remaining (1 vs 2) -0.1213246   -0.2203441  -0.05458727\nDisparity Reduction (1 vs 2) -0.1536412   -0.1896213  -0.10521328\nInitial Disparity   (1 vs 3) -0.6137425   -0.7326095  -0.47793913\nDisparity Remaining (1 vs 3) -0.3500123   -0.5151994  -0.08733348\nDisparity Reduction (1 vs 3) -0.2637302   -0.4880614  -0.11574038\n```\n:::\n:::\n\n\n- sensitivity analysis[@Park2023]\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsensRes <- sensitivity(boot.res = fit_smi, fit.m = fit.m, fit.y = fit.y, \n                       mediator = \"T\",\n                       covariates = c(\"C1\", \"C2\", \"C3\", \"C4\"), \n                       treat = \"X\",\n                       sel.lev.treat = \"4\", \n                       max.rsq = 0.3)\nplot(sensRes)\n```\n\n::: {.cell-output-display}\n![](Causal_Decomposition_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\n# binary mediator\n\n## `cfdecomp`\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# cfd.mean\nset.seed(123456)\nfit_cfdecomp_b <-\n  cfd.mean(\n    formula.y = 'Y ~ X + T2 + X:T2 + L1 + L2 + C1 + C2 + C3 + C4',\n    formula.m = 'T2 ~ X + C1 + C2 + C3 + C4',\n    mediator = 'T2',\n    group = 'X',\n    data = d |> mutate(T2 = as.numeric(T2) - 1) |> data.frame(),\n    family.y = 'gaussian',\n    family.m = 'binomial',\n    bs.size = 50,\n    mc.size = 10,\n    alpha = 0.05\n  )\nmean(fit_cfdecomp_b$out_nc_y[,\"4\"] - fit_cfdecomp_b$out_nc_y[,\"1\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.8981701\n```\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp_b$out_cf_y[,\"4\"] - fit_cfdecomp_b$out_nc_y[,\"1\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.5546351\n```\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp_b$out_nc_y[,\"4\"] - fit_cfdecomp_b$out_cf_y[,\"4\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.343535\n```\n:::\n\n```{.r .cell-code}\nfit_cfdecomp_b$mediation\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        4         2         3 \n0.3828971 0.1298177 0.2061071 \n```\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp_b$out_nc_y[,\"2\"] - fit_cfdecomp_b$out_nc_y[,\"1\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.2774845\n```\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp_b$out_cf_y[,\"2\"] - fit_cfdecomp_b$out_nc_y[,\"1\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.2419289\n```\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp_b$out_nc_y[,\"2\"] - fit_cfdecomp_b$out_cf_y[,\"2\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.03555558\n```\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp_b$out_nc_y[,\"3\"] - fit_cfdecomp_b$out_nc_y[,\"1\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.5849521\n```\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp_b$out_cf_y[,\"3\"] - fit_cfdecomp_b$out_nc_y[,\"1\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.4655888\n```\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp_b$out_nc_y[,\"3\"] - fit_cfdecomp_b$out_cf_y[,\"3\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.1193632\n```\n:::\n:::\n\n\n## `causal.decomp`\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# smi\nfit.y <- lm(Y ~ X + T2 + X:T2 + L1 + L2 + C1 + C2 + C3 + C4, data = d)\nfit.m <- glm(T2 ~ X + C1 + C2 + C3 + C4, data = d, family = binomial(link = \"logit\"))\n\nfit_smi_b <- smi(fit.y = fit.y,\n               fit.m = fit.m,\n               treat = \"X\", \n               sims = 100, \n               conf.level = .95,\n               conditional = TRUE,\n               # covariates = 1,\n               covariates = c(\"C1\", \"C2\", \"C3\", \"C4\"),\n               seed = 123456)\nfit_smi_b\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nResults:\n\n                                estimate 95% CI Lower 95% CI Upper\nInitial Disparity   (1 vs 4) -0.95667843  -1.02938841  -0.88175003\nDisparity Remaining (1 vs 4) -0.61262729  -0.77966809  -0.46844380\nDisparity Reduction (1 vs 4) -0.34405113  -0.49650368  -0.21581205\nInitial Disparity   (1 vs 2) -0.31394841  -0.38058533  -0.26000373\nDisparity Remaining (1 vs 2) -0.27995004  -0.34624791  -0.22226331\nDisparity Reduction (1 vs 2) -0.03399837  -0.05003528  -0.02022012\nInitial Disparity   (1 vs 3) -0.59968604  -0.69525994  -0.49987857\nDisparity Remaining (1 vs 3) -0.48148718  -0.61387973  -0.32105036\nDisparity Reduction (1 vs 3) -0.11819886  -0.24676548  -0.03361808\n```\n:::\n\n```{.r .cell-code}\nsensRes <- sensitivity(boot.res = fit_smi_b, \n                       fit.m = fit.m, \n                       fit.y = fit.y, \n                       mediator = \"T2\",\n                       covariates = c(\"C1\", \"C2\", \"C3\", \"C4\"), \n                       treat = \"X\",\n                       sel.lev.treat = \"4\", \n                       max.rsq = 0.3)\nplot(sensRes)\n```\n\n::: {.cell-output-display}\n![](Causal_Decomposition_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n## `gapclosing`\n\n- @Lundberg2022a\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# gapclosing - regression\n# stochastic intervention\n# treatmentの割り当て確率の予測値を算出\nfit_glm <- glm(T2 ~ X + C1 + C2 + C3, data = d, family = binomial(link = \"logit\"))\n\n# 全員のtreatmentが1だった時の予測値\nassing_prob <- predict(fit_glm, newdata = d |> mutate(X = \"1\"), type = \"response\")\n\n# 予測値をもとにrandom draw\ndraw <- rbinom(n = nrow(d), size = 1, prob = assing_prob)\n\nfit_gapclosing <- \n  gapclosing(\n    data = d |> mutate(T2 = as.numeric(T2) - 1),\n    outcome_formula = Y ~ T2 * X + C1 + C2 + C3 + C4 + L1 + L2,\n    treatment_name = \"T2\",\n    category_name = \"X\",\n    counterfactual_assignments = draw # random draw\n  )\n\nfit_gapclosing\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nFactual mean outcomes:\n# A tibble: 4 × 2\n  X     estimate\n  <fct>    <dbl>\n1 1         7.60\n2 4         6.70\n3 2         7.32\n4 3         6.98\n\nCounterfactual mean outcomes (post-intervention means):\n# A tibble: 4 × 2\n  X     estimate\n  <fct>    <dbl>\n1 1         7.60\n2 4         7.03\n3 2         7.36\n4 3         7.11\n\nFactual disparities:\n# A tibble: 12 × 2\n   X     estimate\n   <chr>    <dbl>\n 1 1 - 4    0.899\n 2 1 - 2    0.275\n 3 1 - 3    0.614\n 4 4 - 1   -0.899\n 5 4 - 2   -0.624\n 6 4 - 3   -0.286\n 7 2 - 1   -0.275\n 8 2 - 4    0.624\n 9 2 - 3    0.339\n10 3 - 1   -0.614\n11 3 - 4    0.286\n12 3 - 2   -0.339\n\nCounterfactual disparities (gap-closing estimands):\n# A tibble: 12 × 2\n   X     estimate\n   <chr>    <dbl>\n 1 1 - 4   0.566 \n 2 1 - 2   0.241 \n 3 1 - 3   0.483 \n 4 4 - 1  -0.566 \n 5 4 - 2  -0.325 \n 6 4 - 3  -0.0830\n 7 2 - 1  -0.241 \n 8 2 - 4   0.325 \n 9 2 - 3   0.242 \n10 3 - 1  -0.483 \n11 3 - 4   0.0830\n12 3 - 2  -0.242 \n\nAdditive gap closed: Counterfactual - Factual\n# A tibble: 12 × 2\n   X     estimate\n   <chr>    <dbl>\n 1 1 - 4   0.334 \n 2 1 - 2   0.0339\n 3 1 - 3   0.131 \n 4 4 - 1  -0.334 \n 5 4 - 2  -0.300 \n 6 4 - 3  -0.203 \n 7 2 - 1  -0.0339\n 8 2 - 4   0.300 \n 9 2 - 3   0.0972\n10 3 - 1  -0.131 \n11 3 - 4   0.203 \n12 3 - 2  -0.0972\n\nProportional gap closed: (Counterfactual - Factual) / Factual\n# A tibble: 12 × 2\n   X     estimate\n   <chr>    <dbl>\n 1 1 - 4    0.371\n 2 1 - 2    0.123\n 3 1 - 3    0.214\n 4 4 - 1    0.371\n 5 4 - 2    0.480\n 6 4 - 3    0.710\n 7 2 - 1    0.123\n 8 2 - 4    0.480\n 9 2 - 3    0.287\n10 3 - 1    0.214\n11 3 - 4    0.710\n12 3 - 2    0.287\n```\n:::\n\n```{.r .cell-code}\ndisparityplot(fit_gapclosing, category_A = \"1\", category_B = \"4\")\n```\n\n::: {.cell-output-display}\n![](Causal_Decomposition_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n\n```{.r .cell-code}\ndisparityplot(fit_gapclosing, category_A = \"1\", category_B = \"2\")\n```\n\n::: {.cell-output-display}\n![](Causal_Decomposition_files/figure-html/unnamed-chunk-8-2.png){width=672}\n:::\n\n```{.r .cell-code}\ndisparityplot(fit_gapclosing, category_A = \"1\", category_B = \"3\")\n```\n\n::: {.cell-output-display}\n![](Causal_Decomposition_files/figure-html/unnamed-chunk-8-3.png){width=672}\n:::\n:::\n\n\n- 機械学習をつかったdoubly robustな方法も使える\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# gapclosing - ranger, doubly robust\nfit_gapclosing_ranger <- \n  gapclosing(\n  data = d |> mutate(T2 = as.numeric(T2) - 1),\n  outcome_formula = Y ~ T2 + X + C1 + C2 + C3 + C4 + L1 + L2,\n  treatment_formula = T2 ~ X + C1 + C2 + C3 + C4 + L1 + L2, \n  treatment_name = \"T2\",\n  treatment_algorithm = \"ranger\",\n  outcome_algorithm = \"ranger\",\n  category_name = \"X\",\n  counterfactual_assignments = rbinom(n = nrow(d), size = 1, prob = assing_prob) \n)\n\nfit_gapclosing\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nFactual mean outcomes:\n# A tibble: 4 × 2\n  X     estimate\n  <fct>    <dbl>\n1 1         7.60\n2 4         6.70\n3 2         7.32\n4 3         6.98\n\nCounterfactual mean outcomes (post-intervention means):\n# A tibble: 4 × 2\n  X     estimate\n  <fct>    <dbl>\n1 1         7.60\n2 4         7.03\n3 2         7.36\n4 3         7.11\n\nFactual disparities:\n# A tibble: 12 × 2\n   X     estimate\n   <chr>    <dbl>\n 1 1 - 4    0.899\n 2 1 - 2    0.275\n 3 1 - 3    0.614\n 4 4 - 1   -0.899\n 5 4 - 2   -0.624\n 6 4 - 3   -0.286\n 7 2 - 1   -0.275\n 8 2 - 4    0.624\n 9 2 - 3    0.339\n10 3 - 1   -0.614\n11 3 - 4    0.286\n12 3 - 2   -0.339\n\nCounterfactual disparities (gap-closing estimands):\n# A tibble: 12 × 2\n   X     estimate\n   <chr>    <dbl>\n 1 1 - 4   0.566 \n 2 1 - 2   0.241 \n 3 1 - 3   0.483 \n 4 4 - 1  -0.566 \n 5 4 - 2  -0.325 \n 6 4 - 3  -0.0830\n 7 2 - 1  -0.241 \n 8 2 - 4   0.325 \n 9 2 - 3   0.242 \n10 3 - 1  -0.483 \n11 3 - 4   0.0830\n12 3 - 2  -0.242 \n\nAdditive gap closed: Counterfactual - Factual\n# A tibble: 12 × 2\n   X     estimate\n   <chr>    <dbl>\n 1 1 - 4   0.334 \n 2 1 - 2   0.0339\n 3 1 - 3   0.131 \n 4 4 - 1  -0.334 \n 5 4 - 2  -0.300 \n 6 4 - 3  -0.203 \n 7 2 - 1  -0.0339\n 8 2 - 4   0.300 \n 9 2 - 3   0.0972\n10 3 - 1  -0.131 \n11 3 - 4   0.203 \n12 3 - 2  -0.0972\n\nProportional gap closed: (Counterfactual - Factual) / Factual\n# A tibble: 12 × 2\n   X     estimate\n   <chr>    <dbl>\n 1 1 - 4    0.371\n 2 1 - 2    0.123\n 3 1 - 3    0.214\n 4 4 - 1    0.371\n 5 4 - 2    0.480\n 6 4 - 3    0.710\n 7 2 - 1    0.123\n 8 2 - 4    0.480\n 9 2 - 3    0.287\n10 3 - 1    0.214\n11 3 - 4    0.710\n12 3 - 2    0.287\n```\n:::\n\n```{.r .cell-code}\ndisparityplot(fit_gapclosing_ranger, category_A = \"1\", category_B = \"4\")\n```\n\n::: {.cell-output-display}\n![](Causal_Decomposition_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n\n```{.r .cell-code}\ndisparityplot(fit_gapclosing_ranger, category_A = \"1\", category_B = \"2\")\n```\n\n::: {.cell-output-display}\n![](Causal_Decomposition_files/figure-html/unnamed-chunk-9-2.png){width=672}\n:::\n\n```{.r .cell-code}\ndisparityplot(fit_gapclosing_ranger, category_A = \"1\", category_B = \"3\")\n```\n\n::: {.cell-output-display}\n![](Causal_Decomposition_files/figure-html/unnamed-chunk-9-3.png){width=672}\n:::\n:::\n",
    "supporting": [
      "Causal_Decomposition_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}