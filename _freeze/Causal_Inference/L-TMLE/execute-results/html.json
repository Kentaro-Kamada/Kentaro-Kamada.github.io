{
  "hash": "87b017dcb90a59f4594e0c3efe0f3ff0",
  "result": {
    "markdown": "---\ntitle: \"Longitudinal TMLE\"\nexecute: \n  cache: true\n---\n\n\n# 複数時点での介入の因果効果の推定\n\n@Hernan2020 では、TMLEは時間依存交絡などに対処するG-Methodの一般化として提示されている。ここでは`ltmle`パッケージを用いた時間依存交絡への対処を中心に記述する。\n\n## 下準備\n\n### ライブラリなど\n\n\n\n::: {.cell hash='L-TMLE_cache/html/unnamed-chunk-1_165a6d97e82bcfdc3b73704de4c5a46b'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(SuperLearner)\nlibrary(ltmle)\nlibrary(randomForest)\nlibrary(ggdag)\nlibrary(future)\n\noptions(mc.cores = 8)\nplan(strategy = 'multisession')\n\nset.seed(95)\n```\n:::\n\n\n\n### データの作成\n\n以下のDAGを考える\n\n\n::: {.cell hash='L-TMLE_cache/html/unnamed-chunk-2_1ae81b5b2a881df02cbfbd2eed4e5cb0'}\n\n```{.r .cell-code}\ndagify(\n  L1 ~ A0 + U1,\n  A1 ~ A0 + L1,\n  Y ~ U1,\n  exposure = c('A0', 'A1'), \n  outcome = 'Y', \n  coords = list(x = c(A0 = 0, L1 = 1, A1 = 2, U1 = 1, Y = 3),\n                y = c(A0 = 0, L1 = 0, A1 = 0, U1 = -1, Y = 0))\n) %>% \n  ggdag()+\n  theme_dag()\n```\n\n::: {.cell-output-display}\n![](L-TMLE_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nTreatmentはA0とA1であるが、ここからYへのpathはないので、因果効果は全ての組み合わせについて0になる\n\n具体的には、potential outcomeのすべての組み合わせについて、差分を取った値が0になる\n\n\\begin{eqnarray}\n\\mathrm{E}[Y^{0, 0} - Y^{1, 0}] &= 0\\\\ \n\\mathrm{E}[Y^{0, 0} - Y^{0, 1}] &= 0\\\\\n\\mathrm{E}[Y^{0, 0} - Y^{1, 1}] &= 0\\\\\n\\mathrm{E}[Y^{1, 0} - Y^{0, 1}] &= 0\\\\\n\\mathrm{E}[Y^{1, 0} - Y^{1, 1}] &= 0\\\\\n\\mathrm{E}[Y^{0, 1} - Y^{1, 1}] &= 0\n\\end{eqnarray}\n\n\n\n::: {.cell hash='L-TMLE_cache/html/unnamed-chunk-3_607046d5c8fe5016c5c84c3a11206643'}\n\n```{.r .cell-code}\ngenerate_data <- function(n){ \n    A0 <- rbinom(n, size=1, prob=0.3) # binary treatment\n    U1 <- rnorm(n, mean = 0, sd = 1) # latent continuous confounder\n    L1 <- 0.1 + 0.3*A0 + 0.3*U1 + rnorm(n, sd = 0.1)\n    A1 <- rbinom(n, size=1, prob = plogis(-0.2 + 0.3*L1 + 0.02*L1^2)) # binary treatment\n    Y <- -0.2 + 0.5*U1 + rnorm(n, sd = 0.1) # continuous outcome depends on confounders\n    return(tibble(Y, A0, A1, L1, U1))\n}\n\ndata_obs <- generate_data(1000)\n```\n:::\n\n\nA0の因果効果\n\n\n::: {.cell hash='L-TMLE_cache/html/unnamed-chunk-4_15739f75a23ce246ed4ff97adcfbb76c'}\n\n```{.r .cell-code}\ndata_obs %>% \n  lm(Y ~ A0, data = .) %>% \n  summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Y ~ A0, data = .)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.0295 -0.3631  0.0081  0.3323  1.8426 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -0.20740    0.01898 -10.925   <2e-16 ***\nA0           0.02873    0.03575   0.804    0.422    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5087 on 998 degrees of freedom\nMultiple R-squared:  0.0006469,\tAdjusted R-squared:  -0.0003545 \nF-statistic: 0.646 on 1 and 998 DF,  p-value: 0.4217\n```\n:::\n:::\n\n\n- collider bias\n\n$L_1$を条件づけると、$A_0 \\to L_1 \\gets U_1 \\to Y$というパスが開いて、バイアスをもたらす\n\n\n::: {.cell hash='L-TMLE_cache/html/unnamed-chunk-5_893437105b26438e847c74c1bf6b67fa'}\n\n```{.r .cell-code}\ndata_obs %>% \n  lm(Y ~ A0 + L1, data = .) %>% \n  summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Y ~ A0 + L1, data = .)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.55477 -0.13977 -0.00681  0.12914  0.54753 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -0.352169   0.007096  -49.63   <2e-16 ***\nA0          -0.469341   0.014311  -32.80   <2e-16 ***\nL1           1.539818   0.018919   81.39   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1841 on 997 degrees of freedom\nMultiple R-squared:  0.8693,\tAdjusted R-squared:  0.869 \nF-statistic:  3315 on 2 and 997 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n::: {.cell hash='L-TMLE_cache/html/unnamed-chunk-6_be830ef76feb469fa78e0bdfe4f78ff8'}\n\n```{.r .cell-code}\ndata_obs %>% \n  lm(Y ~ A0*A1, data = .) %>% \n  summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Y ~ A0 * A1, data = .)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.01955 -0.36365  0.00781  0.33180  1.85253 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -0.21730    0.02598  -8.364   <2e-16 ***\nA0           0.04341    0.05053   0.859    0.390    \nA1           0.02128    0.03809   0.559    0.576    \nA0:A1       -0.03064    0.07162  -0.428    0.669    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5091 on 996 degrees of freedom\nMultiple R-squared:  0.0009839,\tAdjusted R-squared:  -0.002025 \nF-statistic: 0.327 on 3 and 996 DF,  p-value: 0.8059\n```\n:::\n:::\n\n\n\n## IPW\n\n@Hernan2020 にて紹介されている方法\n\n以下のウェイトを作成する\n\n$$\nW^{A_0, A_1} = \\frac{1}{f(A_0 | L_0)} \\times \\frac{1}{f(A_1 | A_0, L_0, L_1)}\n$$\n\n今回はベースライン共変量がない（$L_0 = \\varnothing$）ので\n\n$$\nW^{A_0, A_1} = \\frac{1}{f(A_0)} \\times \\frac{1}{f(A_1 | A_0, L_1)}\n$$\n\n\n::: {.cell hash='L-TMLE_cache/html/unnamed-chunk-7_09f7a707e0f19d059f6b1b105f23a5a4'}\n\n```{.r .cell-code}\nres_ipw <- \n  broom::augment_columns(\n    glm(A0 ~ 1, data = data_obs, family = 'binomial'), \n    data = data_obs, \n    type.predict = 'response'\n  ) %>% \n  # A0に対するウェイト\n  mutate(\n    ipw_A0 = case_when(A0 == 1 ~ 1 / .fitted,\n                       A0 == 0 ~ 1 / (1 - .fitted))\n  ) %>% \n  select(Y:U1, ipw_A0) %>% \n  broom::augment_columns(\n    glm(A1 ~ A0 + L1 + I(L1^2), data = data_obs, family = 'binomial'),\n    data = .,\n    type.predict = 'response'\n  ) %>% \n  mutate(\n    # A1に対するウェイト\n    ipw_A1 = case_when(A1 == 1 ~ 1 / .fitted,\n                       A1 == 0 ~ 1 / (1 - .fitted))\n  ) %>% \n  select(Y:U1, ipw_A0, ipw_A1) %>% \n  # A0に対するウェイトとA1に対するウェイトをかけ算\n  mutate(ipw = ipw_A0*ipw_A1) %>% \n  # 重み付け推定\n  summarise(CFmean = weighted.mean(Y, ipw), .by = c(A0, A1)) %>% \n  arrange(A0, A1)\n```\n:::\n\n\nipwによる各treatment strategyにおけるcounterfactual mean\n\n\n::: {.cell hash='L-TMLE_cache/html/unnamed-chunk-8_0988268ef5d1dc667d3b9d622ce7155e'}\n\n```{.r .cell-code}\nres_ipw\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 × 3\n     A0    A1 CFmean\n  <int> <int>  <dbl>\n1     0     0 -0.208\n2     0     1 -0.207\n3     1     0 -0.166\n4     1     1 -0.189\n```\n:::\n:::\n\n\ncounterfactual meanの差分\n\n\n::: {.cell hash='L-TMLE_cache/html/unnamed-chunk-9_3e98dd2cdbeeeaccc27876906af631b2'}\n\n```{.r .cell-code}\ncross_join(\n  res_ipw %>% \n    mutate(A0_A1 = str_c(A0, ',', A1)) %>% \n    select(A0_A1, CFmean),\n  res_ipw %>% \n    mutate(A0_A1 = str_c(A0, ',', A1)) %>% \n    select(A0_A1, CFmean)\n  ) %>% \n  filter(A0_A1.x != A0_A1.y) %>% \n  mutate(ATE = CFmean.y - CFmean.x)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 12 × 5\n   A0_A1.x CFmean.x A0_A1.y CFmean.y       ATE\n   <chr>      <dbl> <chr>      <dbl>     <dbl>\n 1 0,0       -0.208 0,1       -0.207  0.000654\n 2 0,0       -0.208 1,0       -0.166  0.0419  \n 3 0,0       -0.208 1,1       -0.189  0.0190  \n 4 0,1       -0.207 0,0       -0.208 -0.000654\n 5 0,1       -0.207 1,0       -0.166  0.0412  \n 6 0,1       -0.207 1,1       -0.189  0.0184  \n 7 1,0       -0.166 0,0       -0.208 -0.0419  \n 8 1,0       -0.166 0,1       -0.207 -0.0412  \n 9 1,0       -0.166 1,1       -0.189 -0.0229  \n10 1,1       -0.189 0,0       -0.208 -0.0190  \n11 1,1       -0.189 0,1       -0.207 -0.0184  \n12 1,1       -0.189 1,0       -0.166  0.0229  \n```\n:::\n:::\n\n\n\n## Longitudinal TMLE\n\n- `ltmle`による実装\n\n\n::: {.cell hash='L-TMLE_cache/html/unnamed-chunk-10_fe5d48f9994ccc9bd2633e24566c2ef6'}\n\n```{.r .cell-code}\nres_tmle <- \n  ltmle::ltmle(\n    # データセットの列の順番が大切\n    data = data_obs %>% select(A0, L1, A1, Y), \n    Anodes = c('A0', 'A1'), \n    Lnodes = 'L1',\n    Ynodes = 'Y',\n    abar = list(treatment = c(1, 1), control = c(0, 0)), \n    # Yrange = c(-100, 100), \n    SL.library = c('SL.glm', 'SL.gam', 'SL.randomForest')\n  )\n\n\nsummary(res_tmle)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEstimator:  tmle \nCall:\nltmle::ltmle(data = data_obs %>% select(A0, L1, A1, Y), Anodes = c(\"A0\", \n    \"A1\"), Lnodes = \"L1\", Ynodes = \"Y\", abar = list(treatment = c(1, \n    1), control = c(0, 0)), SL.library = c(\"SL.glm\", \"SL.gam\", \n    \"SL.randomForest\"))\n\nTreatment Estimate:\n   Parameter Estimate:  -0.17554 \n    Estimated Std Err:  0.033541 \n              p-value:  <2e-16 \n    95% Conf Interval: (-0.24128, -0.1098) \n\nControl Estimate:\n   Parameter Estimate:  -0.20361 \n    Estimated Std Err:  0.019777 \n              p-value:  <2e-16 \n    95% Conf Interval: (-0.24237, -0.16485) \n\nAdditive Treatment Effect:\n   Parameter Estimate:  0.028069 \n    Estimated Std Err:  0.038937 \n              p-value:  0.47099 \n    95% Conf Interval: (-0.048247, 0.10438) \n```\n:::\n:::\n\n\n\n\n## 他のパッケージ\n\n`ltmle`はメジャー（？）だが、あんまり汎用性が高いと言えず、開発も盛んなようには見えない。ほかにlongitudinal TMLEを実装しているパッケージとして[`lmtp`](https://github.com/nt-williams/lmtp)や[`stremr`](https://github.com/osofr/stremr)がある。`lmtp`はCRANにも登録してあり、試してみる価値あり。`stremr`はさまざまなアプローチの統合を目指す非常に意欲的なパッケージだが、開発は止まっている？っぽい。\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}