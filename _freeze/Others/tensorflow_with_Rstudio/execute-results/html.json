{
  "hash": "63924a68e810d086e6fbb9d546a7f859",
  "result": {
    "markdown": "---\ntitle: \"tensorflowをRstudioで\"\nengine: knitr\n---\n\n\npythonをRStudioで使うのは`reticulate`パッケージによりだいぶ楽になった。\n\nただpythonにおけるdeep learningの代表的パッケージである`tensorflow`をRStudioで使う際に少しつまづいたのでメモです。\n\n## pythonの環境をどうやって構築するか？\n\nRでは`renv`パッケージを使っている。ではpythonでは？\n\npythonはRよりも環境が複雑で変化も早そうなので、環境構築は重要。\n\n今回はpython公式が推奨しているっぽい`venv`を使う。\n\n:::{.callout-note}\n最初global環境でそのままやろうとしたが上手くいかず挫折。Dockerとかも有力だと思う。\n:::\n\n## venvを使って仮想環境を用意\n\n- pythonがインストールされているか確認\n  - homebrewなりでインストールしておく\n  - PATHを通しておく\n\n- 作業ディレクトリにて、terminalで以下のコマンドを実行し`.venv`フォルダを作成\n\n\n::: {.cell filename='terminal'}\n\n```{.bash .cell-code}\npython3 -m venv .venv\n```\n:::\n\n\n## pythonライブラリをインストール\n\n- 以下のコマンドを実行し、仮想環境を起動\n  - pythonの場所が`.venv`内のフォルダになっているのを確認\n\n\n::: {.cell filename='terminal'}\n\n```{.bash .cell-code}\nsource .venv/bin/activate\nwhich python\n```\n\n\n::: {.cell-output .cell-output-stdout}\n```\n/Users/kamaken/Documents/R/Project/Kentaro-Kamada/.venv/bin/python\n```\n:::\n:::\n\n\n:::{.callout-note}\n`source .venv/bin/activate`は、ライブラリをインストールするときは毎回実行する必要があります！\n\nまちがってglobal環境を汚さないように！\n:::\n\n- ライブラリをインストール\n  - `tensorflow`のほか、`numpy`も必須（`tensorflow`をインストールしたときに入る）\n  - M1 macでGPUを使いたい場合は`tensorflow-metal`もインストールする\n\n\n::: {.cell filename='terminal'}\n\n```{.bash .cell-code}\npip install tensorflow-macos\npip install tensorflow-metal\n```\n:::\n\n\n- 仮想環境を抜けるときは以下のコマンドを実行\n\n\n::: {.cell filename='terminal'}\n\n```{.bash .cell-code}\ndeactivate\n```\n:::\n\n\n\n## RStudioでpythonを使う\n\n### pythonの場所を指定\n\n- RStudioでpythonを使うには、RStudioにpythonの場所を教えてやる必要がある\n  - 今回は`.venv`内のpythonを使いたいので、作業ディレクトリに`.Rprofile`を作成し、以下のコードを書く\n\n\n::: {.cell filename='.Rprofile'}\n\n```{.r .cell-code}\nSys.setenv(RETICULATE_PYTHON = \".venv/bin/python\")\n```\n:::\n\n\n### pythonを起動\n\n- RStudioでpythonのコードを実行すると、`reticulate::repl_python()`が走ってコンソールがpythonになる\n\n\n::: {.cell filename='python'}\n\n```{.python .cell-code}\nimport sys\nprint(sys.version)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n3.11.7 (main, Dec  4 2023, 18:10:11) [Clang 15.0.0 (clang-1500.1.0.2.5)]\n```\n:::\n:::\n\n\n- tensorflowを起動して、GPUが使えるかを確認\n- physical_deviceでCPUとGPUの両方が表示されてればOK\n\n\n::: {.cell filename='python'}\n\n```{.python .cell-code}\nimport tensorflow as tf\ntf.config.list_physical_devices()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n```\n:::\n:::\n\n\n## ニューラルネットをやってみる\n\n- チュートリアルとして、手書きのアルファベットを分類するモデルを作成してみる\n- Rでデータを読み込んで、pythonに渡して`tensorflow`で分析\n- [参考](https://ai.stanford.edu/~btaskar/ocr/)\n\n\n::: {.cell filename='R'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(rsample)\nlibrary(reticulate)\n```\n:::\n\n\n\n### データのダウンロード\n\n\n::: {.cell filename='R'}\n\n```{.r .cell-code}\n# データのダウンロード\nif (!dir.exists('data')) dir.create('data')\ndownload.file('https://ai.stanford.edu/~btaskar/ocr/letter.data.gz', destfile = 'data/letter.data')\n```\n:::\n\n\n### データの読み込み\n\n- 列名は[https://ai.stanford.edu/~btaskar/ocr/letter.names](https://ai.stanford.edu/~btaskar/ocr/letter.names)より取得できる\n- 詳細は以下の通り\n  1. id: each letter is assigned a unique integer id\n  1. letter: a-z\n  1. next_id: id for next letter in the word, -1 if last letter\n  1. word_id: each word is assigned a unique integer id (not used)\n  1. position: position of letter in the word (not used)\n  1. fold: 0-9 -- cross-validation fold\n  1. p_i_j: 0/1 -- value of pixel in row i, column j\n- letterとp_i_j（pixel）のみ使うのでそれ以外は削除\n\n\n::: {.cell filename='R'}\n\n```{.r .cell-code}\ncolname <- read_lines('https://ai.stanford.edu/~btaskar/ocr/letter.names')\ndata <- \n  read_tsv('data/letter.data', col_names = colname) |> \n  # letterとpixelだけ残す\n  select(id, letter, matches('p_\\\\d+_\\\\d+'))\n```\n:::\n\n\n### データの前処理\n\n- letterを数値に変換\n\n\n::: {.cell filename='R'}\n\n```{.r .cell-code}\ndf <- \n  data |> \n  mutate(\n    letter = factor(letter),\n    # pythonは0からはじまるので-1する（Rは1から）\n    letter_num = as.numeric(letter) - 1\n  )\n```\n:::\n\n\n- 訓練データとテストデータに分割\n\n\n::: {.cell filename='R'}\n\n```{.r .cell-code}\nsplit <- rsample::initial_split(df, prop = 0.8)\ntrain <- rsample::training(split)\ntest <- rsample::testing(split)\n```\n:::\n\n\n- pythonに渡せる形にデータを変換\n  - `reticulate::np_array()`であらかじめ`ndarray`にしておくと便利\n\n\n::: {.cell filename='R'}\n\n```{.r .cell-code}\ntrain_x <- \n  train |> \n  select(!c(id, letter, letter_num)) |>\n  as.matrix() |> \n  np_array()\n\ntrain_y <-\n  train |>\n  pull(letter_num) |>\n  np_array()\n\ntest_x <-\n  test |> \n  select(!c(id, letter, letter_num)) |>\n  as.matrix() |> \n  np_array()\n\ntest_y <-\n  test |>\n  pull(letter_num) |>\n  np_array()\n```\n:::\n\n\n\n### ニューラルネットで学習\n\n- 中間層が1つのニューラルネットを作成\n  - 入力層は16x8=128（ピクセル）\n  - 中間層は64次元\n  - 出力層はa-zの26分類\n\n\n::: {.cell filename='python'}\n\n```{.python .cell-code}\nimport tensorflow as tf\nimport numpy as np\n\n# モデルの作成\nmodel = tf.keras.Sequential([\n  tf.keras.layers.Dense(64, activation='relu'),\n  tf.keras.layers.Dense(26, activation='softmax')\n])\n\nmodel.compile(\n  optimizer='adam',\n  loss='sparse_categorical_crossentropy',\n  metrics=['accuracy']\n)\n```\n:::\n\n\n- rで作成したデータをpythonに渡して学習\n- `r.train_x`でRの`train_x`を参照できる\n- pythonのオブジェクトを渡すときは`py$train_x`\n\n\n::: {.cell filename='python'}\n\n```{.python .cell-code}\n# モデルの学習\nmodel.fit(r.train_x, r.train_y, epochs=10, verbose=2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nEpoch 1/10\n1304/1304 - 1s - loss: 1.3103 - accuracy: 0.6443 - 674ms/epoch - 517us/step\nEpoch 2/10\n1304/1304 - 1s - loss: 0.8173 - accuracy: 0.7754 - 544ms/epoch - 417us/step\nEpoch 3/10\n1304/1304 - 1s - loss: 0.6954 - accuracy: 0.8087 - 544ms/epoch - 417us/step\nEpoch 4/10\n1304/1304 - 1s - loss: 0.6173 - accuracy: 0.8277 - 540ms/epoch - 414us/step\nEpoch 5/10\n1304/1304 - 1s - loss: 0.5613 - accuracy: 0.8428 - 541ms/epoch - 415us/step\nEpoch 6/10\n1304/1304 - 1s - loss: 0.5192 - accuracy: 0.8514 - 543ms/epoch - 416us/step\nEpoch 7/10\n1304/1304 - 1s - loss: 0.4876 - accuracy: 0.8605 - 542ms/epoch - 416us/step\nEpoch 8/10\n1304/1304 - 1s - loss: 0.4605 - accuracy: 0.8670 - 540ms/epoch - 414us/step\nEpoch 9/10\n1304/1304 - 1s - loss: 0.4390 - accuracy: 0.8725 - 539ms/epoch - 413us/step\nEpoch 10/10\n1304/1304 - 1s - loss: 0.4211 - accuracy: 0.8768 - 541ms/epoch - 415us/step\n<keras.src.callbacks.History object at 0x2848e8d90>\n```\n:::\n:::\n\n\n### テストデータで評価\n\n- テストデータでの正答率は77%くらい\n\n\n::: {.cell filename='python'}\n\n```{.python .cell-code}\n# モデルの評価\nmodel.evaluate(r.test_x, r.test_y, verbose=2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n326/326 - 0s - loss: 0.5127 - accuracy: 0.8534 - 142ms/epoch - 434us/step\n[0.5126842856407166, 0.853417694568634]\n```\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}