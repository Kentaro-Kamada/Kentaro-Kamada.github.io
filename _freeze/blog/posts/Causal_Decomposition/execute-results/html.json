{
  "hash": "c5908a71fd684070c82fbe0f06776b4b",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Causal Decomposition Analysis\"\ndate: 2024-02-22\ncategories: [Causal Inference]\n---\n\n\n\n## 前準備\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(cfdecomp)\nlibrary(gapclosing)\nlibrary(causal.decomp)\n\n\nd <- \n  sMIDUS |> \n  transmute(Y = health |> as.numeric(),  # outcome\n            T = edu |> as.numeric(),   # treatment (continuous)\n            T2 = edu |> case_match(4:6 ~ 0,   # treatment (binary)\n                                   7:9 ~ 1,\n                                   .default = NA) |> factor(),\n            X = racesex |> factor(levels = c(\"1\", \"4\", \"2\", \"3\")),  # note!\n            L1 = lowchildSES |> as.numeric(),\n            L2 = abuse |> as.numeric(),\n            C1 = age |> as.numeric(),\n            C2 = stroke |> as.numeric(),\n            C3 = T2DM |> as.numeric(),\n            C4 = heart |> as.numeric()) |> \n  mutate(across(L1:C4, \\(.x){.x - mean(.x, na.rm = TRUE)})) |> \n  tibble()\n```\n:::\n\n\n\n# continuuous mediator\n\n## `cfdecomp`\n\n- @Sudharsanan2021 の方法。mediatorの値をシミュレーションで複数生成するのが特徴\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# cfd.mean\nfit_cfdecomp <-\n  cfdecomp::cfd.mean(\n    formula.y = 'Y ~ X + T + X:T + L1 + L2 + C1 + C2 + C3 + C4',\n    formula.m = 'T ~ X + C1 + C2 + C3 + C4',\n    mediator = 'T',\n    group = 'X',\n    data = d |> data.frame(),\n    family.y = 'gaussian',\n    family.m = 'gaussian',\n    bs.size = 50,\n    mc.size = 10,\n    alpha = 0.05\n  )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_cfdecomp\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$out_nc_m\n          1        4        2        3\n1  7.711633 5.888257 7.125844 6.352904\n2  7.711335 5.888175 7.067714 6.367545\n3  7.680955 5.879973 7.083105 6.290285\n4  7.731151 5.883833 7.054332 6.314513\n5  7.741197 5.919269 7.068209 6.411571\n6  7.679647 5.874477 7.071199 6.442494\n7  7.743790 5.900932 7.083522 6.434297\n8  7.718472 5.884156 7.099022 6.309715\n9  7.678637 5.804392 7.116342 6.344669\n10 7.707989 5.879045 7.084649 6.386724\n11 7.665000 5.854644 7.082168 6.404390\n12 7.687069 5.879753 7.062328 6.411204\n13 7.713308 5.892926 7.065359 6.375275\n14 7.705918 5.886559 7.081125 6.461115\n15 7.749694 5.860974 7.105595 6.348651\n16 7.738547 5.872752 7.087563 6.404910\n17 7.693606 5.850646 7.098890 6.459896\n18 7.713330 5.893088 7.091596 6.376642\n19 7.709143 5.823530 7.029086 6.413343\n20 7.733210 5.858471 7.087219 6.467162\n21 7.738161 5.911049 7.092461 6.335316\n22 7.746965 5.920713 7.089514 6.283847\n23 7.694358 5.888971 7.102488 6.363968\n24 7.693684 5.908104 7.052797 6.421523\n25 7.679553 5.875793 7.105435 6.411341\n26 7.659899 5.884256 7.051559 6.460068\n27 7.686961 5.894971 7.072704 6.403770\n28 7.710311 5.869419 7.055817 6.434180\n29 7.716763 5.903774 7.081851 6.455534\n30 7.693189 5.868528 7.081334 6.421027\n31 7.742753 5.925176 7.080192 6.333420\n32 7.751380 5.894483 7.097142 6.455502\n33 7.711411 5.809214 7.071902 6.437017\n34 7.740161 5.911441 7.105231 6.511967\n35 7.705447 5.909566 7.095954 6.380936\n36 7.702558 5.903924 7.081581 6.407733\n37 7.700893 5.881401 7.086621 6.461621\n38 7.738122 5.904513 7.063869 6.395699\n39 7.746447 5.870571 7.026998 6.484040\n40 7.759368 5.910303 7.092030 6.406555\n41 7.718450 5.831043 7.054374 6.358089\n42 7.695918 5.835081 7.075573 6.416062\n43 7.731954 5.813791 7.036193 6.421428\n44 7.712310 5.893671 7.025246 6.455531\n45 7.680701 5.846358 7.061539 6.407396\n46 7.694061 5.845573 7.072832 6.391219\n47 7.668851 5.817726 7.080903 6.406440\n48 7.711376 5.949511 7.053901 6.456014\n49 7.716736 5.826249 7.080758 6.422543\n50 7.654022 5.866163 7.131136 6.413449\n\n$out_cf_m\n          1        4        2        3\n1  7.710530 7.707118 7.729085 7.689582\n2  7.722146 7.715962 7.718530 7.694744\n3  7.685399 7.679285 7.699618 7.684752\n4  7.710964 7.722139 7.724466 7.721053\n5  7.730490 7.752241 7.751842 7.799405\n6  7.664568 7.663683 7.674068 7.663177\n7  7.724971 7.749857 7.752868 7.706792\n8  7.714129 7.716862 7.722281 7.723609\n9  7.683756 7.671424 7.702381 7.617404\n10 7.695261 7.735147 7.719256 7.703986\n11 7.670528 7.683359 7.689876 7.687277\n12 7.706871 7.707688 7.704846 7.672708\n13 7.704887 7.736651 7.703969 7.675736\n14 7.709934 7.709054 7.727723 7.682492\n15 7.740935 7.721385 7.747651 7.710687\n16 7.742387 7.735513 7.746277 7.728202\n17 7.691813 7.700624 7.705163 7.669490\n18 7.695803 7.723519 7.715414 7.705193\n19 7.714527 7.724800 7.728529 7.731613\n20 7.752440 7.731310 7.731205 7.740443\n21 7.747701 7.751927 7.746104 7.736706\n22 7.744353 7.753527 7.757974 7.699908\n23 7.698835 7.707310 7.733331 7.642548\n24 7.688320 7.678430 7.695832 7.700293\n25 7.678879 7.703020 7.682947 7.674868\n26 7.662760 7.686827 7.677796 7.669470\n27 7.667674 7.688950 7.702769 7.645594\n28 7.708490 7.720959 7.712414 7.715071\n29 7.717942 7.738635 7.736016 7.725968\n30 7.696543 7.693711 7.704273 7.674739\n31 7.732255 7.762128 7.749186 7.722042\n32 7.746046 7.742624 7.751110 7.730741\n33 7.713978 7.723498 7.716193 7.716831\n34 7.745275 7.731578 7.746356 7.749622\n35 7.705166 7.686891 7.714852 7.647096\n36 7.700198 7.701480 7.708816 7.661288\n37 7.711325 7.716404 7.731762 7.711473\n38 7.712923 7.725907 7.735120 7.730548\n39 7.750298 7.756705 7.764771 7.732673\n40 7.766789 7.768882 7.776410 7.764838\n41 7.717941 7.713504 7.723617 7.715233\n42 7.679975 7.704309 7.704923 7.687836\n43 7.737060 7.735301 7.739600 7.718730\n44 7.708164 7.721542 7.701967 7.645525\n45 7.682980 7.686698 7.681756 7.670019\n46 7.695651 7.713801 7.706790 7.662348\n47 7.665926 7.714450 7.687832 7.659873\n48 7.703820 7.719615 7.695535 7.688421\n49 7.726563 7.701374 7.736214 7.689662\n50 7.645600 7.695163 7.665097 7.640491\n\n$out_nc_quantile_m\n             1        4        2        3\n2.5%  7.661047 5.810243 7.027468 6.294657\n50%   7.711356 5.882617 7.081230 6.409468\n97.5% 7.751000 5.924172 7.123706 6.480242\n\n$out_cf_quantile_m\n             1        4        2        3\n2.5%  7.663167 7.673000 7.674907 7.640954\n50%   7.709212 7.716633 7.718893 7.697326\n97.5% 7.751958 7.760908 7.763242 7.761414\n\n$out_nc_y\n          1        4        2        3\n1  7.643030 6.732799 7.375613 6.910479\n2  7.607577 6.717165 7.346198 7.052359\n3  7.607693 6.599873 7.269480 6.873304\n4  7.610145 6.723795 7.289715 6.952498\n5  7.616292 6.678440 7.333097 7.001349\n6  7.557731 6.704395 7.250811 6.992294\n7  7.599877 6.719521 7.340502 7.077658\n8  7.628274 6.719762 7.296094 6.900450\n9  7.519645 6.578178 7.334936 6.963192\n10 7.636567 6.695734 7.262511 7.051596\n11 7.611775 6.700613 7.292579 7.049620\n12 7.631828 6.683791 7.331269 7.083689\n13 7.563892 6.674326 7.316754 6.908562\n14 7.603895 6.737479 7.327165 6.927612\n15 7.618607 6.670229 7.255864 6.985934\n16 7.622240 6.704231 7.320607 7.053559\n17 7.585641 6.734660 7.341138 6.945470\n18 7.604256 6.707089 7.302909 7.041279\n19 7.524772 6.703693 7.298052 7.103668\n20 7.553036 6.722339 7.308819 7.009432\n21 7.574128 6.759331 7.311300 6.899021\n22 7.609917 6.680900 7.350035 6.967131\n23 7.607101 6.731611 7.357399 6.922846\n24 7.620362 6.689117 7.271719 6.909727\n25 7.600291 6.721549 7.343278 7.091111\n26 7.580349 6.750467 7.322421 7.079178\n27 7.588436 6.694641 7.341734 6.990717\n28 7.573369 6.765644 7.320928 6.946950\n29 7.578826 6.691312 7.331328 6.974224\n30 7.601308 6.629131 7.267103 6.999810\n31 7.603843 6.783977 7.376238 6.952896\n32 7.603542 6.734427 7.370235 6.965581\n33 7.620574 6.695155 7.328574 6.988810\n34 7.631733 6.629085 7.316282 7.039475\n35 7.614603 6.723767 7.332842 6.990229\n36 7.587058 6.682920 7.313699 6.875552\n37 7.590790 6.698495 7.371529 7.092733\n38 7.599795 6.681993 7.317343 6.869174\n39 7.585488 6.704832 7.335817 7.077249\n40 7.609017 6.707175 7.327749 6.978417\n41 7.570631 6.681757 7.330553 6.931524\n42 7.622285 6.650356 7.320067 6.998195\n43 7.620196 6.697024 7.337561 6.933217\n44 7.625899 6.619717 7.265149 7.086506\n45 7.541506 6.675692 7.294960 6.897559\n46 7.634605 6.657319 7.288395 6.937194\n47 7.590675 6.667401 7.355573 6.968337\n48 7.640129 6.790121 7.279111 6.935163\n49 7.598317 6.712968 7.344339 7.088489\n50 7.609962 6.684222 7.339409 7.026853\n\n$out_cf_y\n          1        4        2        3\n1  7.642828 7.228655 7.472077 7.044363\n2  7.610666 7.217077 7.479253 7.210653\n3  7.608739 7.042916 7.414806 7.153437\n4  7.605145 7.217781 7.452585 7.336006\n5  7.613874 7.287004 7.518205 7.143872\n6  7.554566 7.294251 7.384723 7.342034\n7  7.595708 7.312383 7.507010 7.324459\n8  7.627264 7.353019 7.429607 7.023240\n9  7.520749 7.217301 7.498648 7.195415\n10 7.634141 7.158135 7.437276 7.380509\n11 7.613326 7.312547 7.438580 7.217391\n12 7.636896 7.233261 7.494746 7.434478\n13 7.561744 7.346572 7.457141 7.021547\n14 7.604743 7.324411 7.453311 7.211474\n15 7.616689 7.236342 7.432433 7.312738\n16 7.623216 7.294132 7.488400 7.301480\n17 7.585169 7.293564 7.492201 7.007174\n18 7.599991 7.097552 7.472330 7.256049\n19 7.525761 7.140974 7.451360 7.495060\n20 7.557790 7.315725 7.505289 7.214017\n21 7.576391 7.363599 7.451759 7.137034\n22 7.609120 7.228905 7.483233 7.328490\n23 7.608396 7.173141 7.499450 7.104582\n24 7.619150 7.134299 7.413481 7.102330\n25 7.600139 7.295098 7.489918 7.308457\n26 7.581097 7.396744 7.491733 7.300458\n27 7.582923 7.368377 7.515990 7.358491\n28 7.572931 7.244174 7.466398 7.172318\n29 7.579088 7.366221 7.480393 7.158943\n30 7.601925 7.050239 7.405865 7.281161\n31 7.601097 7.217883 7.501238 7.079388\n32 7.602343 7.215997 7.486182 7.362801\n33 7.621057 7.371830 7.477008 7.321741\n34 7.632899 7.159265 7.465772 7.294746\n35 7.614549 7.213676 7.464199 7.014393\n36 7.586656 7.270587 7.435904 7.400305\n37 7.593428 7.108840 7.522947 7.414827\n38 7.593836 7.193211 7.492250 7.175875\n39 7.586345 7.250112 7.477559 7.152434\n40 7.610498 7.269978 7.452130 7.254088\n41 7.570510 7.347217 7.476158 7.220753\n42 7.618182 7.287882 7.412706 7.084224\n43 7.621420 7.233066 7.507654 7.124081\n44 7.624912 7.074213 7.438136 7.212636\n45 7.541945 7.178940 7.451000 7.109039\n46 7.635028 7.263358 7.453537 7.242004\n47 7.590112 7.170538 7.506422 6.924094\n48 7.638272 7.468543 7.431446 7.129897\n49 7.600589 7.215825 7.450062 7.366063\n50 7.607752 7.131514 7.427264 7.360753\n\n$out_nc_quantile_y\n             1        4        2        3\n2.5%  7.528537 6.604338 7.257360 6.873810\n50%   7.604075 6.699554 7.324793 6.982175\n97.5% 7.639328 6.779852 7.374694 7.092368\n\n$out_cf_quantile_y\n             1        4        2        3\n2.5%  7.529402 7.055633 7.407404 7.008799\n50%   7.603543 7.234802 7.469238 7.215704\n97.5% 7.637962 7.391138 7.517707 7.430056\n\n$mediation\n        4         2         3 \n0.6073567 0.5348774 0.3926196 \n\n$mediation_quantile\n              4         2          3\n2.5%  0.4362047 0.3328234 0.05168082\n97.5% 0.7746384 0.7824060 0.71708929\n\n$mc_conv_info_m\n          [,1]     [,2]     [,3]     [,4]\n [1,] 7.723179 5.928527 7.115377 6.273738\n [2,] 7.703455 5.931829 7.113009 6.283259\n [3,] 7.707302 5.893149 7.113309 6.302433\n [4,] 7.705497 5.903295 7.112800 6.309729\n [5,] 7.706187 5.906655 7.120460 6.311052\n [6,] 7.712124 5.901055 7.122027 6.330075\n [7,] 7.710921 5.900642 7.118638 6.347855\n [8,] 7.708649 5.901588 7.121293 6.351281\n [9,] 7.712484 5.896719 7.121812 6.349336\n[10,] 7.711633 5.888257 7.125844 6.352904\n\n$mc_conv_info_y\n          [,1]     [,2]     [,3]     [,4]\n [1,] 7.645142 6.743777 7.373939 6.902550\n [2,] 7.641534 6.744677 7.373561 6.903504\n [3,] 7.642238 6.734132 7.373609 6.905424\n [4,] 7.641907 6.736898 7.373527 6.906155\n [5,] 7.642034 6.737814 7.374752 6.906288\n [6,] 7.643120 6.736288 7.375003 6.908193\n [7,] 7.642899 6.736175 7.374461 6.909974\n [8,] 7.642484 6.736433 7.374885 6.910317\n [9,] 7.643185 6.735106 7.374968 6.910122\n[10,] 7.643030 6.732799 7.375613 6.910479\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp$out_nc_y[,2] - fit_cfdecomp$out_nc_y[,1])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.9016258\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp$out_cf_y[,2] - fit_cfdecomp$out_nc_y[,1])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.3558926\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp$out_nc_y[,2] - fit_cfdecomp$out_cf_y[,2])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.5457332\n```\n\n\n:::\n\n```{.r .cell-code}\nfit_cfdecomp$mediation\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        4         2         3 \n0.6073567 0.5348774 0.3926196 \n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp$out_nc_y[,3] - fit_cfdecomp$out_nc_y[,1])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.2804946\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp$out_cf_y[,3] - fit_cfdecomp$out_nc_y[,1])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.1334747\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp$out_nc_y[,3] - fit_cfdecomp$out_cf_y[,3])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.1470199\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp$out_nc_y[,4] - fit_cfdecomp$out_nc_y[,1])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.6136728\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp$out_cf_y[,4] - fit_cfdecomp$out_nc_y[,1])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.3771942\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp$out_nc_y[,4] - fit_cfdecomp$out_cf_y[,4])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.2364786\n```\n\n\n:::\n:::\n\n\n\n## `causal.decomp`\n\n- @Park2023 の方法。\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# smi \nfit.y <- lm(Y ~ X + T + X:T + L1 + L2 + C1 + C2 + C3 + C4, data = d)\nfit.m <- lm(T ~ X + C1 + C2 + C3 + C4, data = d)\n\nfit_smi <- smi(fit.y = fit.y,\n    fit.m = fit.m,\n    treat = \"X\", \n    sims = 100, \n    conf.level = .95,\n    conditional = TRUE,\n    covariates = 1,\n    # baseline covariatesを調整できる\n    #covariates = c(\"C1\", \"C2\", \"C3\", \"C4\"),\n    seed = 227,\n    )\n\nfit_smi\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nResults:\n\n                               estimate 95% CI Lower 95% CI Upper\nInitial Disparity   (1 vs 4) -0.8993401   -0.9925190  -0.79813505\nDisparity Remaining (1 vs 4) -0.3384430   -0.4880863  -0.14795873\nDisparity Reduction (1 vs 4) -0.5608971   -0.7346168  -0.42650061\nInitial Disparity   (1 vs 2) -0.2749659   -0.3378874  -0.19366549\nDisparity Remaining (1 vs 2) -0.1213246   -0.2203441  -0.05458727\nDisparity Reduction (1 vs 2) -0.1536412   -0.1896213  -0.10521328\nInitial Disparity   (1 vs 3) -0.6137425   -0.7326095  -0.47793913\nDisparity Remaining (1 vs 3) -0.3500123   -0.5151994  -0.08733348\nDisparity Reduction (1 vs 3) -0.2637302   -0.4880614  -0.11574038\n```\n\n\n:::\n:::\n\n\n\n- sensitivity analysis[@Park2023]\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsensRes <- sensitivity(boot.res = fit_smi, fit.m = fit.m, fit.y = fit.y, \n                       mediator = \"T\",\n                       covariates = c(\"C1\", \"C2\", \"C3\", \"C4\"), \n                       treat = \"X\",\n                       sel.lev.treat = \"4\", \n                       max.rsq = 0.3)\nplot(sensRes)\n```\n\n::: {.cell-output-display}\n![](Causal_Decomposition_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\n\n# binary mediator\n\n## `cfdecomp`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# cfd.mean\nset.seed(123456)\nfit_cfdecomp_b <-\n  cfd.mean(\n    formula.y = 'Y ~ X + T2 + X:T2 + L1 + L2 + C1 + C2 + C3 + C4',\n    formula.m = 'T2 ~ X + C1 + C2 + C3 + C4',\n    mediator = 'T2',\n    group = 'X',\n    data = d |> mutate(T2 = as.numeric(T2) - 1) |> data.frame(),\n    family.y = 'gaussian',\n    family.m = 'binomial',\n    bs.size = 50,\n    mc.size = 10,\n    alpha = 0.05\n  )\nmean(fit_cfdecomp_b$out_nc_y[,\"4\"] - fit_cfdecomp_b$out_nc_y[,\"1\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.8981701\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp_b$out_cf_y[,\"4\"] - fit_cfdecomp_b$out_nc_y[,\"1\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.5546351\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp_b$out_nc_y[,\"4\"] - fit_cfdecomp_b$out_cf_y[,\"4\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.343535\n```\n\n\n:::\n\n```{.r .cell-code}\nfit_cfdecomp_b$mediation\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        4         2         3 \n0.3828971 0.1298177 0.2061071 \n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp_b$out_nc_y[,\"2\"] - fit_cfdecomp_b$out_nc_y[,\"1\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.2774845\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp_b$out_cf_y[,\"2\"] - fit_cfdecomp_b$out_nc_y[,\"1\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.2419289\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp_b$out_nc_y[,\"2\"] - fit_cfdecomp_b$out_cf_y[,\"2\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.03555558\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp_b$out_nc_y[,\"3\"] - fit_cfdecomp_b$out_nc_y[,\"1\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.5849521\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp_b$out_cf_y[,\"3\"] - fit_cfdecomp_b$out_nc_y[,\"1\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.4655888\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp_b$out_nc_y[,\"3\"] - fit_cfdecomp_b$out_cf_y[,\"3\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.1193632\n```\n\n\n:::\n:::\n\n\n\n## `causal.decomp`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# smi\nfit.y <- lm(Y ~ X + T2 + X:T2 + L1 + L2 + C1 + C2 + C3 + C4, data = d)\nfit.m <- glm(T2 ~ X + C1 + C2 + C3 + C4, data = d, family = binomial(link = \"logit\"))\n\nfit_smi_b <- smi(fit.y = fit.y,\n               fit.m = fit.m,\n               treat = \"X\", \n               sims = 100, \n               conf.level = .95,\n               conditional = TRUE,\n               # covariates = 1,\n               covariates = c(\"C1\", \"C2\", \"C3\", \"C4\"),\n               seed = 123456)\nfit_smi_b\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nResults:\n\n                                estimate 95% CI Lower 95% CI Upper\nInitial Disparity   (1 vs 4) -0.95667843  -1.02938841  -0.88175003\nDisparity Remaining (1 vs 4) -0.61262729  -0.77966809  -0.46844380\nDisparity Reduction (1 vs 4) -0.34405113  -0.49650368  -0.21581205\nInitial Disparity   (1 vs 2) -0.31394841  -0.38058533  -0.26000373\nDisparity Remaining (1 vs 2) -0.27995004  -0.34624791  -0.22226331\nDisparity Reduction (1 vs 2) -0.03399837  -0.05003528  -0.02022012\nInitial Disparity   (1 vs 3) -0.59968604  -0.69525994  -0.49987857\nDisparity Remaining (1 vs 3) -0.48148718  -0.61387973  -0.32105036\nDisparity Reduction (1 vs 3) -0.11819886  -0.24676548  -0.03361808\n```\n\n\n:::\n\n```{.r .cell-code}\nsensRes <- sensitivity(boot.res = fit_smi_b, \n                       fit.m = fit.m, \n                       fit.y = fit.y, \n                       mediator = \"T2\",\n                       covariates = c(\"C1\", \"C2\", \"C3\", \"C4\"), \n                       treat = \"X\",\n                       sel.lev.treat = \"4\", \n                       max.rsq = 0.3)\nplot(sensRes)\n```\n\n::: {.cell-output-display}\n![](Causal_Decomposition_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n\n## `gapclosing`\n\n- @Lundberg2022a\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# gapclosing - regression\n# stochastic intervention\n# treatmentの割り当て確率の予測値を算出\nfit_glm <- glm(T2 ~ X + C1 + C2 + C3, data = d, family = binomial(link = \"logit\"))\n\n# 全員のtreatmentが1だった時の予測値\nassing_prob <- predict(fit_glm, newdata = d |> mutate(X = \"1\"), type = \"response\")\n\n# 予測値をもとにrandom draw\ndraw <- rbinom(n = nrow(d), size = 1, prob = assing_prob)\n\nfit_gapclosing <- \n  gapclosing(\n    data = d |> mutate(T2 = as.numeric(T2) - 1),\n    outcome_formula = Y ~ T2 * X + C1 + C2 + C3 + C4 + L1 + L2,\n    treatment_name = \"T2\",\n    category_name = \"X\",\n    counterfactual_assignments = draw # random draw\n  )\n\nfit_gapclosing\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nFactual mean outcomes:\n# A tibble: 4 × 2\n  X     estimate\n  <fct>    <dbl>\n1 1         7.60\n2 4         6.70\n3 2         7.32\n4 3         6.98\n\nCounterfactual mean outcomes (post-intervention means):\n# A tibble: 4 × 2\n  X     estimate\n  <fct>    <dbl>\n1 1         7.60\n2 4         7.03\n3 2         7.36\n4 3         7.11\n\nFactual disparities:\n# A tibble: 12 × 2\n   X     estimate\n   <chr>    <dbl>\n 1 1 - 4    0.899\n 2 1 - 2    0.275\n 3 1 - 3    0.614\n 4 4 - 1   -0.899\n 5 4 - 2   -0.624\n 6 4 - 3   -0.286\n 7 2 - 1   -0.275\n 8 2 - 4    0.624\n 9 2 - 3    0.339\n10 3 - 1   -0.614\n11 3 - 4    0.286\n12 3 - 2   -0.339\n\nCounterfactual disparities (gap-closing estimands):\n# A tibble: 12 × 2\n   X     estimate\n   <chr>    <dbl>\n 1 1 - 4   0.566 \n 2 1 - 2   0.241 \n 3 1 - 3   0.483 \n 4 4 - 1  -0.566 \n 5 4 - 2  -0.325 \n 6 4 - 3  -0.0830\n 7 2 - 1  -0.241 \n 8 2 - 4   0.325 \n 9 2 - 3   0.242 \n10 3 - 1  -0.483 \n11 3 - 4   0.0830\n12 3 - 2  -0.242 \n\nAdditive gap closed: Counterfactual - Factual\n# A tibble: 12 × 2\n   X     estimate\n   <chr>    <dbl>\n 1 1 - 4   0.334 \n 2 1 - 2   0.0339\n 3 1 - 3   0.131 \n 4 4 - 1  -0.334 \n 5 4 - 2  -0.300 \n 6 4 - 3  -0.203 \n 7 2 - 1  -0.0339\n 8 2 - 4   0.300 \n 9 2 - 3   0.0972\n10 3 - 1  -0.131 \n11 3 - 4   0.203 \n12 3 - 2  -0.0972\n\nProportional gap closed: (Counterfactual - Factual) / Factual\n# A tibble: 12 × 2\n   X     estimate\n   <chr>    <dbl>\n 1 1 - 4    0.371\n 2 1 - 2    0.123\n 3 1 - 3    0.214\n 4 4 - 1    0.371\n 5 4 - 2    0.480\n 6 4 - 3    0.710\n 7 2 - 1    0.123\n 8 2 - 4    0.480\n 9 2 - 3    0.287\n10 3 - 1    0.214\n11 3 - 4    0.710\n12 3 - 2    0.287\n```\n\n\n:::\n\n```{.r .cell-code}\ndisparityplot(fit_gapclosing, category_A = \"1\", category_B = \"4\")\n```\n\n::: {.cell-output-display}\n![](Causal_Decomposition_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n\n```{.r .cell-code}\ndisparityplot(fit_gapclosing, category_A = \"1\", category_B = \"2\")\n```\n\n::: {.cell-output-display}\n![](Causal_Decomposition_files/figure-html/unnamed-chunk-8-2.png){width=672}\n:::\n\n```{.r .cell-code}\ndisparityplot(fit_gapclosing, category_A = \"1\", category_B = \"3\")\n```\n\n::: {.cell-output-display}\n![](Causal_Decomposition_files/figure-html/unnamed-chunk-8-3.png){width=672}\n:::\n:::\n\n\n\n- 機械学習をつかったdoubly robustな方法も使える\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# gapclosing - ranger, doubly robust\nfit_gapclosing_ranger <- \n  gapclosing(\n  data = d |> mutate(T2 = as.numeric(T2) - 1),\n  outcome_formula = Y ~ T2 + X + C1 + C2 + C3 + C4 + L1 + L2,\n  treatment_formula = T2 ~ X + C1 + C2 + C3 + C4 + L1 + L2, \n  treatment_name = \"T2\",\n  treatment_algorithm = \"ranger\",\n  outcome_algorithm = \"ranger\",\n  category_name = \"X\",\n  counterfactual_assignments = rbinom(n = nrow(d), size = 1, prob = assing_prob) \n)\n\nfit_gapclosing\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nFactual mean outcomes:\n# A tibble: 4 × 2\n  X     estimate\n  <fct>    <dbl>\n1 1         7.60\n2 4         6.70\n3 2         7.32\n4 3         6.98\n\nCounterfactual mean outcomes (post-intervention means):\n# A tibble: 4 × 2\n  X     estimate\n  <fct>    <dbl>\n1 1         7.60\n2 4         7.03\n3 2         7.36\n4 3         7.11\n\nFactual disparities:\n# A tibble: 12 × 2\n   X     estimate\n   <chr>    <dbl>\n 1 1 - 4    0.899\n 2 1 - 2    0.275\n 3 1 - 3    0.614\n 4 4 - 1   -0.899\n 5 4 - 2   -0.624\n 6 4 - 3   -0.286\n 7 2 - 1   -0.275\n 8 2 - 4    0.624\n 9 2 - 3    0.339\n10 3 - 1   -0.614\n11 3 - 4    0.286\n12 3 - 2   -0.339\n\nCounterfactual disparities (gap-closing estimands):\n# A tibble: 12 × 2\n   X     estimate\n   <chr>    <dbl>\n 1 1 - 4   0.566 \n 2 1 - 2   0.241 \n 3 1 - 3   0.483 \n 4 4 - 1  -0.566 \n 5 4 - 2  -0.325 \n 6 4 - 3  -0.0830\n 7 2 - 1  -0.241 \n 8 2 - 4   0.325 \n 9 2 - 3   0.242 \n10 3 - 1  -0.483 \n11 3 - 4   0.0830\n12 3 - 2  -0.242 \n\nAdditive gap closed: Counterfactual - Factual\n# A tibble: 12 × 2\n   X     estimate\n   <chr>    <dbl>\n 1 1 - 4   0.334 \n 2 1 - 2   0.0339\n 3 1 - 3   0.131 \n 4 4 - 1  -0.334 \n 5 4 - 2  -0.300 \n 6 4 - 3  -0.203 \n 7 2 - 1  -0.0339\n 8 2 - 4   0.300 \n 9 2 - 3   0.0972\n10 3 - 1  -0.131 \n11 3 - 4   0.203 \n12 3 - 2  -0.0972\n\nProportional gap closed: (Counterfactual - Factual) / Factual\n# A tibble: 12 × 2\n   X     estimate\n   <chr>    <dbl>\n 1 1 - 4    0.371\n 2 1 - 2    0.123\n 3 1 - 3    0.214\n 4 4 - 1    0.371\n 5 4 - 2    0.480\n 6 4 - 3    0.710\n 7 2 - 1    0.123\n 8 2 - 4    0.480\n 9 2 - 3    0.287\n10 3 - 1    0.214\n11 3 - 4    0.710\n12 3 - 2    0.287\n```\n\n\n:::\n\n```{.r .cell-code}\ndisparityplot(fit_gapclosing_ranger, category_A = \"1\", category_B = \"4\")\n```\n\n::: {.cell-output-display}\n![](Causal_Decomposition_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n\n```{.r .cell-code}\ndisparityplot(fit_gapclosing_ranger, category_A = \"1\", category_B = \"2\")\n```\n\n::: {.cell-output-display}\n![](Causal_Decomposition_files/figure-html/unnamed-chunk-9-2.png){width=672}\n:::\n\n```{.r .cell-code}\ndisparityplot(fit_gapclosing_ranger, category_A = \"1\", category_B = \"3\")\n```\n\n::: {.cell-output-display}\n![](Causal_Decomposition_files/figure-html/unnamed-chunk-9-3.png){width=672}\n:::\n:::\n",
    "supporting": [
      "Causal_Decomposition_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}