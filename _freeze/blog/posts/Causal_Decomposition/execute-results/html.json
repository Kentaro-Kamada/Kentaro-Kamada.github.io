{
  "hash": "8698537d34337f9c8ea92ca079d64245",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Causal Decomposition Analysis\"\ndate: 2024-02-22\ncategories: [Causal Inference]\n---\n\n\n\n## 前準備\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(cfdecomp)\nlibrary(gapclosing)\nlibrary(causal.decomp)\n\n\nd <- \n  sMIDUS |> \n  transmute(Y = health |> as.numeric(),  # outcome\n            T = edu |> as.numeric(),   # treatment (continuous)\n            T2 = edu |> case_match(4:6 ~ 0,   # treatment (binary)\n                                   7:9 ~ 1,\n                                   .default = NA) |> factor(),\n            X = racesex |> factor(levels = c(\"1\", \"4\", \"2\", \"3\")),  # note!\n            L1 = lowchildSES |> as.numeric(),\n            L2 = abuse |> as.numeric(),\n            C1 = age |> as.numeric(),\n            C2 = stroke |> as.numeric(),\n            C3 = T2DM |> as.numeric(),\n            C4 = heart |> as.numeric()) |> \n  mutate(across(L1:C4, \\(.x){.x - mean(.x, na.rm = TRUE)})) |> \n  tibble()\n```\n:::\n\n\n\n# continuuous mediator\n\n## `cfdecomp`\n\n- @Sudharsanan2021 の方法。mediatorの値をシミュレーションで複数生成するのが特徴\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# cfd.mean\nfit_cfdecomp <-\n  cfdecomp::cfd.mean(\n    formula.y = 'Y ~ X + T + X:T + L1 + L2 + C1 + C2 + C3 + C4',\n    formula.m = 'T ~ X + C1 + C2 + C3 + C4',\n    mediator = 'T',\n    group = 'X',\n    data = d |> data.frame(),\n    family.y = 'gaussian',\n    family.m = 'gaussian',\n    bs.size = 50,\n    mc.size = 10,\n    alpha = 0.05\n  )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_cfdecomp\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$out_nc_m\n          1        4        2        3\n1  7.691620 5.903479 7.074230 6.401085\n2  7.686288 5.851340 7.093282 6.399524\n3  7.708576 5.822106 7.094568 6.384855\n4  7.705292 5.868466 7.076435 6.338724\n5  7.719214 5.913302 7.105034 6.404542\n6  7.684584 5.926160 7.049353 6.326670\n7  7.710585 5.882988 7.095104 6.348387\n8  7.679686 5.899821 7.080776 6.470807\n9  7.725260 5.935738 7.066875 6.447876\n10 7.680137 5.857691 7.054819 6.373660\n11 7.696426 5.944271 7.063720 6.439212\n12 7.700643 5.821413 7.085500 6.339201\n13 7.693362 5.846745 7.088152 6.419090\n14 7.716584 5.850613 7.101872 6.458169\n15 7.712684 5.885706 7.060460 6.404721\n16 7.704699 5.920647 7.072777 6.446932\n17 7.700979 5.886535 7.092668 6.414058\n18 7.665549 5.913848 7.109964 6.392970\n19 7.705040 5.812203 7.083783 6.460505\n20 7.717075 5.893334 7.062888 6.438355\n21 7.717534 5.932667 7.080653 6.412771\n22 7.726708 5.833179 7.058449 6.382606\n23 7.747496 5.888901 7.102890 6.391513\n24 7.736253 5.871866 7.082152 6.349239\n25 7.711726 5.870103 7.117876 6.472197\n26 7.723777 5.882988 7.103639 6.326517\n27 7.672843 5.795129 7.071731 6.481404\n28 7.733062 5.842725 7.075069 6.374337\n29 7.692945 5.859889 7.097161 6.433527\n30 7.717666 5.927108 7.091016 6.366568\n31 7.691101 5.852563 7.113142 6.415854\n32 7.697604 5.831029 7.105097 6.367603\n33 7.741424 5.902711 7.105534 6.331117\n34 7.722045 5.784367 7.103666 6.437032\n35 7.692453 5.862954 7.076089 6.321857\n36 7.646706 5.809606 7.062814 6.383445\n37 7.705667 5.860735 7.041463 6.436072\n38 7.699599 5.809260 7.071437 6.413898\n39 7.713365 5.884598 7.065502 6.334899\n40 7.697805 5.904221 7.088727 6.410220\n41 7.701732 5.853243 7.068522 6.428324\n42 7.712378 5.929001 7.090080 6.437932\n43 7.712444 5.837593 7.074545 6.392852\n44 7.745429 5.907289 7.060106 6.432842\n45 7.744076 5.882094 7.077142 6.328885\n46 7.701634 5.856016 7.061101 6.394278\n47 7.688703 5.866987 7.051684 6.389235\n48 7.693028 5.872492 7.063328 6.418712\n49 7.678176 5.854286 7.047194 6.379773\n50 7.693541 5.946907 7.042778 6.365255\n\n$out_cf_m\n          1        4        2        3\n1  7.694368 7.706683 7.711569 7.676656\n2  7.675996 7.709028 7.680850 7.684987\n3  7.693016 7.706211 7.713118 7.695313\n4  7.712819 7.707977 7.719926 7.675929\n5  7.699568 7.711089 7.699306 7.688434\n6  7.698347 7.667810 7.701188 7.671001\n7  7.708082 7.725790 7.716572 7.713793\n8  7.682451 7.700808 7.692263 7.667218\n9  7.726994 7.725572 7.731699 7.717573\n10 7.708675 7.724889 7.705377 7.671621\n11 7.691167 7.701819 7.708740 7.677413\n12 7.706299 7.723064 7.730158 7.696099\n13 7.693928 7.709600 7.707202 7.684103\n14 7.710371 7.730474 7.717734 7.704569\n15 7.723861 7.719707 7.735832 7.736501\n16 7.705975 7.739768 7.723184 7.681721\n17 7.711067 7.708167 7.718204 7.696593\n18 7.666730 7.682081 7.667588 7.702620\n19 7.694994 7.686376 7.706852 7.692542\n20 7.712226 7.708470 7.715184 7.703222\n21 7.714746 7.739595 7.738355 7.728673\n22 7.713479 7.742127 7.728872 7.731431\n23 7.742325 7.735250 7.751190 7.717709\n24 7.740702 7.738517 7.771374 7.717973\n25 7.710550 7.697311 7.728057 7.727471\n26 7.711095 7.748652 7.731093 7.683119\n27 7.661539 7.659760 7.677740 7.644783\n28 7.722719 7.773671 7.733193 7.710887\n29 7.694222 7.713420 7.724826 7.735735\n30 7.708394 7.711895 7.728228 7.735981\n31 7.693792 7.712127 7.677894 7.654353\n32 7.698869 7.707765 7.722551 7.711125\n33 7.727526 7.729553 7.725879 7.712680\n34 7.736907 7.734511 7.747580 7.737776\n35 7.688590 7.689720 7.699519 7.677718\n36 7.651915 7.661290 7.659749 7.684469\n37 7.713434 7.709630 7.715647 7.705886\n38 7.700683 7.694580 7.687552 7.653711\n39 7.716684 7.709416 7.717984 7.643918\n40 7.678471 7.716327 7.727294 7.698329\n41 7.693627 7.704902 7.707023 7.703769\n42 7.704315 7.742958 7.713615 7.659216\n43 7.713094 7.717394 7.707769 7.671835\n44 7.750917 7.762555 7.744067 7.728395\n45 7.751429 7.758673 7.756817 7.725800\n46 7.700168 7.722584 7.718004 7.667568\n47 7.699436 7.706097 7.714158 7.680908\n48 7.684891 7.672446 7.679650 7.667766\n49 7.676596 7.678788 7.710157 7.650747\n50 7.696234 7.682737 7.688559 7.668339\n\n$out_nc_quantile_m\n             1        4        2        3\n2.5%  7.667190 5.798309 7.043772 6.326551\n50%   7.704870 5.870985 7.076789 6.400304\n97.5% 7.745125 5.942351 7.112427 6.471884\n\n$out_cf_quantile_m\n             1        4        2        3\n2.5%  7.662707 7.662757 7.669873 7.646125\n50%   7.705145 7.710360 7.716109 7.693927\n97.5% 7.748984 7.761681 7.755551 7.736384\n\n$out_nc_y\n          1        4        2        3\n1  7.573016 6.752405 7.321271 7.061268\n2  7.634295 6.726107 7.322181 6.949904\n3  7.586864 6.680242 7.363882 6.883184\n4  7.609331 6.727532 7.326431 6.810922\n5  7.595753 6.766591 7.308360 7.071568\n6  7.607702 6.684720 7.325853 6.854390\n7  7.599817 6.703397 7.307502 6.882905\n8  7.592916 6.718701 7.324578 6.920241\n9  7.561821 6.795550 7.285833 7.081418\n10 7.587595 6.667228 7.296214 6.964471\n11 7.629020 6.749562 7.345921 6.932641\n12 7.605666 6.716479 7.304525 6.962370\n13 7.615934 6.779819 7.336255 6.937528\n14 7.599271 6.689468 7.324713 7.049985\n15 7.593428 6.738799 7.292353 7.018741\n16 7.640615 6.670906 7.324079 6.936599\n17 7.573441 6.802899 7.367897 7.026279\n18 7.607972 6.680871 7.331547 6.987752\n19 7.595871 6.614606 7.350704 7.067088\n20 7.595863 6.731565 7.359684 7.014888\n21 7.615533 6.665645 7.298754 7.071895\n22 7.610810 6.680488 7.273439 7.017883\n23 7.611379 6.620520 7.350792 6.942568\n24 7.558913 6.697029 7.330005 6.941346\n25 7.626489 6.712025 7.379597 7.058167\n26 7.619216 6.697429 7.302447 6.985057\n27 7.612853 6.650963 7.342401 7.034549\n28 7.629465 6.736374 7.323146 6.999512\n29 7.598120 6.637056 7.352217 6.910594\n30 7.558746 6.658438 7.303486 7.009547\n31 7.574483 6.703021 7.302062 6.993343\n32 7.579724 6.781071 7.356608 6.994657\n33 7.592171 6.721632 7.317557 6.949315\n34 7.621765 6.664997 7.320297 7.046020\n35 7.613701 6.666155 7.349768 6.976570\n36 7.602946 6.678714 7.333877 7.011596\n37 7.599440 6.790371 7.286552 7.069060\n38 7.574340 6.704108 7.367429 6.855076\n39 7.645508 6.701465 7.313479 6.939002\n40 7.603820 6.729732 7.381661 7.017929\n41 7.605537 6.687921 7.310661 6.953378\n42 7.593308 6.793165 7.318804 7.059395\n43 7.610781 6.634967 7.338410 6.976505\n44 7.616556 6.651578 7.311554 6.974912\n45 7.632992 6.720921 7.352840 7.006610\n46 7.617324 6.661013 7.270648 6.882098\n47 7.574085 6.696714 7.321917 7.054938\n48 7.599348 6.711412 7.340888 6.957741\n49 7.592058 6.653166 7.320236 6.870126\n50 7.589620 6.693150 7.326758 6.944336\n\n$out_cf_y\n          1        4        2        3\n1  7.573730 7.240279 7.482160 7.302499\n2  7.631680 7.368768 7.474985 7.113000\n3  7.582978 7.260099 7.512674 7.231814\n4  7.611341 7.411821 7.452879 7.253369\n5  7.590240 7.346065 7.411637 7.605579\n6  7.610949 7.280478 7.457437 7.199937\n7  7.599172 7.361021 7.422648 7.318868\n8  7.593424 7.248864 7.479899 7.262653\n9  7.562247 7.409231 7.464533 7.197400\n10 7.593578 7.179452 7.441228 7.090939\n11 7.627558 7.362620 7.511612 7.145889\n12 7.606965 7.239569 7.476154 7.265005\n13 7.616101 7.294466 7.467196 7.171395\n14 7.597951 7.271881 7.479806 7.187036\n15 7.596067 7.348779 7.446468 7.199063\n16 7.640890 7.128956 7.453126 7.204143\n17 7.575415 7.366839 7.470799 7.312720\n18 7.608315 7.280738 7.498315 7.156028\n19 7.593474 7.114045 7.473989 7.315470\n20 7.594700 7.359600 7.487534 7.317045\n21 7.614798 7.246894 7.456660 7.431237\n22 7.607819 7.255252 7.444764 7.221171\n23 7.610009 7.185242 7.503252 7.349578\n24 7.560010 7.188910 7.504737 7.182100\n25 7.626224 7.259911 7.496198 7.266678\n26 7.615960 7.302600 7.433851 7.345645\n27 7.609832 7.091500 7.445738 7.337904\n28 7.626666 7.276931 7.441374 7.391370\n29 7.598436 7.254692 7.464678 7.114766\n30 7.556404 7.147611 7.459120 7.238598\n31 7.575181 7.293017 7.434385 7.150378\n32 7.580022 7.470379 7.508724 7.182596\n33 7.589021 7.403243 7.468844 7.367467\n34 7.625055 7.184854 7.458165 7.168135\n35 7.612651 7.162224 7.523586 7.197273\n36 7.604204 7.301450 7.475374 7.387443\n37 7.601125 7.329756 7.441788 7.224172\n38 7.574534 7.137476 7.493522 6.991932\n39 7.646302 7.253615 7.455726 7.440136\n40 7.598518 7.248932 7.545624 7.248419\n41 7.603452 7.297836 7.453622 7.278437\n42 7.591664 7.354226 7.452288 7.333391\n43 7.610948 7.133287 7.472096 7.216578\n44 7.617624 7.170186 7.461299 7.154297\n45 7.634294 7.382895 7.469423 7.244824\n46 7.616935 7.333921 7.453229 7.300790\n47 7.576508 7.242801 7.427903 7.369563\n48 7.597225 7.280241 7.481485 7.226395\n49 7.591651 7.161913 7.471343 7.308058\n50 7.590347 7.261708 7.471020 7.125801\n\n$out_nc_quantile_y\n             1        4        2        3\n2.5%  7.559567 6.623770 7.276227 6.854545\n50%   7.601382 6.699447 7.324329 6.980813\n97.5% 7.639193 6.795013 7.376964 7.071822\n\n$out_cf_quantile_y\n             1        4        2        3\n2.5%  7.560513 7.117400 7.423830 7.095903\n50%   7.600148 7.266794 7.468020 7.241711\n97.5% 7.639406 7.411239 7.521131 7.438134\n\n$mediation\n        4         2         3 \n0.6333258 0.5223352 0.4399892 \n\n$mediation_quantile\n              4         2         3\n2.5%  0.4781255 0.3829605 0.2050149\n97.5% 0.7968414 0.7253825 0.6984420\n\n$mc_conv_info_m\n          [,1]     [,2]     [,3]     [,4]\n [1,] 7.723979 5.860656 7.069235 6.433601\n [2,] 7.700368 5.910926 7.087214 6.426046\n [3,] 7.707292 5.897989 7.082427 6.420352\n [4,] 7.705495 5.907370 7.079774 6.421104\n [5,] 7.703893 5.905221 7.078589 6.414830\n [6,] 7.702086 5.908586 7.077403 6.387218\n [7,] 7.696097 5.903654 7.077836 6.390850\n [8,] 7.692815 5.898737 7.075043 6.394151\n [9,] 7.691646 5.899766 7.075412 6.392675\n[10,] 7.691620 5.903479 7.074230 6.401085\n\n$mc_conv_info_y\n          [,1]     [,2]     [,3]     [,4]\n [1,] 7.581415 6.740819 7.320010 7.067418\n [2,] 7.575287 6.754420 7.324549 7.065989\n [3,] 7.577084 6.750919 7.323340 7.064912\n [4,] 7.576617 6.753458 7.322670 7.065054\n [5,] 7.576202 6.752876 7.322371 7.063868\n [6,] 7.575733 6.753787 7.322072 7.058646\n [7,] 7.574178 6.752452 7.322181 7.059333\n [8,] 7.573327 6.751122 7.321476 7.059957\n [9,] 7.573023 6.751400 7.321569 7.059678\n[10,] 7.573016 6.752405 7.321271 7.061268\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp$out_nc_y[,2] - fit_cfdecomp$out_nc_y[,1])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.8977706\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp$out_cf_y[,2] - fit_cfdecomp$out_nc_y[,1])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.3320029\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp$out_nc_y[,2] - fit_cfdecomp$out_cf_y[,2])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.5657677\n```\n\n\n:::\n\n```{.r .cell-code}\nfit_cfdecomp$mediation\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        4         2         3 \n0.6333258 0.5223352 0.4399892 \n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp$out_nc_y[,3] - fit_cfdecomp$out_nc_y[,1])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.2753829\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp$out_cf_y[,3] - fit_cfdecomp$out_nc_y[,1])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.1330466\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp$out_nc_y[,3] - fit_cfdecomp$out_cf_y[,3])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.1423364\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp$out_nc_y[,4] - fit_cfdecomp$out_nc_y[,1])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.623387\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp$out_cf_y[,4] - fit_cfdecomp$out_nc_y[,1])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.3488448\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp$out_nc_y[,4] - fit_cfdecomp$out_cf_y[,4])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.2745423\n```\n\n\n:::\n:::\n\n\n\n## `causal.decomp`\n\n- @Park2023a の方法。\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# smi \nfit.y <- lm(Y ~ X + T + X:T + L1 + L2 + C1 + C2 + C3 + C4, data = d)\nfit.m <- lm(T ~ X + C1 + C2 + C3 + C4, data = d)\n\nfit_smi <- smi(fit.y = fit.y,\n    fit.m = fit.m,\n    treat = \"X\", \n    sims = 100, \n    conf.level = .95,\n    conditional = TRUE,\n    covariates = 1,\n    # baseline covariatesを調整できる\n    #covariates = c(\"C1\", \"C2\", \"C3\", \"C4\"),\n    seed = 227,\n    )\n\nfit_smi\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nResults:\n\n                               estimate 95% CI Lower 95% CI Upper\nInitial Disparity   (1 vs 4) -0.8993401   -0.9925190  -0.79813505\nDisparity Remaining (1 vs 4) -0.3384430   -0.4880863  -0.14795873\nDisparity Reduction (1 vs 4) -0.5608971   -0.7346168  -0.42650061\nInitial Disparity   (1 vs 2) -0.2749659   -0.3378874  -0.19366549\nDisparity Remaining (1 vs 2) -0.1213246   -0.2203441  -0.05458727\nDisparity Reduction (1 vs 2) -0.1536412   -0.1896213  -0.10521328\nInitial Disparity   (1 vs 3) -0.6137425   -0.7326095  -0.47793913\nDisparity Remaining (1 vs 3) -0.3500123   -0.5151994  -0.08733348\nDisparity Reduction (1 vs 3) -0.2637302   -0.4880614  -0.11574038\n```\n\n\n:::\n:::\n\n\n\n- sensitivity analysis[@Park2023]\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsensRes <- sensitivity(boot.res = fit_smi, fit.m = fit.m, fit.y = fit.y, \n                       mediator = \"T\",\n                       covariates = c(\"C1\", \"C2\", \"C3\", \"C4\"), \n                       treat = \"X\",\n                       sel.lev.treat = \"4\", \n                       max.rsq = 0.3)\nplot(sensRes)\n```\n\n::: {.cell-output-display}\n![](Causal_Decomposition_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\n\n# binary mediator\n\n## `cfdecomp`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# cfd.mean\nset.seed(123456)\nfit_cfdecomp_b <-\n  cfd.mean(\n    formula.y = 'Y ~ X + T2 + X:T2 + L1 + L2 + C1 + C2 + C3 + C4',\n    formula.m = 'T2 ~ X + C1 + C2 + C3 + C4',\n    mediator = 'T2',\n    group = 'X',\n    data = d |> mutate(T2 = as.numeric(T2) - 1) |> data.frame(),\n    family.y = 'gaussian',\n    family.m = 'binomial',\n    bs.size = 50,\n    mc.size = 10,\n    alpha = 0.05\n  )\nmean(fit_cfdecomp_b$out_nc_y[,\"4\"] - fit_cfdecomp_b$out_nc_y[,\"1\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.8981701\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp_b$out_cf_y[,\"4\"] - fit_cfdecomp_b$out_nc_y[,\"1\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.5546351\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp_b$out_nc_y[,\"4\"] - fit_cfdecomp_b$out_cf_y[,\"4\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.343535\n```\n\n\n:::\n\n```{.r .cell-code}\nfit_cfdecomp_b$mediation\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        4         2         3 \n0.3828971 0.1298177 0.2061071 \n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp_b$out_nc_y[,\"2\"] - fit_cfdecomp_b$out_nc_y[,\"1\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.2774845\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp_b$out_cf_y[,\"2\"] - fit_cfdecomp_b$out_nc_y[,\"1\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.2419289\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp_b$out_nc_y[,\"2\"] - fit_cfdecomp_b$out_cf_y[,\"2\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.03555558\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp_b$out_nc_y[,\"3\"] - fit_cfdecomp_b$out_nc_y[,\"1\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.5849521\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp_b$out_cf_y[,\"3\"] - fit_cfdecomp_b$out_nc_y[,\"1\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.4655888\n```\n\n\n:::\n\n```{.r .cell-code}\nmean(fit_cfdecomp_b$out_nc_y[,\"3\"] - fit_cfdecomp_b$out_cf_y[,\"3\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.1193632\n```\n\n\n:::\n:::\n\n\n\n## `causal.decomp`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# smi\nfit.y <- lm(Y ~ X + T2 + X:T2 + L1 + L2 + C1 + C2 + C3 + C4, data = d)\nfit.m <- glm(T2 ~ X + C1 + C2 + C3 + C4, data = d, family = binomial(link = \"logit\"))\n\nfit_smi_b <- smi(fit.y = fit.y,\n               fit.m = fit.m,\n               treat = \"X\", \n               sims = 100, \n               conf.level = .95,\n               conditional = TRUE,\n               # covariates = 1,\n               covariates = c(\"C1\", \"C2\", \"C3\", \"C4\"),\n               seed = 123456)\nfit_smi_b\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nResults:\n\n                                estimate 95% CI Lower 95% CI Upper\nInitial Disparity   (1 vs 4) -0.95667843  -1.02938841  -0.88175003\nDisparity Remaining (1 vs 4) -0.61262729  -0.77966809  -0.46844380\nDisparity Reduction (1 vs 4) -0.34405113  -0.49650368  -0.21581205\nInitial Disparity   (1 vs 2) -0.31394841  -0.38058533  -0.26000373\nDisparity Remaining (1 vs 2) -0.27995004  -0.34624791  -0.22226331\nDisparity Reduction (1 vs 2) -0.03399837  -0.05003528  -0.02022012\nInitial Disparity   (1 vs 3) -0.59968604  -0.69525994  -0.49987857\nDisparity Remaining (1 vs 3) -0.48148718  -0.61387973  -0.32105036\nDisparity Reduction (1 vs 3) -0.11819886  -0.24676548  -0.03361808\n```\n\n\n:::\n\n```{.r .cell-code}\nsensRes <- sensitivity(boot.res = fit_smi_b, \n                       fit.m = fit.m, \n                       fit.y = fit.y, \n                       mediator = \"T2\",\n                       covariates = c(\"C1\", \"C2\", \"C3\", \"C4\"), \n                       treat = \"X\",\n                       sel.lev.treat = \"4\", \n                       max.rsq = 0.3)\nplot(sensRes)\n```\n\n::: {.cell-output-display}\n![](Causal_Decomposition_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n\n## `gapclosing`\n\n- @Lundberg2022a\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# gapclosing - regression\n# stochastic intervention\n# treatmentの割り当て確率の予測値を算出\nfit_glm <- glm(T2 ~ X + C1 + C2 + C3, data = d, family = binomial(link = \"logit\"))\n\n# 全員のtreatmentが1だった時の予測値\nassing_prob <- predict(fit_glm, newdata = d |> mutate(X = \"1\"), type = \"response\")\n\n# 予測値をもとにrandom draw\ndraw <- rbinom(n = nrow(d), size = 1, prob = assing_prob)\n\nfit_gapclosing <- \n  gapclosing(\n    data = d |> mutate(T2 = as.numeric(T2) - 1),\n    outcome_formula = Y ~ T2 * X + C1 + C2 + C3 + C4 + L1 + L2,\n    treatment_name = \"T2\",\n    category_name = \"X\",\n    counterfactual_assignments = draw # random draw\n  )\n\nfit_gapclosing\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nFactual mean outcomes:\n# A tibble: 4 × 2\n  X     estimate\n  <fct>    <dbl>\n1 1         7.60\n2 4         6.70\n3 2         7.32\n4 3         6.98\n\nCounterfactual mean outcomes (post-intervention means):\n# A tibble: 4 × 2\n  X     estimate\n  <fct>    <dbl>\n1 1         7.60\n2 4         7.03\n3 2         7.36\n4 3         7.11\n\nFactual disparities:\n# A tibble: 12 × 2\n   X     estimate\n   <chr>    <dbl>\n 1 1 - 4    0.899\n 2 1 - 2    0.275\n 3 1 - 3    0.614\n 4 4 - 1   -0.899\n 5 4 - 2   -0.624\n 6 4 - 3   -0.286\n 7 2 - 1   -0.275\n 8 2 - 4    0.624\n 9 2 - 3    0.339\n10 3 - 1   -0.614\n11 3 - 4    0.286\n12 3 - 2   -0.339\n\nCounterfactual disparities (gap-closing estimands):\n# A tibble: 12 × 2\n   X     estimate\n   <chr>    <dbl>\n 1 1 - 4   0.566 \n 2 1 - 2   0.241 \n 3 1 - 3   0.483 \n 4 4 - 1  -0.566 \n 5 4 - 2  -0.325 \n 6 4 - 3  -0.0830\n 7 2 - 1  -0.241 \n 8 2 - 4   0.325 \n 9 2 - 3   0.242 \n10 3 - 1  -0.483 \n11 3 - 4   0.0830\n12 3 - 2  -0.242 \n\nAdditive gap closed: Counterfactual - Factual\n# A tibble: 12 × 2\n   X     estimate\n   <chr>    <dbl>\n 1 1 - 4   0.334 \n 2 1 - 2   0.0339\n 3 1 - 3   0.131 \n 4 4 - 1  -0.334 \n 5 4 - 2  -0.300 \n 6 4 - 3  -0.203 \n 7 2 - 1  -0.0339\n 8 2 - 4   0.300 \n 9 2 - 3   0.0972\n10 3 - 1  -0.131 \n11 3 - 4   0.203 \n12 3 - 2  -0.0972\n\nProportional gap closed: (Counterfactual - Factual) / Factual\n# A tibble: 12 × 2\n   X     estimate\n   <chr>    <dbl>\n 1 1 - 4    0.371\n 2 1 - 2    0.123\n 3 1 - 3    0.214\n 4 4 - 1    0.371\n 5 4 - 2    0.480\n 6 4 - 3    0.710\n 7 2 - 1    0.123\n 8 2 - 4    0.480\n 9 2 - 3    0.287\n10 3 - 1    0.214\n11 3 - 4    0.710\n12 3 - 2    0.287\n```\n\n\n:::\n\n```{.r .cell-code}\ndisparityplot(fit_gapclosing, category_A = \"1\", category_B = \"4\")\n```\n\n::: {.cell-output-display}\n![](Causal_Decomposition_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n\n```{.r .cell-code}\ndisparityplot(fit_gapclosing, category_A = \"1\", category_B = \"2\")\n```\n\n::: {.cell-output-display}\n![](Causal_Decomposition_files/figure-html/unnamed-chunk-8-2.png){width=672}\n:::\n\n```{.r .cell-code}\ndisparityplot(fit_gapclosing, category_A = \"1\", category_B = \"3\")\n```\n\n::: {.cell-output-display}\n![](Causal_Decomposition_files/figure-html/unnamed-chunk-8-3.png){width=672}\n:::\n:::\n\n\n\n- 機械学習をつかったdoubly robustな方法も使える\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# gapclosing - ranger, doubly robust\nfit_gapclosing_ranger <- \n  gapclosing(\n  data = d |> mutate(T2 = as.numeric(T2) - 1),\n  outcome_formula = Y ~ T2 + X + C1 + C2 + C3 + C4 + L1 + L2,\n  treatment_formula = T2 ~ X + C1 + C2 + C3 + C4 + L1 + L2, \n  treatment_name = \"T2\",\n  treatment_algorithm = \"ranger\",\n  outcome_algorithm = \"ranger\",\n  category_name = \"X\",\n  counterfactual_assignments = rbinom(n = nrow(d), size = 1, prob = assing_prob) \n)\n\nfit_gapclosing\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nFactual mean outcomes:\n# A tibble: 4 × 2\n  X     estimate\n  <fct>    <dbl>\n1 1         7.60\n2 4         6.70\n3 2         7.32\n4 3         6.98\n\nCounterfactual mean outcomes (post-intervention means):\n# A tibble: 4 × 2\n  X     estimate\n  <fct>    <dbl>\n1 1         7.60\n2 4         7.03\n3 2         7.36\n4 3         7.11\n\nFactual disparities:\n# A tibble: 12 × 2\n   X     estimate\n   <chr>    <dbl>\n 1 1 - 4    0.899\n 2 1 - 2    0.275\n 3 1 - 3    0.614\n 4 4 - 1   -0.899\n 5 4 - 2   -0.624\n 6 4 - 3   -0.286\n 7 2 - 1   -0.275\n 8 2 - 4    0.624\n 9 2 - 3    0.339\n10 3 - 1   -0.614\n11 3 - 4    0.286\n12 3 - 2   -0.339\n\nCounterfactual disparities (gap-closing estimands):\n# A tibble: 12 × 2\n   X     estimate\n   <chr>    <dbl>\n 1 1 - 4   0.566 \n 2 1 - 2   0.241 \n 3 1 - 3   0.483 \n 4 4 - 1  -0.566 \n 5 4 - 2  -0.325 \n 6 4 - 3  -0.0830\n 7 2 - 1  -0.241 \n 8 2 - 4   0.325 \n 9 2 - 3   0.242 \n10 3 - 1  -0.483 \n11 3 - 4   0.0830\n12 3 - 2  -0.242 \n\nAdditive gap closed: Counterfactual - Factual\n# A tibble: 12 × 2\n   X     estimate\n   <chr>    <dbl>\n 1 1 - 4   0.334 \n 2 1 - 2   0.0339\n 3 1 - 3   0.131 \n 4 4 - 1  -0.334 \n 5 4 - 2  -0.300 \n 6 4 - 3  -0.203 \n 7 2 - 1  -0.0339\n 8 2 - 4   0.300 \n 9 2 - 3   0.0972\n10 3 - 1  -0.131 \n11 3 - 4   0.203 \n12 3 - 2  -0.0972\n\nProportional gap closed: (Counterfactual - Factual) / Factual\n# A tibble: 12 × 2\n   X     estimate\n   <chr>    <dbl>\n 1 1 - 4    0.371\n 2 1 - 2    0.123\n 3 1 - 3    0.214\n 4 4 - 1    0.371\n 5 4 - 2    0.480\n 6 4 - 3    0.710\n 7 2 - 1    0.123\n 8 2 - 4    0.480\n 9 2 - 3    0.287\n10 3 - 1    0.214\n11 3 - 4    0.710\n12 3 - 2    0.287\n```\n\n\n:::\n\n```{.r .cell-code}\ndisparityplot(fit_gapclosing_ranger, category_A = \"1\", category_B = \"4\")\n```\n\n::: {.cell-output-display}\n![](Causal_Decomposition_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n\n```{.r .cell-code}\ndisparityplot(fit_gapclosing_ranger, category_A = \"1\", category_B = \"2\")\n```\n\n::: {.cell-output-display}\n![](Causal_Decomposition_files/figure-html/unnamed-chunk-9-2.png){width=672}\n:::\n\n```{.r .cell-code}\ndisparityplot(fit_gapclosing_ranger, category_A = \"1\", category_B = \"3\")\n```\n\n::: {.cell-output-display}\n![](Causal_Decomposition_files/figure-html/unnamed-chunk-9-3.png){width=672}\n:::\n:::\n",
    "supporting": [
      "Causal_Decomposition_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}