{
  "hash": "c2d7e6dcba77b80880e14718b5cca103",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"複数時点での処置の因果効果の推定\"\ndate: 2024-02-22\ndate-modified: today\ncategories: [Causal Inference]\n---\n\n\n\n\n@Hernan2024 のPart3では、複数時点での処置の因果推論について議論されている。ここでは、IPW、g-formulaを用いた因果効果の推定を実際にやってみる。\n\n## 下準備\n\n### ライブラリなど\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(broom)\n\nkable <- partial(\n  knitr::kable,\n  digits = 3\n)\n\nset.seed(95)\n```\n:::\n\n\n\n\n\n### データの作成\n\n以下のDAGを考える[@Hernan2024, Figure 20.3]\n\n![](../images/L-TMLE-DAG.svg)\n\n\nTreatmentは$A_0$と$A_1$であるが、ここから$Y$へのpathはないので、因果効果は全ての組み合わせについて0になる\n\n具体的には、potential outcomeのすべての組み合わせについて、差分を取った値が0になる\n\n\\begin{align}\n\\mathrm{E}[Y^{0, 0} - Y^{1, 0}] &= 0\\\\ \n\\mathrm{E}[Y^{0, 0} - Y^{0, 1}] &= 0\\\\\n\\mathrm{E}[Y^{0, 0} - Y^{1, 1}] &= 0\\\\\n\\mathrm{E}[Y^{1, 0} - Y^{0, 1}] &= 0\\\\\n\\mathrm{E}[Y^{1, 0} - Y^{1, 1}] &= 0\\\\\n\\mathrm{E}[Y^{0, 1} - Y^{1, 1}] &= 0\n\\end{align}\n\n上記のDAGに合うように作成されたデータが以下である[@Hernan2024, Table 20.1]\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_agg <- \n  tribble(\n    ~N, ~A0, ~L1, ~A1, ~Y, \n    2400, 0, 0, 0, 84, \n    1600, 0, 0, 1, 84, \n    2400, 0, 1, 0, 52, \n    9600, 0, 1, 1, 52, \n    4800, 1, 0, 0, 76, \n    3200, 1, 0, 1, 76, \n    1600, 1, 1, 0, 44, \n    6400, 1, 1, 1, 44\n  )\n\ndata_agg |> kable()\n```\n\n::: {.cell-output-display}\n\n\n|    N| A0| L1| A1|  Y|\n|----:|--:|--:|--:|--:|\n| 2400|  0|  0|  0| 84|\n| 1600|  0|  0|  1| 84|\n| 2400|  0|  1|  0| 52|\n| 9600|  0|  1|  1| 52|\n| 4800|  1|  0|  0| 76|\n| 3200|  1|  0|  1| 76|\n| 1600|  1|  1|  0| 44|\n| 6400|  1|  1|  1| 44|\n\n\n:::\n:::\n\n\n\nこれを個人レベルのデータに変換\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_ind <- uncount(data_agg, N)\n\ndata_ind\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 32,000 × 4\n      A0    L1    A1     Y\n   <dbl> <dbl> <dbl> <dbl>\n 1     0     0     0    84\n 2     0     0     0    84\n 3     0     0     0    84\n 4     0     0     0    84\n 5     0     0     0    84\n 6     0     0     0    84\n 7     0     0     0    84\n 8     0     0     0    84\n 9     0     0     0    84\n10     0     0     0    84\n# ℹ 31,990 more rows\n```\n\n\n:::\n:::\n\n\n\n\n## 各処置の因果効果\n\n- 各処置の効果を確認\n- 処置からアウトカムへの直接のパスはないので、各時点の処置の因果効果も0になる\n\n### $A_0$の因果効果\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_ind |> \n  lm(Y ~ A0, data = _) |> \n  tidy() |> \n  kable()\n```\n\n::: {.cell-output-display}\n\n\n|term        | estimate| std.error| statistic| p.value|\n|:-----------|--------:|---------:|---------:|-------:|\n|(Intercept) |       60|     0.118|   507.077|       0|\n|A0          |        0|     0.167|     0.000|       1|\n\n\n:::\n:::\n\n\n\n### $A_1$の因果効果\n\n- 以下のバックドアが存在するので$L_1$を統制\n- $A_1 \\gets L_1 \\gets U_1 \\to Y$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_ind |> \n  lm(Y ~ A1 + L1, data = _) |>\n  tidy() |> \n  kable()\n```\n\n::: {.cell-output-display}\n\n\n|term        | estimate| std.error| statistic| p.value|\n|:-----------|--------:|---------:|---------:|-------:|\n|(Intercept) |   78.667|     0.040|  1943.969|       0|\n|A1          |    0.000|     0.050|     0.000|       1|\n|L1          |  -29.867|     0.049|  -611.652|       0|\n\n\n:::\n:::\n\n\n\n\n### collider bias\n\n- $A_0$の因果効果の推定において、$L_1$を条件づける\n- $A_0 \\to \\boxed{L_1} \\gets U_1 \\to Y$というパスが開いて、バイアスをもたらす\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_ind |> \n  lm(Y ~ A0 + L1, data = _) |> \n  tidy() |> \n  kable()\n```\n\n::: {.cell-output-display}\n\n\n|term        | estimate| std.error|     statistic| p.value|\n|:-----------|--------:|---------:|-------------:|-------:|\n|(Intercept) |       84|         0|  3.657678e+14|       0|\n|A0          |       -8|         0| -3.597746e+13|       0|\n|L1          |      -32|         0| -1.393401e+14|       0|\n\n\n:::\n:::\n\n\n\n\n\n## IPW\n\n- $\\bar{A}_k = (A_1, A_2, \\dots, A_k)$：$k$時点までの処置の履歴\n- $\\bar{L}_k = (L_1, L_2, \\dots, L_k)$：$k$時点までの共変量の履歴\n\n以下のウェイトを作成する\n\n$$\nW^{\\bar{A}_k} = \\prod_{k=0}^{K}\\frac{1}{f(A_k | \\bar{A}_{k-1},\\bar{L}_{k})}\n$$\n\n2時点では以下のように書ける\n\n$$\nW^{A_0, A_1} = \\frac{1}{f(A_0 | L_0)} \\times \\frac{1}{f(A_1 | A_0, L_0, L_1)}\n$$\n\nさらに、今回はベースライン共変量がない（$L_0 = \\varnothing$）ので\n\n$$\nW^{A_0, A_1} = \\frac{1}{f(A_0)} \\times \\frac{1}{f(A_1 | A_0, L_1)}\n$$\n\n\n\nStabilized IP weights も推定してみる\n\n\n$$\nSW^{A_0, A_1} = \\frac{f(A_0)}{f(A_0)} \\times \\frac{f(A_1 | A_0)}{f(A_1 | A_0, L_1)}\n$$\n\n### 各処置に対するウェイトの推定\n\nまずは、$f(A_0), f(A_1|A_0,L_1), f(A_1|A_0)$の3つを推定する\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 各時点の処置を予測するモデル\nmodel_A0 <- glm(A0 ~ 1, data = data_ind, family = \"binomial\")\nmodel_A1 <- glm(A1 ~ A0 * L1, data = data_ind, family = \"binomial\")\n\n# Stabilized Weightsの分子を予測するモデル\nmodel_A1_without_L1 <- glm(A1 ~ A0, data = data_ind, family = 'binomial')\n```\n:::\n\n\n\n予測値を算出\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nipw_data1 <-\n  data_ind |> \n  mutate(\n    # 各モデルの予測値を算出\n    pred_A0 = predict(model_A0, type = 'response'),\n    pred_A1 = predict(model_A1, type = 'response'),\n    pred_A1_without_L1 = predict(model_A1_without_L1, type = 'response'),\n  )\n\nipw_data1 |> \n  count(pick(everything())) |> \n  kable()\n```\n\n::: {.cell-output-display}\n\n\n| A0| L1| A1|  Y| pred_A0| pred_A1| pred_A1_without_L1|    n|\n|--:|--:|--:|--:|-------:|-------:|------------------:|----:|\n|  0|  0|  0| 84|     0.5|     0.4|                0.7| 2400|\n|  0|  0|  1| 84|     0.5|     0.4|                0.7| 1600|\n|  0|  1|  0| 52|     0.5|     0.8|                0.7| 2400|\n|  0|  1|  1| 52|     0.5|     0.8|                0.7| 9600|\n|  1|  0|  0| 76|     0.5|     0.4|                0.6| 4800|\n|  1|  0|  1| 76|     0.5|     0.4|                0.6| 3200|\n|  1|  1|  0| 44|     0.5|     0.8|                0.6| 1600|\n|  1|  1|  1| 44|     0.5|     0.8|                0.6| 6400|\n\n\n:::\n:::\n\n\n\n各処置に対するウェイトを作成\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nipw_data2 <-\n  ipw_data1 |> \n  mutate(\n    # A0に対するウェイト\n    ipw_A0 = case_when(\n      A0 == 1 ~ 1 / pred_A0,\n      A0 == 0 ~ 1 / (1 - pred_A0)\n    ),\n    # A0に対するSW\n    sw_A0 = case_when(\n      A0 == 1 ~ pred_A0 / pred_A0,\n      A0 == 0 ~ (1 - pred_A0) / (1 - pred_A0)\n    ),\n    # A1に対するウェイト\n    ipw_A1 = case_when(\n      A1 == 1 ~ 1 / pred_A1,\n      A1 == 0 ~ 1 / (1 - pred_A1)\n    ),\n    # A1に対するSW\n    sw_A1 = case_when(\n      A1 == 1 ~ pred_A1_without_L1 / pred_A1,\n      A1 == 0 ~ (1 - pred_A1_without_L1) / (1 - pred_A1)\n    ),\n  )\n\nipw_data2 |>\n  count(pick(everything())) |>\n  kable()\n```\n\n::: {.cell-output-display}\n\n\n| A0| L1| A1|  Y| pred_A0| pred_A1| pred_A1_without_L1| ipw_A0| sw_A0| ipw_A1| sw_A1|    n|\n|--:|--:|--:|--:|-------:|-------:|------------------:|------:|-----:|------:|-----:|----:|\n|  0|  0|  0| 84|     0.5|     0.4|                0.7|      2|     1|  1.667| 0.500| 2400|\n|  0|  0|  1| 84|     0.5|     0.4|                0.7|      2|     1|  2.500| 1.750| 1600|\n|  0|  1|  0| 52|     0.5|     0.8|                0.7|      2|     1|  5.000| 1.500| 2400|\n|  0|  1|  1| 52|     0.5|     0.8|                0.7|      2|     1|  1.250| 0.875| 9600|\n|  1|  0|  0| 76|     0.5|     0.4|                0.6|      2|     1|  1.667| 0.667| 4800|\n|  1|  0|  1| 76|     0.5|     0.4|                0.6|      2|     1|  2.500| 1.500| 3200|\n|  1|  1|  0| 44|     0.5|     0.8|                0.6|      2|     1|  5.000| 2.000| 1600|\n|  1|  1|  1| 44|     0.5|     0.8|                0.6|      2|     1|  1.250| 0.750| 6400|\n\n\n:::\n:::\n\n\n\n\n### IP weightの作成\n\n各時点のウェイトを掛け合わせる。たしかにSWのほうがウェイトが狭い範囲にまとまっていることがわかる。\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nipw_data3 <-\n  ipw_data2 |> \n  mutate(\n    # A0に対するウェイトとA1に対するウェイトをかけ算\n    ipw = ipw_A0 * ipw_A1,\n    sw = sw_A0 * sw_A1\n  ) \n\nipw_data3 |> \n  count(pick(everything())) |> \n  kable()\n```\n\n::: {.cell-output-display}\n\n\n| A0| L1| A1|  Y| pred_A0| pred_A1| pred_A1_without_L1| ipw_A0| sw_A0| ipw_A1| sw_A1|    ipw|    sw|    n|\n|--:|--:|--:|--:|-------:|-------:|------------------:|------:|-----:|------:|-----:|------:|-----:|----:|\n|  0|  0|  0| 84|     0.5|     0.4|                0.7|      2|     1|  1.667| 0.500|  3.333| 0.500| 2400|\n|  0|  0|  1| 84|     0.5|     0.4|                0.7|      2|     1|  2.500| 1.750|  5.000| 1.750| 1600|\n|  0|  1|  0| 52|     0.5|     0.8|                0.7|      2|     1|  5.000| 1.500| 10.000| 1.500| 2400|\n|  0|  1|  1| 52|     0.5|     0.8|                0.7|      2|     1|  1.250| 0.875|  2.500| 0.875| 9600|\n|  1|  0|  0| 76|     0.5|     0.4|                0.6|      2|     1|  1.667| 0.667|  3.333| 0.667| 4800|\n|  1|  0|  1| 76|     0.5|     0.4|                0.6|      2|     1|  2.500| 1.500|  5.000| 1.500| 3200|\n|  1|  1|  0| 44|     0.5|     0.8|                0.6|      2|     1|  5.000| 2.000| 10.000| 2.000| 1600|\n|  1|  1|  1| 44|     0.5|     0.8|                0.6|      2|     1|  1.250| 0.750|  2.500| 0.750| 6400|\n\n\n:::\n:::\n\n\n\n### Counterfactual meanの推定\n\nすべてのパターンで同じ値なので、差分をとれば0になる\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nres_ipw <- \n  ipw_data3 |>\n  # 重み付け推定\n  summarise(\n    CFmean_ipw = weighted.mean(Y, ipw), \n    CFmean_sw = weighted.mean(Y, sw), \n    .by = c(A0, A1),\n  ) |>\n  arrange(A0, A1)\n\nres_ipw |> \n  kable()\n```\n\n::: {.cell-output-display}\n\n\n| A0| A1| CFmean_ipw| CFmean_sw|\n|--:|--:|----------:|---------:|\n|  0|  0|         60|        60|\n|  0|  1|         60|        60|\n|  1|  0|         60|        60|\n|  1|  1|         60|        60|\n\n\n:::\n:::\n\n\n\n### Marginal structural modelの推定\n\n以下のようなmarginal structural modelを考えてみる\n\n$$\n\\mathrm{E}[Y^{A_0,A_1}] = \\beta_0 + \\beta_1 (A_0 + A_1)\n$$\n\n当然ながら$\\beta_1 = 0$となる\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nestimatr::lm_robust(Y ~ I(A0 + A1), data = ipw_data3, weight = ipw) |> \n  broom::tidy() |> \n  kable()\n```\n\n::: {.cell-output-display}\n\n\n|term        | estimate| std.error| statistic| p.value| conf.low| conf.high|    df|outcome |\n|:-----------|--------:|---------:|---------:|-------:|--------:|---------:|-----:|:-------|\n|(Intercept) |       60|     0.154|    389.52|       0|   59.698|    60.302| 31998|Y       |\n|I(A0 + A1)  |        0|     0.122|      0.00|       1|   -0.240|     0.240| 31998|Y       |\n\n\n:::\n\n```{.r .cell-code}\nestimatr::lm_robust(Y ~ I(A0 + A1), data = ipw_data3, weights = sw) |> \n  broom::tidy() |> \n  kable()\n```\n\n::: {.cell-output-display}\n\n\n|term        | estimate| std.error| statistic| p.value| conf.low| conf.high|    df|outcome |\n|:-----------|--------:|---------:|---------:|-------:|--------:|---------:|-----:|:-------|\n|(Intercept) |       60|     0.162|    369.84|       0|   59.682|    60.318| 31998|Y       |\n|I(A0 + A1)  |        0|     0.127|      0.00|       1|   -0.250|     0.250| 31998|Y       |\n\n\n:::\n:::\n\n\n\n\n\n## G-formula\n\nSequential exchangeabilityが成立しているとき、以下の式が成り立つ\n\n$$\n\\mathrm{E}[Y^{\\bar{A}_k}] = \\sum_\\bar{l}\\mathrm{E}[Y | \\bar{A}_k = \\bar{a}_k, \\bar{L}_k = \\bar{l}_k]\\prod_{k = 0}^K f(l_k | \\bar{a}_{k-1},\\bar{l}_{k-1})\n$$\n\n一般式はイカツイが、2時点かつ$L_0$がない今回の条件だと以下のようになる\n\n$$\n\\mathrm{E}[Y^{A_0,A_1}] = \\sum_{l_1} \\mathrm{E}[Y | A_0 = a_0,A_1 = a_1,L_1 = l_1]f(l_1 | a_0)\n$$\n\n### アウトカムと共変量の予測モデルを推定\n\n- $\\mathrm{E}[Y | A_0 = a_0,A_1 = a_1,L_1 = l_1]$と$f(l_1 | a_0)$のモデルを推定\n- 1時点の時と比較すると、共変量の予測モデルが必要になる点が新しい\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# アウトカムモデル\nmodel_Y <- lm(Y ~ A0*A1*L1, data = data_ind)\n# L1の予測モデル\nmodel_L1 <- lm(L1 ~ A0, data = data_ind)\n```\n:::\n\n\n\n### 共変量の予測値を推定\n\nひとまず、$A_0 = A_1 = 0$のときのpotential outcome$\\mathrm{E}[Y^{0,0}]$を推定することを考える\n\nまずサンプル全員の処置の値を$A_0 = A_1 = 0$で置き換える\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngform_data1 <- \n  data_ind |> \n  # 名前を変えておく\n  rename(A0_obs = A0, A1_obs = A1, L1_obs = L1, Y_obs = Y) |> \n  # 処置の値を変更\n  mutate(A0 = 0, A1 = 0)\n\ngform_data1 |> \n  count(pick(everything())) |> \n  kable()\n```\n\n::: {.cell-output-display}\n\n\n| A0_obs| L1_obs| A1_obs| Y_obs| A0| A1|    n|\n|------:|------:|------:|-----:|--:|--:|----:|\n|      0|      0|      0|    84|  0|  0| 2400|\n|      0|      0|      1|    84|  0|  0| 1600|\n|      0|      1|      0|    52|  0|  0| 2400|\n|      0|      1|      1|    52|  0|  0| 9600|\n|      1|      0|      0|    76|  0|  0| 4800|\n|      1|      0|      1|    76|  0|  0| 3200|\n|      1|      1|      0|    44|  0|  0| 1600|\n|      1|      1|      1|    44|  0|  0| 6400|\n\n\n:::\n:::\n\n\n\n次に、$A_0 = 0$の状況での$L_1$の値を予測する。これが$f(l_1 | 0)$\n\n$L^{A_0 = 0}$の値をシミュレートしているとも考えられる\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngform_data2 <- \n  gform_data1 |> \n  # 全員がA0 = 0のときの共変量L1の値をシミュレート\n  mutate(L1 = predict(model_L1, newdata = gform_data1))\n\ngform_data2 |> \n  count(pick(everything())) |> \n  kable()\n```\n\n::: {.cell-output-display}\n\n\n| A0_obs| L1_obs| A1_obs| Y_obs| A0| A1|   L1|    n|\n|------:|------:|------:|-----:|--:|--:|----:|----:|\n|      0|      0|      0|    84|  0|  0| 0.75| 2400|\n|      0|      0|      1|    84|  0|  0| 0.75| 1600|\n|      0|      1|      0|    52|  0|  0| 0.75| 2400|\n|      0|      1|      1|    52|  0|  0| 0.75| 9600|\n|      1|      0|      0|    76|  0|  0| 0.75| 4800|\n|      1|      0|      1|    76|  0|  0| 0.75| 3200|\n|      1|      1|      0|    44|  0|  0| 0.75| 1600|\n|      1|      1|      1|    44|  0|  0| 0.75| 6400|\n\n\n:::\n:::\n\n\n\n### アウトカムの予測値を推定\n\nさらに、シミュレートした$L_1$と、$A_0 = A_1 = 0$のもとでの$Y$の値を予測する。これが$\\mathrm{E}[Y | A_0 = 0,A_1 = 0,L_1 = l_1]$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngform_data3 <- \n  gform_data2 |> \n  mutate(Y = predict(model_Y, newdata = gform_data2))\n\ngform_data3 |> \n  count(pick(everything())) |> \n  kable()\n```\n\n::: {.cell-output-display}\n\n\n| A0_obs| L1_obs| A1_obs| Y_obs| A0| A1|   L1|  Y|    n|\n|------:|------:|------:|-----:|--:|--:|----:|--:|----:|\n|      0|      0|      0|    84|  0|  0| 0.75| 60| 2400|\n|      0|      0|      1|    84|  0|  0| 0.75| 60| 1600|\n|      0|      1|      0|    52|  0|  0| 0.75| 60| 2400|\n|      0|      1|      1|    52|  0|  0| 0.75| 60| 9600|\n|      1|      0|      0|    76|  0|  0| 0.75| 60| 4800|\n|      1|      0|      1|    76|  0|  0| 0.75| 60| 3200|\n|      1|      1|      0|    44|  0|  0| 0.75| 60| 1600|\n|      1|      1|      1|    44|  0|  0| 0.75| 60| 6400|\n\n\n:::\n:::\n\n\n\n### サンプル全体で平均する\n\n以下のように変形できるので、アウトカムの予測値をサンプル全体で平均すればよい\n\n$$\n\\sum_{l_1} \\mathrm{E}[Y | A_0 = a_0,A_1 = a_1,L_1 = l_1]f(l_1 | a_0) = \\mathrm{E}[\\mathrm{E}[Y | A_0 = a_0, A_1 = a_1, L_1]]\n$$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngform_data3 |> \n  summarise(CFmean = mean(Y), .by = c(A0, A1)) |> \n  kable()\n```\n\n::: {.cell-output-display}\n\n\n| A0| A1| CFmean|\n|--:|--:|------:|\n|  0|  0|     60|\n\n\n:::\n:::\n\n\n\n### すべてのパターンを推定\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 処置のパターンごとにデータを4つ作成\nlist(\n  data_ind |> mutate(A0 = 0, A1 = 0),\n  data_ind |> mutate(A0 = 0, A1 = 1),\n  data_ind |> mutate(A0 = 1, A1 = 0),\n  data_ind |> mutate(A0 = 1, A1 = 1)\n) |>\n  # 各パターンにおいてL1の値を予測\n  map(\n    \\(data) data |> mutate(L1 = predict(model_L1, newdata = data))\n  ) |>\n  # 予測したL1の値とトリートメントを用いて、Potential Outcomeを予測\n  map(\n    \\(data) data |> mutate(Y_pred = predict(model_Y, newdata = data))\n  ) |> \n  bind_rows() |> \n  summarise(\n    CFmean = mean(Y_pred),\n    .by = c(A0, A1)\n  ) |> \n  kable()\n```\n\n::: {.cell-output-display}\n\n\n| A0| A1| CFmean|\n|--:|--:|------:|\n|  0|  0|     60|\n|  0|  1|     60|\n|  1|  0|     60|\n|  1|  1|     60|\n\n\n:::\n:::\n\n\n\n\n共変量が増えるとそれだけシミュレートする変数が増えるので大変そう...\n\n\n\n## 疑問点＆残された課題\n\n- Marginal structural modelのパラメータはg-formulaでは推定できないのか？\n  - L-TMLEの推定ができるパッケージではMSMのパラメータも推定できる\n- G-formulaとRegression with residualsの関係が気になった\n  - どちらも共変量のモデリングを行うが、g-fomulaは予測値を用いるのに対して、RWRは残差の方を用いる\n- 本当は今回の課題でTMLEまで実装したかった\n  - 理解が追いつかず断念\n",
    "supporting": [
      "L-TMLE_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}