{
  "hash": "2ecf173e210dc57c8076b906395d3fb9",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: 手動でSuperlearner\ndate: 2024-11-01\ncategories: [Others]\n---\n\n\n\n## 文献\n\nNaimi, Ashley I. & Laura B. Balzer, 2018, \"Stacked Generalization: An Introduction to Super Learning,\" _European Journal of Epidemiology_, 33(5): 459–64, (<https://doi.org/10.1007/s10654-018-0390-z>).\n\n## パッケージ読み込み\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(rsample)\nlibrary(sl3)\nlibrary(future)\nlibrary(earth)\n\ntheme_set(theme_bw(base_family = 'Noto Sans JP'))\n\n# 並列化\nplan(multisession(workers = 5))\n```\n:::\n\n\n\n\n## データ生成\n\n\\begin{align}\nY = 5 + 4\\sqrt{9x} \\times I(x<2) + I(x\\geq2) \\times (|x-6|^{2}) + \\epsilon\n\\end{align}\n\n- $I()$：Indicator function（TRUEなら1、FALSEなら0となる）\n- $\\epsilon \\sim \\mathrm{Labpace}(0, 1)$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(12345)\n\ndata <- tibble(\n  x = runif(1000, 0, 8),\n  epsilon = rmutil::rlaplace(1000, 0, 1)\n) |> \n  mutate(\n    y_truth = 5 + 4*sqrt(9 * x)*as.numeric(x<2) + as.numeric(x>=2)*(abs(x-6)^(2)),\n    y = y_truth + epsilon\n  )\n```\n:::\n\n\n\n- データの確認（gamが優秀）\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata |> \n  ggplot(aes(x, y)) +\n  geom_point(alpha = 0.3)+\n  geom_line(\n    data = tibble(\n      x = seq(0, 8, 0.1), \n      y = 5 + 4*sqrt(9 * x)*as.numeric(x<2) + as.numeric(x>=2)*(abs(x-6)^(2))\n    ), \n    aes(x, y), \n    color = \"black\"\n  )+\n  geom_smooth(method = 'gam', formula = y ~ s(x, bs = 'cs'), se = FALSE)\n```\n\n::: {.cell-output-display}\n![](Manual-Superlearner_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\n- cross-fitの準備\n- データを5分割\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- \n  vfold_cv(data, v = 5) |> \n  mutate(\n    train = map(splits, analysis),\n    test = map(splits, assessment)\n  )\n\ndf\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#  5-fold cross-validation \n# A tibble: 5 × 4\n  splits            id    train              test              \n  <list>            <chr> <list>             <list>            \n1 <split [800/200]> Fold1 <tibble [800 × 4]> <tibble [200 × 4]>\n2 <split [800/200]> Fold2 <tibble [800 × 4]> <tibble [200 × 4]>\n3 <split [800/200]> Fold3 <tibble [800 × 4]> <tibble [200 × 4]>\n4 <split [800/200]> Fold4 <tibble [800 × 4]> <tibble [200 × 4]>\n5 <split [800/200]> Fold5 <tibble [800 × 4]> <tibble [200 × 4]>\n```\n\n\n:::\n:::\n\n\n\n## 手動でSuper learner\n\n- Cross-fitで各モデルの予測値を計算\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nres <- \n  df |> \n  mutate(\n    model_earth = map(\n      train, \\(data) \n      earth(y ~ x, degree = 2, penalty = 3, nk = 21, pmethod = \"backward\", data = data)\n    ),\n    model_lm = map(\n      train, \\(data) \n      lm(y ~ poly(x, degree = 4), data = data)\n    ),\n    pred_earth = map2(model_earth, test, \\(x, y) predict(x, newdata = y)[,1]),\n    pred_lm = map2(model_lm, test, \\(x, y) predict(x, newdata = y))\n  )\n```\n:::\n\n\n\n- 各モデルの予測値を独立変数、アウトカムを目的変数とした回帰モデルを、Non-negative least squaresにより推定\n- パフォーマンスの良いモデルにより大きい重みがつくように、重みを推定\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nweight <-\n  nnls::nnls(\n    A = \n      res |> \n      select(pred_earth, pred_lm) |> \n      unnest(cols = c(pred_earth, pred_lm)) |> \n      as.matrix(), \n    b = data$y\n  ) |> \n  pluck('x')\n\nweight\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.2467513 0.5523356\n```\n\n\n:::\n\n```{.r .cell-code}\n# weightを、足して1になるように基準化\nweight_normalized <- weight / sum(weight)\nweight_normalized\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.3087915 0.6912085\n```\n\n\n:::\n:::\n\n\n\n## 予測値の計算\n\n1. 全データを用いて、各モデルの予測値を計算\n1. 先ほど推定した重みを用いて、各モデルの予測値を組み合わせた予測値を計算\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# サンプル全体での予測値を計算\nmodel1 <- earth(y ~ x, degree = 2, penalty = 3, nk = 21, pmethod = \"backward\", data = data)\nmodel2 <- lm(y ~ poly(x, degree = 4), data = data)\n\nresult <- \n  data |> \n  mutate(\n    pred1 = predict(model1)[,1],\n    pred2 = predict(model2)\n  ) |> \n  mutate(\n    pred_sl = weight_normalized[1]*pred1 + weight_normalized[2]*pred2\n  )\n\nresult\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,000 × 7\n       x epsilon y_truth      y pred1 pred2 pred_sl\n   <dbl>   <dbl>   <dbl>  <dbl> <dbl> <dbl>   <dbl>\n 1  5.77  -1.86     5.05  3.19   5.21  4.84    4.96\n 2  7.01   1.16     6.01  7.18   6.36  6.57    6.51\n 3  6.09  -4.30     5.01  0.712  5.16  5.00    5.05\n 4  7.09  -0.353    6.19  5.83   6.56  6.75    6.69\n 5  3.65   0.465   10.5  11.0    9.98 11.0    10.7 \n 6  1.33  -0.677   18.8  18.2   20.0  19.5    19.7 \n 7  2.60  -1.05    16.6  15.5   17.5  16.8    17.0 \n 8  4.07   0.535    8.71  9.25   8.73  8.90    8.85\n 9  5.82   7.05     5.03 12.1    5.20  4.85    4.96\n10  7.92   2.30     8.68 11.0    8.52  8.20    8.30\n# ℹ 990 more rows\n```\n\n\n:::\n:::\n\n\n\n- 結果のプロット\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresult |> \n  pivot_longer(\n    cols = c(pred1, pred2, pred_sl), \n    names_to = 'model', \n    values_to = 'prediction'\n  ) |> \n  ggplot(aes(x, y)) +\n  geom_point(alpha = 0.05)+\n  geom_line(aes(x, prediction, color = model))+\n  geom_line(\n    data = tibble(\n      x = seq(0, 8, 0.1), \n      y = 5 + 4*sqrt(9 * x)*as.numeric(x<2) + as.numeric(x>=2)*(abs(x-6)^(2))\n    ), \n    aes(x, y), \n    color = \"black\"\n  )\n```\n\n::: {.cell-output-display}\n![](Manual-Superlearner_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n\n## `sl3`でSuper learner\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntask <- sl3_Task$new(\n  data = data, outcome = \"y\", covariates = \"x\", outcome_type = 'continuous', folds = 5\n)\n\nsl_lib <- \n  Lrnr_sl$new(\n    learners = Stack$new(\n      Lrnr_earth$new(degree = 4), \n      Lrnr_gam$new(),\n      Lrnr_mean$new(),\n      Lrnr_xgboost$new(nrounds = 100, max_depth = 3, eta = 0.3),\n      Lrnr_bartMachine$new(serialize = TRUE)\n    ),\n    metalearner = Lrnr_nnls$new(convex = TRUE)\n  )\n\nfit <- sl_lib$train(task)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nserializing in order to be saved for future R sessions...done\nserializing in order to be saved for future R sessions...done\nserializing in order to be saved for future R sessions...done\nserializing in order to be saved for future R sessions...done\nserializing in order to be saved for future R sessions...done\nserializing in order to be saved for future R sessions...done\n```\n\n\n:::\n\n```{.r .cell-code}\nfit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Cross-validated risk:\"\nKey: <learner>\n                           learner coefficients       MSE        se   fold_sd\n                            <fctr>        <num>     <num>     <num>     <num>\n1: Lrnr_earth_4_3_backward_0_1_0_0  0.000000000  2.439980 0.1491178 0.5590197\n2:       Lrnr_gam_NULL_NULL_GCV.Cp  0.655902673  2.156928 0.1368631 0.5163999\n3:                       Lrnr_mean  0.000000000 30.590277 1.0519860 2.2451721\n4:        Lrnr_xgboost_100_1_3_0.3  0.004810931  2.437071 0.1515221 0.5109703\n5:           Lrnr_bartMachine_TRUE  0.339286396  2.220592 0.1429715 0.4626009\n   fold_min_MSE fold_max_MSE\n          <num>        <num>\n1:     1.969880     3.393874\n2:     1.767867     3.055205\n3:    27.834174    33.991665\n4:     2.098941     3.308421\n5:     1.856710     3.012823\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nresult |> \n  mutate(\n    pred_sl3 = fit$predict(task = task)\n  ) |> \n  pivot_longer(\n    cols = c(pred1, pred2, pred_sl, pred_sl3), \n    names_to = 'model', \n    values_to = 'prediction'\n  ) |> \n  ggplot(aes(x, y)) +\n  geom_point(alpha = 0.05)+\n  geom_line(\n    data = tibble(\n      x = seq(0, 8, 0.1), \n      y = 5 + 4*sqrt(9 * x)*as.numeric(x<2) + as.numeric(x>=2)*(abs(x-6)^(2))\n    ), \n    aes(x, y), \n    color = \"black\"\n  )+\n  geom_line(aes(x, prediction, color = model))\n```\n\n::: {.cell-output-display}\n![](Manual-Superlearner_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "Manual-Superlearner_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}