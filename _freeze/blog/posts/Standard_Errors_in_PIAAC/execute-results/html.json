{
  "hash": "502c8bd51e6e011411623184a300a5aa",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"PIAAC、PISAの標準誤差\"\ndate: 2024-09-21\ncategories: [Statistics]\n---\n\n\n\n## 前準備\n\n### パッケージ読み込み\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(haven)\nlibrary(survey)\nlibrary(srvyr)\nlibrary(kamaken)\n\nkable <- partial(knitr::kable, digits = 3)\n```\n:::\n\n\n\n### データ読み込み\n\n- PIAAC 1st cycleの日本データ（SPSS形式）\n  - <https://webfs.oecd.org/piaac/puf-data/SPSS/prgjpnp1.sav>\n- 変数の名前を適宜変更しておく\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- read_sav('data/prgjpnp1.sav')\n# 直接読み込むこともできるが多少時間がかかる\n# data <- read_sav('https://webfs.oecd.org/piaac/puf-data/SPSS/prgjpnp1.sav')\n\ndf <- \n  data |> \n  # 変数を絞る\n  select(\n    country = CNTRYID, \n    id = SEQID,\n    age = AGE_R, \n    gender = GENDER_R, \n    region = REG_TL2, \n    edu = B_Q01a, \n    medu = J_Q06b, \n    fedu = J_Q07b, \n    numbooks = J_Q08,\n    sampling_weight = SPFWT0, \n    # 読解力、数的思考力、ITスキルのスコア\n    matches('^PV'), \n    # Replicate weights\n    matches(str_c('SPFWT', 1:80)),\n    VEMETHOD\n  ) |> \n  # 変数名を小文字に変換\n  rename_with(str_to_lower) |> \n  as_factor() |> \n  mutate(\n    age = as.character(age) |> parse_double(),\n    # 年齢をカテゴリ化\n    agegroup = cut(\n      age,\n      breaks = c(15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65),\n      labels = c('16-20', '21-25', '26-30', '31-35', '36-40', '41-45', '46-50', '51-55', '56-60', '61-65')\n    ),\n    # 大学卒業ダミー\n    univ = case_match(\n      edu,\n      'No formal qualification or below ISCED 1' ~ 0,\n      'ISCED 2' ~ 0,\n      'ISCED 3C shorter than 2 years' ~ 0,\n      'ISCED 3C 2 years or more' ~ 0,\n      'ISCED 3A-B' ~ 0,\n      'ISCED 3 (without distinction A-B-C, 2y+)' ~ 0,\n      'ISCED 4 (without distinction A-B-C)' ~ 0,\n      'ISCED 5B' ~ 0,\n      'ISCED 5A, bachelor degree' ~ 1,\n      'ISCED 5A, master degree' ~ 1,\n      'ISCED 6' ~ 1,\n      'Foreign qualification' ~ NA,\n      NA ~ NA\n    )\n  )\n```\n:::\n\n\n\n## 標準誤差の推定式\n\n- jackknife法による標準誤差\n\n$$\n\\mathrm{SE}_\\theta = \\sqrt{h\\sum_{r=1}^{R} (\\hat{\\theta}_{(r)} - \\hat{\\theta})^2}\n$$\n\n- $R$：反復回数、replicate weightの数（PIAACは80）\n- $\\hat{\\theta}_{(r)}$：$r$番目のreplicate weightを用いた推定値\n- $\\hat{\\theta}$：全体の推定値（サンプリングウェイトを用いた推定値）\n- $h$：乗数、 Jackknife法のバリエーションによって異なる\n  - JK1の場合は$h = \\frac{R-1}{R}$\n  - JK2の場合は$h = 1$\n\n## 分析\n\n- 点推定値\n- jackknife法による標準誤差\n\nの二つを推定する\n\n### packageによる推定\n\n- `survey`パッケージ（のラッパーの`srvyr`パッケージ）を用いる\n- `type`: 標準誤差の推定方法\n  - PIAACでは`JK1`の国と`JK2`の国が混在（変数`VEMETHOD`にどちらを使用すれば良いかが書かれている）\n  - 日本は`JK2`で推定する\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_design <- \n  df |> \n  # 調査デザインの設定\n  as_survey_rep(\n    weights = sampling_weight, \n    repweights = matches('spfwt'), \n    type = 'JK2',\n    mse = TRUE\n  )\n\nresult_literacy <- \n  df_design |> \n  # 読解力の各PVごとに平均値と標準誤差を計算\n  summarise(\n    across(matches('pvlit'), \\(x) survey_mean(x, na.rm = TRUE))\n  ) \n  \n# 結果の整理\npackage <- \n  result_literacy |>\n  rename_with(\\(x) str_replace(x, '(\\\\d)$', '\\\\1_estimate')) |>\n  # 縦持ちに変換\n  pivot_longer(\n    cols = matches('pvlit'),\n    names_to = c('literacy', '.value'),\n    names_pattern = '(pvlit\\\\d{1,2})_(.+)',\n  ) \n\nkable(package)\n```\n\n::: {.cell-output-display}\n\n\n|literacy | estimate|    se|\n|:--------|--------:|-----:|\n|pvlit1   |  296.468| 0.549|\n|pvlit2   |  296.143| 0.529|\n|pvlit3   |  296.184| 0.543|\n|pvlit4   |  296.111| 0.541|\n|pvlit5   |  296.172| 0.522|\n|pvlit6   |  296.936| 0.543|\n|pvlit7   |  295.561| 0.481|\n|pvlit8   |  296.827| 0.518|\n|pvlit9   |  296.188| 0.521|\n|pvlit10  |  295.832| 0.542|\n\n\n:::\n:::\n\n\n\n### 手作業による推定\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npoint_estimate <-\n  df |> \n  select(sampling_weight, matches('(pvlit|spfwt)')) |> \n  summarise(\n    across(\n      matches('pvlit'), \n      \\(x) weighted.mean(x, w = sampling_weight, na.rm = TRUE), \n      .names = '{.col}_estimate'\n    )\n  ) |> \n  pivot_longer(\n    cols = matches('pvlit'),\n    names_to = c('literacy', '.value'),\n    names_pattern = '(pvlit\\\\d{1,2})_(.+)',\n  )\n  \n# jackknife法に用いるウェイト（80個）\njackweight <- select(df, matches('spfwt'))\n\njack_estimate <-\n  # 各ウェイトを用いて、それぞれのPVの平均値を計算\n  map(\n    jackweight, \\(weight) \n    df |> \n      summarise(\n        across(\n          matches('pvlit'),\n          \\(x) weighted.mean(x, w = weight, na.rm = TRUE),\n          .names = '{.col}_jack'\n        )\n      )\n  ) |> \n  bind_rows(.id = 'replicate') |> \n  pivot_longer(\n    cols = matches('pvlit'),\n    names_to = c('literacy', '.value'),\n    names_pattern = '(pvlit\\\\d{1,2})_(.+)',\n  )\n\nhandmade <- \n  # 点推定値にジャックナイフウェイトを用いた推定値を結合\n  left_join(\n    point_estimate, \n    jack_estimate, \n    by = join_by(literacy)\n  ) |> \n  # 標準誤差の計算\n  summarise(\n    estimate = mean(estimate),\n    se = sqrt(sum((estimate - jack)^2)),\n    .by = literacy\n  )\n\nkable(handmade)\n```\n\n::: {.cell-output-display}\n\n\n|literacy | estimate|    se|\n|:--------|--------:|-----:|\n|pvlit1   |  296.468| 0.549|\n|pvlit2   |  296.143| 0.529|\n|pvlit3   |  296.184| 0.543|\n|pvlit4   |  296.111| 0.541|\n|pvlit5   |  296.172| 0.522|\n|pvlit6   |  296.936| 0.543|\n|pvlit7   |  295.561| 0.481|\n|pvlit8   |  296.827| 0.518|\n|pvlit9   |  296.188| 0.521|\n|pvlit10  |  295.832| 0.542|\n\n\n:::\n:::\n\n\n\n### 結果の比較\n\n- 結果は一致する\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nleft_join(\n  package, \n  handmade, \n  by = join_by(literacy),\n  suffix = c('_package', '_handmade')\n) |> \n  select(literacy, estimate_package, estimate_handmade, se_package, se_handmade) |>\n  mutate(\n    diff_estimate = estimate_package - estimate_handmade,\n    diff_se = se_package - se_handmade\n  ) |> \n  kable()\n```\n\n::: {.cell-output-display}\n\n\n|literacy | estimate_package| estimate_handmade| se_package| se_handmade| diff_estimate| diff_se|\n|:--------|----------------:|-----------------:|----------:|-----------:|-------------:|-------:|\n|pvlit1   |          296.468|           296.468|      0.549|       0.549|             0|       0|\n|pvlit2   |          296.143|           296.143|      0.529|       0.529|             0|       0|\n|pvlit3   |          296.184|           296.184|      0.543|       0.543|             0|       0|\n|pvlit4   |          296.111|           296.111|      0.541|       0.541|             0|       0|\n|pvlit5   |          296.172|           296.172|      0.522|       0.522|             0|       0|\n|pvlit6   |          296.936|           296.936|      0.543|       0.543|             0|       0|\n|pvlit7   |          295.561|           295.561|      0.481|       0.481|             0|       0|\n|pvlit8   |          296.827|           296.827|      0.518|       0.518|             0|       0|\n|pvlit9   |          296.188|           296.188|      0.521|       0.521|             0|       0|\n|pvlit10  |          295.832|           295.832|      0.542|       0.542|             0|       0|\n\n\n:::\n:::\n\n\n\n### PVの統合\n\n- 読解力、数的思考力などは複数のPV（Plausible Values）という形で測定\n- PVを用いた分析の結果は、多重代入法の要領で統合が可能\n- 詳しくは @vanBuuren2018 などを参照\n\n- 平均値\n\n$$\n\\hat{\\theta} = \\frac{1}{M} \\sum_{m=1}^{M} \\hat{\\theta}_{(m)}\n$$\n\n- 各PVにおいて生じる分散の平均（分散の平均値）\n\n$$\n\\bar{U} = \\frac{1}{M} \\sum_{m=1}^{M} \\hat{U}_{(m)}\n$$\n\n- PV間で生じる分散（平均値の分散）\n\n$$\nB = \\frac{1}{M-1} \\sum_{m=1}^{M} (\\hat{\\theta}_{(m)} - \\hat{\\theta})^2\n$$\n\n- 統合された推定値の標準誤差\n\n$$\n\\hat{SE} = \\sqrt{\\bar{U} + \\left(1 + \\frac{1}{M}\\right)B}\n$$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npool_rubin <- function(.tibble, term = NULL) {\n  .tibble |> \n    mutate(variance = std.error^2) |>\n    summarise(\n      M = n(),\n      estimate.combined = mean(estimate),\n      Vw = sum(variance) / M,\n      Vb = sum((estimate - mean(estimate)) ^ 2) / (M - 1),\n      Vt = Vw + (1 + 1 / M) * Vb,\n      SE.combined = sqrt(Vt), \n      .by = {{term}}\n    ) |> \n    # 信頼区間計算\n    mutate(\n      conf.low = estimate.combined - qnorm(1 - .025)*SE.combined,\n      conf.high = estimate.combined + qnorm(1 - .025)*SE.combined\n    ) |> \n    select({{term}}, M, estimate = estimate.combined, std.error = SE.combined, conf.low, conf.high)\n} \n```\n:::\n\n\n\n- 結果の統合\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhandmade |> \n  rename(std.error = se) |> \n  pool_rubin() |> \n  kable()\n```\n\n::: {.cell-output-display}\n\n\n|  M| estimate| std.error| conf.low| conf.high|\n|--:|--------:|---------:|--------:|---------:|\n| 10|  296.242|     0.685|    294.9|   297.585|\n\n\n:::\n:::\n\n\n\n\n## より複雑なケース\n\n### 因果効果の推定\n\n- 高等教育進学が読解力に与える因果効果の推定\n- G-computation[@Hernan2020; @Robins1986]によるATEの推定\n- 関数定義\n  - `.outcome`：アウトカム変数\n  - `.treatment`：0-1の二値変数\n  - `.formula_rhs`：回帰式の右辺を指定\n    - ` ~ treatment + covariate1 + covariate2 + ...`のような形\n    - 固定効果も指定可能：` ~ 1 | treatment + fixed_effect1 + fixed_effect2 + ...`\n    - `fixest`パッケージでの`formula`に準拠\n  - `.estimand`：推定対象\n    - `cfmean`：$\\mathrm{E}[Y^1]$と$\\mathrm{E}[Y^0]$\n    - `ATE`：平均処置効果\n  - `.weights`：サンプリングウェイト\n  - `.repweights`：ジャックナイフ法に用いるreplicate weights\n  - `.type`：ジャックナイフ法のタイプ\n  - `.by`：効果の異質性を見たい変数を指定（`NULL`なら集団全体）\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# ATEをjackknife推定する関数\npiaac_ATE_jack <- \n  function(.data, .outcome, .treatment, .formula_rhs, .estimand = c('cfmean', 'ATE'), .weights, .repweights, .type = c('JK1', 'JK2'), .by = NULL) {\n  .treatment <- enquo(.treatment)\n  .weights <- enquo(.weights)\n  .repweights <- select(.data, {{.repweights}}) |> names()\n  .by <- enquo(.by)\n  # scale parameterの設定\n  scale <- case_when(\n    .type == 'JK1' ~ (length(.repweights) - 1) / length(.repweights), \n    .type == 'JK2' ~ 1\n  )\n  # formulaの左辺に.outcomeを追加\n  .formula <- rlang::`f_lhs<-`(.formula_rhs, ensym(.outcome))\n  \n  # OLS推定\n  fit <-\n    fixest::feols(\n      .formula,\n      data = .data,\n      combine.quick = FALSE,\n      weights = str_c('~', rlang::as_name(.weights)) |> as.formula()\n    )\n  # 点推定値\n  res_point_estimate <-\n    bind_rows(\n      broom::augment(fit, newdata = .data |> mutate(!!.treatment := 0)),\n      broom::augment(fit, newdata = .data |> mutate(!!.treatment := 1)),\n    ) |>\n    group_by(pick(!!.treatment, !!.by)) |>\n    summarise(\n      estimate = weighted.mean(.fitted, !!.weights),\n      .groups = 'drop'\n    ) |> \n    mutate(estimand = 'cfmean')\n  if (.estimand == 'ATE') {\n    res_point_estimate <-\n      res_point_estimate |>\n      mutate(estimand = 'ATE') |> \n      pivot_wider(names_from = !!.treatment, values_from = estimate) |>\n      mutate(estimate = `1` - `0`) |>\n      select(!c(`0`, `1`))\n  }\n\n  # 各replicate weightを使ってOLS推定し、jackknifeサンプルにおける点推定値を計算する\n  fit_jack <-\n    furrr::future_map(\n      .repweights, .progress = TRUE, .options = furrr::furrr_options(seed = TRUE), \\(w) {\n        gc()\n        # weightが0のデータを削除\n        df_jack <- .data |> filter(!!ensym(w) != 0)\n        # OLSで推定\n        fit <-\n          fixest::feols(\n            .formula,\n            data = df_jack,\n            weights = str_c('~', w) |> as.formula(),\n            combine.quick = FALSE\n          )\n        # Y^1とY^0を計算\n        res_point_estimate_jack <-\n          bind_rows(\n            broom::augment(fit, newdata = df_jack |> mutate(!!.treatment := 0)),\n            broom::augment(fit, newdata = df_jack |> mutate(!!.treatment := 1)),\n          ) |>\n          group_by(pick(!!.treatment, !!.by)) |>\n          summarise(\n            estimate = weighted.mean(.fitted, !!ensym(w)),\n            .groups = 'drop'\n          ) |> \n          mutate(estimand = 'cfmean')\n        if (.estimand == 'ATE') {\n          res_point_estimate_jack <-\n            res_point_estimate_jack |>\n            mutate(estimand = 'ATE') |>\n            pivot_wider(names_from = !!.treatment, values_from = estimate) |>\n            mutate(estimate = `1` - `0`) |>\n            select(!c(`0`, `1`))\n        }\n        res_point_estimate_jack\n      }\n    )\n  # 結果の統合\n  results <-\n    fit_jack |>\n    bind_rows(.id = 'no') |>\n    rename(estimate_jack = estimate) |>\n    # 点推定値をくっつける\n    left_join(res_point_estimate |> rename(estimate_all = estimate))\n\n  # jackknife標準誤差の計算\n  if (.estimand == 'cfmean') {\n    results <-\n      results |>\n      group_by(pick(estimand, !!.treatment, !!.by)) |>\n      summarise(\n        estimate = mean(estimate_all),\n        std.error = sqrt(scale * sum((estimate_all - estimate_jack)^2, na.rm = TRUE)),\n        .groups = 'drop'\n      )\n  }\n  else if (.estimand == 'ATE') {\n    results <-\n      results |>\n      group_by(pick(estimand, !!.by)) |>\n      summarise(\n        estimate = mean(estimate_all),\n        std.error = sqrt(scale * sum((estimate_all - estimate_jack)^2, na.rm = TRUE)),\n        .groups = 'drop'\n      )\n  }\n  results\n}\n```\n:::\n\n\n\n### 推定結果\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 並列化\nfuture::plan('multisession')\n\ndf |> \n  filter(age >= 26) |> \n  piaac_ATE_jack(\n    .outcome = pvlit1,\n    .treatment = univ,\n    .formula_rhs = ~ 1 | univ^gender^agegroup,\n    .estimand = 'ATE',\n    .weights = sampling_weight,\n    .repweights = matches('spfwt'),\n    .type = 'JK2',\n    .by = c(gender, agegroup)\n  ) |> \n  kable()\n```\n\n::: {.cell-output-display}\n\n\n|estimand |gender |agegroup | estimate| std.error|\n|:--------|:------|:--------|--------:|---------:|\n|ATE      |Male   |26-30    |   26.590|     4.692|\n|ATE      |Male   |31-35    |   24.986|     4.766|\n|ATE      |Male   |36-40    |   28.109|     3.835|\n|ATE      |Male   |41-45    |   28.916|     3.917|\n|ATE      |Male   |46-50    |   30.594|     4.789|\n|ATE      |Male   |51-55    |   35.483|     5.616|\n|ATE      |Male   |56-60    |   38.366|     5.703|\n|ATE      |Male   |61-65    |   24.382|     4.711|\n|ATE      |Female |26-30    |   22.546|     3.546|\n|ATE      |Female |31-35    |   24.534|     3.581|\n|ATE      |Female |36-40    |   27.753|     4.466|\n|ATE      |Female |41-45    |   34.266|     4.167|\n|ATE      |Female |46-50    |   23.310|     4.708|\n|ATE      |Female |51-55    |   32.056|     5.081|\n|ATE      |Female |56-60    |   26.026|     4.619|\n|ATE      |Female |61-65    |   40.169|    10.041|\n\n\n:::\n:::\n\n\n\n### 10個のPVに対して一括で推定\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 読解力PVの変数名を取得\npvs <- df |> select(matches('pvlit')) |> names()\n\nresult <- \n  map(\n    pvs,\n    \\(x) piaac_ATE_jack(\n      .data = df |> filter(age >= 26),\n      # mapで回すときは`!!`を使う\n      .outcome = !!x,\n      .treatment = univ,\n      .formula_rhs = ~ 1 | univ^gender^agegroup,\n      .estimand = 'ATE',\n      .weights = sampling_weight,\n      .repweights = matches('spfwt'),\n      .type = 'JK2',\n      .by = gender\n    )) |> \n  bind_rows(.id = 'pv')\n\nresult\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 20 × 5\n   pv    estimand gender estimate std.error\n   <chr> <chr>    <fct>     <dbl>     <dbl>\n 1 1     ATE      Male       29.4      1.61\n 2 1     ATE      Female     29.2      2.01\n 3 2     ATE      Male       29.8      1.78\n 4 2     ATE      Female     29.7      1.98\n 5 3     ATE      Male       29.4      1.76\n 6 3     ATE      Female     29.6      2.13\n 7 4     ATE      Male       32.2      1.73\n 8 4     ATE      Female     32.3      2.16\n 9 5     ATE      Male       30.6      1.71\n10 5     ATE      Female     29.8      1.82\n11 6     ATE      Male       30.5      1.67\n12 6     ATE      Female     29.7      2.06\n13 7     ATE      Male       30.4      1.78\n14 7     ATE      Female     31.0      1.80\n15 8     ATE      Male       30.0      1.84\n16 8     ATE      Female     31.2      1.91\n17 9     ATE      Male       32.1      1.66\n18 9     ATE      Female     31.3      2.17\n19 10    ATE      Male       30.8      1.60\n20 10    ATE      Female     32.7      1.81\n```\n\n\n:::\n:::\n\n\n\n### 結果の統合\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresult |> \n  pool_rubin(term = c(estimand, gender)) |> \n  kable()\n```\n\n::: {.cell-output-display}\n\n\n|estimand |gender |  M| estimate| std.error| conf.low| conf.high|\n|:--------|:------|--:|--------:|---------:|--------:|---------:|\n|ATE      |Male   | 10|   30.526|     1.996|   26.613|    34.439|\n|ATE      |Female | 10|   30.643|     2.364|   26.011|    35.276|\n\n\n:::\n:::\n\n\n\n\n\n## 参考文献\n\nJakubowski, Maciej & Artur Pokropek, 2019, \"piaactools: A program for data analysis with PIAAC data,\" _The Stata Journal_, 19(1): 112-128. <https://doi.org/10.1177/1536867X19830909>\n",
    "supporting": [
      "Standard_Errors_in_PIAAC_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}