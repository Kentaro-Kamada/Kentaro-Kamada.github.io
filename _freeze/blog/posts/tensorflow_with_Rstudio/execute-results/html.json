{
  "hash": "6cc818172539b35ece102a6e857dc98f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"tensorflowをRstudioで\"\ndate: 2024-02-23\ncategories: [R Tips]\nengine: knitr\n---\n\n\n\npythonをRStudioで使うのは`reticulate`パッケージによりだいぶ楽になった。\n\nただpythonにおけるdeep learningの代表的パッケージである`tensorflow`をRStudioで使う際に少しつまづいたのでメモです。\n\n## pythonの環境をどうやって構築するか？\n\nRでは`renv`パッケージを使っている。ではpythonでは？\n\npythonはRよりも環境が複雑で変化も早そうなので、環境構築は重要。\n\n今回はpython公式が推奨しているっぽい`venv`を使う。\n\n:::{.callout-note}\n最初global環境でそのままやろうとしたが上手くいかず挫折。Dockerとかも有力だと思う。\n:::\n\n## venvを使って仮想環境を用意\n\n- pythonがインストールされているか確認\n  - homebrewなりでインストールしておく\n  - PATHを通しておく\n\n- 作業ディレクトリにて、terminalで以下のコマンドを実行し`.venv`フォルダを作成\n\n\n\n::: {.cell filename='terminal'}\n\n```{.bash .cell-code}\npython3 -m venv .venv\n```\n:::\n\n\n\n## pythonライブラリをインストール\n\n- 以下のコマンドを実行し、仮想環境を起動\n  - pythonの場所が`.venv`内のフォルダになる\n\n\n\n::: {.cell filename='terminal'}\n\n```{.bash .cell-code}\nsource .venv/bin/activate\n```\n:::\n\n\n\n:::{.callout-note}\n`source .venv/bin/activate`は、ライブラリをインストールするときは毎回実行する必要があります！\n\nまちがってglobal環境を汚さないように！\n:::\n\n- ライブラリをインストール\n  - `tensorflow`のほか、`numpy`も必須（`tensorflow`をインストールしたときに入る）\n  - M1 macでGPUを使いたい場合は`tensorflow-metal`もインストールする\n\n\n\n::: {.cell filename='terminal'}\n\n```{.bash .cell-code}\npip install tensorflow-macos\npip install tensorflow-metal\n```\n:::\n\n\n\n- 仮想環境を抜けるときは以下のコマンドを実行\n\n\n\n::: {.cell filename='terminal'}\n\n```{.bash .cell-code}\ndeactivate\n```\n:::\n\n\n\n\n## RStudioでpythonを使う\n\n### pythonの場所を指定\n\n- RStudioでpythonを使うには、RStudioにpythonの場所を教えてやる必要がある\n  - 今回は`.venv`内のpythonを使いたいので、作業ディレクトリに`.Rprofile`を作成し、以下のコードを書く\n  - `renv`を使っている場合は、`.Rprofile`が既に作成されていると思うので、その中に追記する\n\n\n\n::: {.cell filename='.Rprofile'}\n\n```{.r .cell-code}\n# renv起動\nsource(\"renv/activate.R\")\n# pythonの場所を指定\nSys.setenv(RETICULATE_PYTHON = \".venv/bin/python3\")\n```\n:::\n\n\n\n:::{.callout-note}\npythonの場所の指定は`renv`の起動より後に行う必要がある。もし先にpythonの場所を指定してしまうと、`renv`を起動したときにpythonの場所が上書きされてしまい、上手くいかなくなる。\n:::\n\n### pythonを起動\n\n- RStudioでpythonのコードを実行すると、`reticulate::repl_python()`が走ってコンソールがpythonになる\n\n\n\n::: {.cell filename='python'}\n\n```{.python .cell-code}\nimport sys\nprint(sys.version)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n3.11.12 (main, Apr  8 2025, 14:15:29) [Clang 16.0.0 (clang-1600.0.26.6)]\n```\n\n\n:::\n:::\n\n\n\n- tensorflowを起動して、GPUが使えるかを確認\n- physical_deviceでCPUとGPUの両方が表示されてればOK\n\n\n\n::: {.cell filename='python'}\n\n```{.python .cell-code}\nimport tensorflow as tf\ntf.config.list_physical_devices()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n```\n\n\n:::\n:::\n\n\n\n## ニューラルネットをやってみる\n\n- チュートリアルとして、手書きのアルファベットを分類するモデルを作成してみる\n- Rでデータを読み込んで、pythonに渡して`tensorflow`で分析\n- [参考](https://ai.stanford.edu/~btaskar/ocr/)\n\n\n\n::: {.cell filename='R'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(rsample)\nlibrary(reticulate)\n```\n:::\n\n\n\n\n### データのダウンロード\n\n\n\n::: {.cell filename='R'}\n\n```{.r .cell-code}\n# データのダウンロード\nif (!dir.exists('data')) dir.create('data')\ndownload.file('https://ai.stanford.edu/~btaskar/ocr/letter.data.gz', destfile = 'data/letter.data')\n```\n:::\n\n\n\n### データの読み込み\n\n- 列名は[https://ai.stanford.edu/~btaskar/ocr/letter.names](https://ai.stanford.edu/~btaskar/ocr/letter.names)より取得できる\n- 詳細は以下の通り\n  1. id: each letter is assigned a unique integer id\n  1. letter: a-z\n  1. next_id: id for next letter in the word, -1 if last letter\n  1. word_id: each word is assigned a unique integer id (not used)\n  1. position: position of letter in the word (not used)\n  1. fold: 0-9 -- cross-validation fold\n  1. p_i_j: 0/1 -- value of pixel in row i, column j\n- letterとp_i_j（pixel）のみ使うのでそれ以外は削除\n\n\n\n::: {.cell filename='R'}\n\n```{.r .cell-code}\ncolname <- read_lines('https://ai.stanford.edu/~btaskar/ocr/letter.names')\ndata <- \n  read_tsv('data/letter.data', col_names = colname) |> \n  # letterとpixelだけ残す\n  select(id, letter, matches('p_\\\\d+_\\\\d+'))\n```\n:::\n\n\n\n### データの前処理\n\n- letterを数値に変換\n\n\n\n::: {.cell filename='R'}\n\n```{.r .cell-code}\ndf <- \n  data |> \n  mutate(\n    letter = factor(letter),\n    # pythonは0からはじまるので-1する（Rは1から）\n    letter_num = as.numeric(letter) - 1\n  )\n```\n:::\n\n\n\n- 訓練データとテストデータに分割\n\n\n\n::: {.cell filename='R'}\n\n```{.r .cell-code}\nsplit <- rsample::initial_split(df, prop = 0.9)\ntrain <- rsample::training(split)\ntest <- rsample::testing(split)\n```\n:::\n\n\n\n- pythonに渡せる形にデータを変換\n  - `reticulate::np_array()`であらかじめ`ndarray`にしておくと便利\n\n\n\n::: {.cell filename='R'}\n\n```{.r .cell-code}\ntrain_x <- \n  train |> \n  select(!c(id, letter, letter_num)) |>\n  as.matrix() |> \n  np_array()\n\ntrain_y <-\n  train |>\n  pull(letter_num) |>\n  np_array()\n\ntest_x <-\n  test |> \n  select(!c(id, letter, letter_num)) |>\n  as.matrix() |> \n  np_array()\n\ntest_y <-\n  test |>\n  pull(letter_num) |>\n  np_array()\n```\n:::\n\n\n\n\n### ニューラルネットで学習\n\n- 中間層が1つのニューラルネットを作成\n  - 入力層は16x8=128（ピクセル）\n  - 中間層は64次元\n  - 出力層はa-zの26分類\n\n\n\n::: {.cell filename='python'}\n\n```{.python .cell-code}\nimport tensorflow as tf\nimport numpy as np\n\n# モデルの作成\nmodel = tf.keras.Sequential([\n  tf.keras.layers.Dense(64, activation='relu'),\n  tf.keras.layers.Dense(26, activation='softmax')\n])\n\nmodel.compile(\n  optimizer='adam',\n  loss='sparse_categorical_crossentropy',\n  metrics=['accuracy']\n)\n```\n:::\n\n\n\n- rで作成したデータをpythonに渡して学習\n- `r.train_x`でRの`train_x`を参照できる\n- pythonのオブジェクトを渡すときは`py$train_x`\n\n\n\n::: {.cell filename='python'}\n\n```{.python .cell-code}\n# モデルの学習\nmodel.fit(r.train_x, r.train_y, epochs=10, verbose=2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEpoch 1/10\n1467/1467 - 8s - loss: 1.3177 - accuracy: 0.6413 - 8s/epoch - 6ms/step\nEpoch 2/10\n1467/1467 - 6s - loss: 0.9427 - accuracy: 0.7486 - 6s/epoch - 4ms/step\nEpoch 3/10\n1467/1467 - 6s - loss: 0.8788 - accuracy: 0.7642 - 6s/epoch - 4ms/step\nEpoch 4/10\n1467/1467 - 6s - loss: 0.8475 - accuracy: 0.7729 - 6s/epoch - 4ms/step\nEpoch 5/10\n1467/1467 - 6s - loss: 0.8340 - accuracy: 0.7759 - 6s/epoch - 4ms/step\nEpoch 6/10\n1467/1467 - 6s - loss: 0.8259 - accuracy: 0.7777 - 6s/epoch - 4ms/step\nEpoch 7/10\n1467/1467 - 6s - loss: 0.8233 - accuracy: 0.7786 - 6s/epoch - 4ms/step\nEpoch 8/10\n1467/1467 - 6s - loss: 0.8240 - accuracy: 0.7773 - 6s/epoch - 4ms/step\nEpoch 9/10\n1467/1467 - 6s - loss: 0.8218 - accuracy: 0.7789 - 6s/epoch - 4ms/step\nEpoch 10/10\n1467/1467 - 6s - loss: 0.8242 - accuracy: 0.7779 - 6s/epoch - 4ms/step\n<keras.src.callbacks.History object at 0x177fd5910>\n```\n\n\n:::\n:::\n\n\n\n### テストデータで評価\n\n- テストデータでの正答率は77%くらい\n\n\n\n::: {.cell filename='python'}\n\n```{.python .cell-code}\n# モデルの評価\nmodel.evaluate(r.test_x, r.test_y, verbose=2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n163/163 - 1s - loss: 0.8293 - accuracy: 0.7688 - 513ms/epoch - 3ms/step\n[0.8292935490608215, 0.7687883377075195]\n```\n\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}