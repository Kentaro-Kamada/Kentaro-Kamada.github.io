---
title: "Causal Decomposition Analysis"
date: 2024-02-22
categories: [Causal Inference]
---

## 前準備

```{r}
#| warning: false

library(tidyverse)
library(cfdecomp)
library(gapclosing)
library(causal.decomp)


d <- 
  sMIDUS |> 
  transmute(Y = health |> as.numeric(),  # outcome
            T = edu |> as.numeric(),   # treatment (continuous)
            T2 = edu |> case_match(4:6 ~ 0,   # treatment (binary)
                                   7:9 ~ 1,
                                   .default = NA) |> factor(),
            X = racesex |> factor(levels = c("1", "4", "2", "3")),  # note!
            L1 = lowchildSES |> as.numeric(),
            L2 = abuse |> as.numeric(),
            C1 = age |> as.numeric(),
            C2 = stroke |> as.numeric(),
            C3 = T2DM |> as.numeric(),
            C4 = heart |> as.numeric()) |> 
  mutate(across(L1:C4, \(.x){.x - mean(.x, na.rm = TRUE)})) |> 
  tibble()
```

# continuuous mediator

## `cfdecomp`

- @Sudharsanan2021 の方法。mediatorの値をシミュレーションで複数生成するのが特徴

```{r}
# cfd.mean
fit_cfdecomp <-
  cfdecomp::cfd.mean(
    formula.y = 'Y ~ X + T + X:T + L1 + L2 + C1 + C2 + C3 + C4',
    formula.m = 'T ~ X + C1 + C2 + C3 + C4',
    mediator = 'T',
    group = 'X',
    data = d |> data.frame(),
    family.y = 'gaussian',
    family.m = 'gaussian',
    bs.size = 50,
    mc.size = 10,
    alpha = 0.05
  )

```


```{r}

fit_cfdecomp
mean(fit_cfdecomp$out_nc_y[,2] - fit_cfdecomp$out_nc_y[,1])
mean(fit_cfdecomp$out_cf_y[,2] - fit_cfdecomp$out_nc_y[,1])
mean(fit_cfdecomp$out_nc_y[,2] - fit_cfdecomp$out_cf_y[,2])
fit_cfdecomp$mediation

mean(fit_cfdecomp$out_nc_y[,3] - fit_cfdecomp$out_nc_y[,1])
mean(fit_cfdecomp$out_cf_y[,3] - fit_cfdecomp$out_nc_y[,1])
mean(fit_cfdecomp$out_nc_y[,3] - fit_cfdecomp$out_cf_y[,3])

mean(fit_cfdecomp$out_nc_y[,4] - fit_cfdecomp$out_nc_y[,1])
mean(fit_cfdecomp$out_cf_y[,4] - fit_cfdecomp$out_nc_y[,1])
mean(fit_cfdecomp$out_nc_y[,4] - fit_cfdecomp$out_cf_y[,4])

```

## `causal.decomp`

- @Park2023a の方法。

```{r}
# smi 
fit.y <- lm(Y ~ X + T + X:T + L1 + L2 + C1 + C2 + C3 + C4, data = d)
fit.m <- lm(T ~ X + C1 + C2 + C3 + C4, data = d)

fit_smi <- smi(fit.y = fit.y,
    fit.m = fit.m,
    treat = "X", 
    sims = 100, 
    conf.level = .95,
    conditional = TRUE,
    covariates = 1,
    # baseline covariatesを調整できる
    #covariates = c("C1", "C2", "C3", "C4"),
    seed = 227,
    )

fit_smi

```

- sensitivity analysis[@Park2023]

```{r}

sensRes <- sensitivity(boot.res = fit_smi, fit.m = fit.m, fit.y = fit.y, 
                       mediator = "T",
                       covariates = c("C1", "C2", "C3", "C4"), 
                       treat = "X",
                       sel.lev.treat = "4", 
                       max.rsq = 0.3)
plot(sensRes)


```


# binary mediator

## `cfdecomp`

```{r}
# cfd.mean
set.seed(123456)
fit_cfdecomp_b <-
  cfd.mean(
    formula.y = 'Y ~ X + T2 + X:T2 + L1 + L2 + C1 + C2 + C3 + C4',
    formula.m = 'T2 ~ X + C1 + C2 + C3 + C4',
    mediator = 'T2',
    group = 'X',
    data = d |> mutate(T2 = as.numeric(T2) - 1) |> data.frame(),
    family.y = 'gaussian',
    family.m = 'binomial',
    bs.size = 50,
    mc.size = 10,
    alpha = 0.05
  )
mean(fit_cfdecomp_b$out_nc_y[,"4"] - fit_cfdecomp_b$out_nc_y[,"1"])
mean(fit_cfdecomp_b$out_cf_y[,"4"] - fit_cfdecomp_b$out_nc_y[,"1"])
mean(fit_cfdecomp_b$out_nc_y[,"4"] - fit_cfdecomp_b$out_cf_y[,"4"])
fit_cfdecomp_b$mediation

mean(fit_cfdecomp_b$out_nc_y[,"2"] - fit_cfdecomp_b$out_nc_y[,"1"])
mean(fit_cfdecomp_b$out_cf_y[,"2"] - fit_cfdecomp_b$out_nc_y[,"1"])
mean(fit_cfdecomp_b$out_nc_y[,"2"] - fit_cfdecomp_b$out_cf_y[,"2"])

mean(fit_cfdecomp_b$out_nc_y[,"3"] - fit_cfdecomp_b$out_nc_y[,"1"])
mean(fit_cfdecomp_b$out_cf_y[,"3"] - fit_cfdecomp_b$out_nc_y[,"1"])
mean(fit_cfdecomp_b$out_nc_y[,"3"] - fit_cfdecomp_b$out_cf_y[,"3"])

```

## `causal.decomp`

```{r}

# smi
fit.y <- lm(Y ~ X + T2 + X:T2 + L1 + L2 + C1 + C2 + C3 + C4, data = d)
fit.m <- glm(T2 ~ X + C1 + C2 + C3 + C4, data = d, family = binomial(link = "logit"))

fit_smi_b <- smi(fit.y = fit.y,
               fit.m = fit.m,
               treat = "X", 
               sims = 100, 
               conf.level = .95,
               conditional = TRUE,
               # covariates = 1,
               covariates = c("C1", "C2", "C3", "C4"),
               seed = 123456)
fit_smi_b
sensRes <- sensitivity(boot.res = fit_smi_b, 
                       fit.m = fit.m, 
                       fit.y = fit.y, 
                       mediator = "T2",
                       covariates = c("C1", "C2", "C3", "C4"), 
                       treat = "X",
                       sel.lev.treat = "4", 
                       max.rsq = 0.3)
plot(sensRes)


```


## `gapclosing`

- @Lundberg2022a

```{r}
# gapclosing - regression
# stochastic intervention
# treatmentの割り当て確率の予測値を算出
fit_glm <- glm(T2 ~ X + C1 + C2 + C3, data = d, family = binomial(link = "logit"))

# 全員のtreatmentが1だった時の予測値
assing_prob <- predict(fit_glm, newdata = d |> mutate(X = "1"), type = "response")

# 予測値をもとにrandom draw
draw <- rbinom(n = nrow(d), size = 1, prob = assing_prob)

fit_gapclosing <- 
  gapclosing(
    data = d |> mutate(T2 = as.numeric(T2) - 1),
    outcome_formula = Y ~ T2 * X + C1 + C2 + C3 + C4 + L1 + L2,
    treatment_name = "T2",
    category_name = "X",
    counterfactual_assignments = draw # random draw
  )

fit_gapclosing
disparityplot(fit_gapclosing, category_A = "1", category_B = "4")
disparityplot(fit_gapclosing, category_A = "1", category_B = "2")
disparityplot(fit_gapclosing, category_A = "1", category_B = "3")

```

- 機械学習をつかったdoubly robustな方法も使える

```{r}
# gapclosing - ranger, doubly robust
fit_gapclosing_ranger <- 
  gapclosing(
  data = d |> mutate(T2 = as.numeric(T2) - 1),
  outcome_formula = Y ~ T2 + X + C1 + C2 + C3 + C4 + L1 + L2,
  treatment_formula = T2 ~ X + C1 + C2 + C3 + C4 + L1 + L2, 
  treatment_name = "T2",
  treatment_algorithm = "ranger",
  outcome_algorithm = "ranger",
  category_name = "X",
  counterfactual_assignments = rbinom(n = nrow(d), size = 1, prob = assing_prob) 
)

fit_gapclosing
disparityplot(fit_gapclosing_ranger, category_A = "1", category_B = "4")
disparityplot(fit_gapclosing_ranger, category_A = "1", category_B = "2")
disparityplot(fit_gapclosing_ranger, category_A = "1", category_B = "3")


```











